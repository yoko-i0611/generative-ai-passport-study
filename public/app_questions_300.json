{
  "version": "1.0.0",
  "totalQuestions": 300,
  "lastUpdated": "2025-01-15T00:00:00Z",
  "description": "生成AIパスポート試験対策問題集（300問）",
  "questions": [
    {
      "questionId": "unit_001",
      "question": "AI（人工知能）とロボットの定義上の違いとして、最も適切な説明はどれか。",
      "options": [
        "AIは物理的な身体を持つ機械であり、ロボットは知能を持つソフトウェアである。",
        "AIは「脳（ソフトウェア）」であり物理的な身体を必要としないが、ロボットは「体（ハードウェア）」を持つ機械である。",
        "AIとロボットは完全に同じ意味であり、区別する必要はない。",
        "AIは人間型である必要があり、ロボットは産業用である必要がある。"
      ],
      "correctAnswer": "AIは「脳（ソフトウェア）」であり物理的な身体を必要としないが、ロボットは「体（ハードウェア）」を持つ機械である。",
      "explanation": "正解は「AIは「脳（ソフトウェア）」であり物理的な身体を必要としないが、ロボットは「体（ハードウェア）」を持つ機械である。」です。AIは知覚や学習を行うソフトウェア（脳）であり、物理的な身体がなくても機能します。一方、ロボットは物理的な機械（体）を指し、両者は明確に区別されます。選択肢1、3、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit01"
      }
    },
    {
      "questionId": "unit_002",
      "question": "AIの進化段階を示す「AIの4つのレベル」において、レベル3とレベル4の決定的な違いは何か。",
      "options": [
        "レベル3はルールベースだが、レベル4は機械学習である。",
        "レベル3は家電製品に使われるが、レベル4は将棋プログラムに使われる。",
        "レベル3は人間が特徴量（着眼点）を指定する必要があるが、レベル4はAIが自ら特徴量を学習する（ディープラーニング）。",
        "レベル3は強いAI（AGI）だが、レベル4は弱いAI（ANI）である。"
      ],
      "correctAnswer": "レベル3は人間が特徴量（着眼点）を指定する必要があるが、レベル4はAIが自ら特徴量を学習する（ディープラーニング）。",
      "explanation": "正解は「レベル3は人間が特徴量（着眼点）を指定する必要があるが、レベル4はAIが自ら特徴量を学習する（ディープラーニング）。」です。レベル3（検索エンジン等）は人間が特徴量を設定しますが、レベル4（自動運転等）はディープラーニングにより、特徴量の抽出も含めて自律的に学習します。選択肢1、2、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎",
          "ディープラーニング"
        ],
        "difficulty": "medium",
        "unitId": "unit02"
      }
    },
    {
      "questionId": "unit_003",
      "question": "1956年に開催され、「人工知能（Artificial Intelligence）」という言葉が初めて使われた会議はどれか。",
      "options": [
        "ダートマス会議",
        "シリコンバレー会議",
        "ケンブリッジ会議",
        "京都会議"
      ],
      "correctAnswer": "ダートマス会議",
      "explanation": "正解は「ダートマス会議」です。ジョン・マッカーシーらが主催したダートマス会議がAI研究の始まりとされており、ここから第1次AIブームが始まりました。選択肢2、3、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit03"
      }
    },
    {
      "questionId": "unit_004",
      "question": "「第2次AIブーム（1980年代）」が終焉し、再び「AIの冬」が訪れた主な技術的要因はどれか。",
      "options": [
        "コンピュータの計算速度が速すぎたため。",
        "インターネットが普及し、AIが不要になったため。",
        "専門家の知識を入力・管理するコストが膨大になり、複雑な現実問題に対応できないことが露呈したため。",
        "ディープラーニングの計算コストが高すぎたため。"
      ],
      "correctAnswer": "専門家の知識を入力・管理するコストが膨大になり、複雑な現実問題に対応できないことが露呈したため。",
      "explanation": "正解は「専門家の知識を入力・管理するコストが膨大になり、複雑な現実問題に対応できないことが露呈したため。」です。第2次ブームの主役「エキスパートシステム」は、知識入力の手間と管理の難しさ（ボトルネック）により実用性が限定的となり、ブームは終焉しました。選択肢1、2、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit04"
      }
    },
    {
      "questionId": "unit_005",
      "question": "「正解データ」を与えずに、データそのものが持つ構造やパターン（似たもの同士のグループなど）を見つけ出す学習手法はどれか。",
      "options": [
        "教師あり学習",
        "教師なし学習",
        "強化学習",
        "深層学習"
      ],
      "correctAnswer": "教師なし学習",
      "explanation": "正解は「教師なし学習」です。正解（ラベル）を与えない学習は「教師なし学習」です。代表的な手法にクラスタリングや次元削減があります。選択肢1の「教師あり学習」は正解データを必要とします。選択肢3の「強化学習」は報酬に基づいて学習します。選択肢4の「深層学習」は学習手法の分類ではありません。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎",
          "ディープラーニング"
        ],
        "difficulty": "medium",
        "unitId": "unit05"
      }
    },
    {
      "questionId": "unit_006",
      "question": "「強化学習」のプロセスとして最も適切な説明はどれか。",
      "options": [
        "過去のデータを読み込み、未来の数値を予測する。",
        "猫や犬の画像にラベルを付け、それを手本に分類を行う。",
        "コンピュータが行動を選択し、得られる「報酬」を最大化するように試行錯誤して学習する。",
        "少量のエラーデータを人間が修正する。"
      ],
      "correctAnswer": "コンピュータが行動を選択し、得られる「報酬」を最大化するように試行錯誤して学習する。",
      "explanation": "正解は「コンピュータが行動を選択し、得られる「報酬」を最大化するように試行錯誤して学習する。」です。強化学習は、行動の結果として得られる報酬（スコアなど）を最大化するように、試行錯誤を通じて最適な行動を学習します。選択肢1は時系列予測、選択肢2は教師あり学習、選択肢4は半教師あり学習の説明です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit06"
      }
    },
    {
      "questionId": "unit_007",
      "question": "機械学習における「ノーフリーランチ定理」の意味として正しいものはどれか。",
      "options": [
        "無料のランチのように、コストがかからないAIモデルが存在する。",
        "あらゆる問題に対して万能に高性能を発揮できる、唯一のモデルは存在しない。",
        "データを増やせば増やすほど、必ず精度が向上する。",
        "学習には必ず人間による食事（データ入力）が必要である。"
      ],
      "correctAnswer": "あらゆる問題に対して万能に高性能を発揮できる、唯一のモデルは存在しない。",
      "explanation": "正解は「あらゆる問題に対して万能に高性能を発揮できる、唯一のモデルは存在しない。」です。特定の問題に特化したモデルは他の問題では性能が落ちる可能性があり、あらゆる問題に万能なモデルは存在しないという定理です。選択肢1、3、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "機械学習",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit07"
      }
    },
    {
      "questionId": "unit_008",
      "question": "「半教師あり学習」が採用される主なメリットは何か。",
      "options": [
        "ラベル付け（アノテーション）のコストを大幅に削減しつつ、大量のデータを利用できる。",
        "学習時間がゼロになる。",
        "コンピュータの電力を消費しない。",
        "教師あり学習よりも必ず精度が高くなる。"
      ],
      "correctAnswer": "ラベル付け（アノテーション）のコストを大幅に削減しつつ、大量のデータを利用できる。",
      "explanation": "正解は「ラベル付け（アノテーション）のコストを大幅に削減しつつ、大量のデータを利用できる。」です。少量のラベル付きデータと大量のラベルなしデータを組み合わせることで、全てのデータにラベルを付けるコストを削減できるのがメリットです。選択肢2、3、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit08"
      }
    },
    {
      "questionId": "unit_009",
      "question": "ニューラルネットワークにおいて、人間の脳の「シナプスの結合強度」に相当し、情報の伝達効率を調整するパラメータを何と呼ぶか。",
      "options": [
        "ニューロン",
        "バイアス",
        "重み（ウェイト）",
        "層（レイヤー）"
      ],
      "correctAnswer": "重み（ウェイト）",
      "explanation": "正解は「重み（ウェイト）」です。AIの学習とは、入力と出力の誤差が小さくなるように、この「重み」を最適な値に調整し続けるプロセスを指します。選択肢1の「ニューロン」は神経細胞、選択肢2の「バイアス」は別のパラメータ、選択肢4の「層（レイヤー）」はネットワークの構造を表します。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": "unit09"
      }
    },
    {
      "questionId": "unit_010",
      "question": "ディープラーニング（深層学習）の定義として最も適切なものはどれか。",
      "options": [
        "ニューラルネットワークの「隠れ層（中間層）」を多層化したモデル。",
        "1層のみの単純なニューラルネットワーク。",
        "人間が手動でルールを記述するプログラム。",
        "データベースから検索を行うだけのシステム。"
      ],
      "correctAnswer": "ニューラルネットワークの「隠れ層（中間層）」を多層化したモデル。",
      "explanation": "正解は「ニューラルネットワークの「隠れ層（中間層）」を多層化したモデル。」です。隠れ層を何層にも深く（ディープに）重ねることで、複雑な特徴量を自動抽出できるようにしたものがディープラーニングです。選択肢2、3、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎",
          "ディープラーニング"
        ],
        "difficulty": "medium",
        "unitId": "unit10"
      }
    },
    {
      "questionId": "unit_011",
      "question": "AIが画像を認識する際、最初のステップとして行われる処理はどれか。",
      "options": [
        "画像全体を「美しい」か「汚い」かで判断する。",
        "画像を画素（ピクセル）に分解し、色情報（RGB）などを数値データとして抽出する。",
        "画像に描かれている物体の名前を辞書で引く。",
        "画像を白黒に変換して保存する。"
      ],
      "correctAnswer": "画像を画素（ピクセル）に分解し、色情報（RGB）などを数値データとして抽出する。",
      "explanation": "正解は「画像を画素（ピクセル）に分解し、色情報（RGB）などを数値データとして抽出する。」です。AIは画像を数値データとして認識します。まず画像を画素に分解し、それぞれのRGB数値（例：R24, G41, B37）を抽出することから始まります。選択肢1、3、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit11"
      }
    },
    {
      "questionId": "unit_012",
      "question": "機械学習において、AIモデルが訓練データに過度に適応しすぎてしまい、未知のデータに対する予測精度が下がってしまう現象を何と呼ぶか。",
      "options": [
        "汎化（Generalization）",
        "過学習（Overfitting）",
        "転移学習（Transfer Learning）",
        "シンギュラリティ（Singularity）"
      ],
      "correctAnswer": "過学習（Overfitting）",
      "explanation": "正解は「過学習（Overfitting）」です。訓練データのノイズや細かい癖まで暗記してしまい、新しいデータに対応できなくなる状態です。オーバーフィッティングとも呼ばれます。選択肢1の「汎化」は過学習とは逆の理想的な状態、選択肢3の「転移学習」は別のタスクへの知識の再利用、選択肢4の「シンギュラリティ」はAIが人間を超える時点を指します。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "機械学習",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit12"
      }
    },
    {
      "questionId": "unit_013",
      "question": "「過学習」を防ぐための代表的な手法の組み合わせとして、正しいものはどれか。",
      "options": [
        "データの削除・学習の長時間化・ルールの固定",
        "ドロップアウト・正則化・アーリーストッピング",
        "パラメータの増加・画像の高画質化・転移学習",
        "教師なし学習への切り替え・バイアスの増加"
      ],
      "correctAnswer": "ドロップアウト・正則化・アーリーストッピング",
      "explanation": "正解は「ドロップアウト・正則化・アーリーストッピング」です。過学習の対策としては、ニューロンをランダムに無効化する「ドロップアウト」、モデルを単純化する「正則化」、適切な時点で学習を止める「アーリーストッピング」があります。選択肢1、3、4はいずれも過学習の対策ではありません。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit13"
      }
    },
    {
      "questionId": "unit_014",
      "question": "ある領域で学習済みのモデル（例：猫の認識）の知識を、別の領域（例：レントゲン画像の診断）に応用して、学習効率を高める手法を何と呼ぶか。",
      "options": [
        "転移学習",
        "強化学習",
        "アンサンブル学習",
        "敵対的学習"
      ],
      "correctAnswer": "転移学習",
      "explanation": "正解は「転移学習」です。ゼロから学習するのではなく、既存の学習済みモデル（重みなど）を流用・微調整することで、少ないデータと時間で効率的にモデルを構築する手法です。選択肢2の「強化学習」は報酬に基づく学習、選択肢3の「アンサンブル学習」は複数のモデルを組み合わせる手法、選択肢4の「敵対的学習」はGANなどの手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "GAN",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit14"
      }
    },
    {
      "questionId": "unit_015",
      "question": "「AI効果」と呼ばれる心理現象の説明として正しいものはどれか。",
      "options": [
        "AIを使うと人間の知能が低下する現象。",
        "AIの原理が分かってしまうと、「それは単なるプログラムに過ぎない」と考え、知能とは認めなくなる（失望する）現象。",
        "AIが人間を超えて自己進化を始める現象。",
        "AIによって経済効果が生まれる現象。"
      ],
      "correctAnswer": "AIの原理が分かってしまうと、「それは単なるプログラムに過ぎない」と考え、知能とは認めなくなる（失望する）現象。",
      "explanation": "正解は「AIの原理が分かってしまうと、「それは単なるプログラムに過ぎない」と考え、知能とは認めなくなる（失望する）現象。」です。AI技術への期待が高すぎるあまり、実際に仕組みが分かったり普及したりすると「たいしたことない」と失望し、知能として認めなくなる心理現象を指します。選択肢1、3、4はいずれも誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "unit",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": "unit15"
      }
    },
    {
      "questionId": "unit_016",
      "question": "2012〜2013年のディープラーニングのブレークスルーは、画像認識などの「識別（インプット）」の革命でした。一方、現在の生成AIの台頭は、新たなデータを創り出す「生成（アウトプット）の革命」と言えます。この説明は正しいですか？",
      "options": [
        "正しい",
        "誤り"
      ],
      "correctAnswer": "正しい",
      "explanation": "2012〜2013年のディープラーニングのブレークスルーは画像認識などの「識別（インプット）」の革命でした。一方、現在の生成AIの台頭は、新しいデータを生み出す「生成（アウトプット）の革命」です。この対比はAIの進化を理解する上で重要な概念であり、表現は正確です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "ディープラーニング"
        ],
        "difficulty": "medium",
        "unitId": "unit16"
      }
    },
    {
      "questionId": "unit_017",
      "question": "AI研究の歴史において、2012年の画像認識コンペティションで圧倒的な精度を記録し、第3次AIブームの火付け役となった技術はどれか。",
      "options": [
        "RNN（回帰型ニューラルネットワーク）",
        "CNN（畳み込みニューラルネットワーク）",
        "GAN（敵対的生成ネットワーク）",
        "Transformer"
      ],
      "correctAnswer": "CNN（畳み込みニューラルネットワーク）",
      "explanation": "正解はCNNです。2012年のImageNetコンペティションでヒントン教授のチームがCNNを用いて圧勝し、ディープラーニングの有効性が世界に示されました。これが第3次AIブームの火付け役となりました。CNNは画像の局所的な特徴（畳み込み）を捉えるのに適しており、画像認識の革命を起こしました。RNNは時系列データ処理、GANは画像生成、Transformerは2017年登場でCNNより後に開発された技術です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "ディープラーニング",
          "GAN",
          "CNN",
          "RNN",
          "Transformer"
        ],
        "difficulty": "medium",
        "unitId": "unit17"
      }
    },
    {
      "questionId": "unit_018",
      "question": "GAN（敵対的生成ネットワーク）の構成要素である「Generator（生成器）」と「Discriminator（識別器）」の関係として適切なものはどれか。",
      "options": [
        "互いに協力して正解率を高める",
        "識別器が生成器に指示を出して画像を修正させる",
        "互いに競い合い（敵対し）、生成器は識別器を騙そうとし、識別器は真偽を見抜こうとする",
        "生成器が画像を生成した後、識別器が色付けを行う"
      ],
      "correctAnswer": "互いに競い合い（敵対し）、生成器は識別器を騙そうとし、識別器は真偽を見抜こうとする",
      "explanation": "正解は「互いに競い合う」関係です。GANでは、生成器（Generator）は識別器を騙そうと高品質なデータを生成し、識別器（Discriminator）はそのデータが本物か偽物かを見抜こうとします。この敵対的な競争により、生成データの品質が向上します。選択肢1の「協力して」は誤りです。選択肢2の「識別器が指示を出す」や選択肢4の「識別器が色付けを行う」もGANの仕組みとは異なります。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "GAN",
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": "unit18"
      }
    },
    {
      "questionId": "unit_019",
      "question": "2017年に登場し、現在のLLM（大規模言語モデル）の全ての基礎となっている「Transformer」モデルの最大の特徴はどれか。",
      "options": [
        "畳み込み演算による画像特徴の抽出",
        "逐次処理による時系列データの学習",
        "Self-Attention（自己注意機構）による並列処理と長距離依存の学習",
        "敵対的学習によるデータ生成"
      ],
      "correctAnswer": "Self-Attention（自己注意機構）による並列処理と長距離依存の学習",
      "explanation": "正解は「Self-Attention（自己注意機構）による並列処理と長距離依存の学習」です。Transformerの最大の特徴は、Self-Attentionにより文中の離れた単語同士の関係性を一括（並列）で計算できることです。これにより学習速度と性能が劇的に向上し、現在のLLMの全ての基礎となりました。選択肢1の「畳み込み演算」はCNNの特徴、選択肢2の「逐次処理」はRNN/LSTMの特徴、選択肢4の「敵対的学習」はGANの特徴です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "GAN",
          "CNN",
          "LSTM",
          "RNN",
          "Transformer"
        ],
        "difficulty": "medium",
        "unitId": "unit19"
      }
    },
    {
      "questionId": "unit_020",
      "question": "自然言語処理モデル「BERT」の特徴として適切なものはどれか。",
      "options": [
        "文章の生成に特化したモデルである",
        "文脈を「双方向」から理解し、マスクされた単語を予測する（MLM）",
        "画像とテキストを同時に処理するマルチモーダルモデルである",
        "時系列データを順に処理するRNNの一種である"
      ],
      "correctAnswer": "文脈を「双方向」から理解し、マスクされた単語を予測する（MLM）",
      "explanation": "正解は「文脈を双方向から理解し、マスクされた単語を予測する（MLM）」です。BERTはTransformerのエンコーダ部分を使用し、文章の前後（双方向）から文脈を読んで、マスクされた単語を予測する「Masked Language Model（MLM）」という手法で学習します。これにより深い言語理解を実現しました。選択肢1の「文章の生成に特化」は誤りで、BERTは理解に特化したモデルです。選択肢3の「マルチモーダル」や選択肢4の「RNNの一種」もBERTの特徴ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "マルチモーダル",
          "Transformer",
          "RNN"
        ],
        "difficulty": "medium",
        "unitId": "unit20"
      }
    },
    {
      "questionId": "unit_021",
      "question": "VAE（変分自己符号化器）の仕組みとして正しいものはどれか。",
      "options": [
        "データを「潜在変数（ベクトル）」に圧縮し、そこから元のデータを復元・生成する",
        "テキストから画像を生成する専用モデルである",
        "生成器と識別器を競わせて画像を生成する",
        "ノイズから徐々に画像を浮かび上がらせる"
      ],
      "correctAnswer": "データを「潜在変数（ベクトル）」に圧縮し、そこから元のデータを復元・生成する",
      "explanation": "正解は「データを潜在変数（ベクトル）に圧縮し、そこから元のデータを復元・生成する」です。VAEはデータを「潜在変数（ベクトル）」と呼ばれる低次元の表現に圧縮（エンコード）し、そこから元のデータを復元・再構築（デコード）する過程で新しいデータを生成します。選択肢2の「テキストから画像生成専用」は誤りで、VAEは様々なデータタイプに適用可能です。選択肢3の「生成器と識別器を競わせる」はGANの特徴、選択肢4の「ノイズから画像を浮かび上がらせる」は拡散モデルの特徴です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "GAN",
          "生成AI",
          "VAE",
          "拡散モデル"
        ],
        "difficulty": "medium",
        "unitId": "unit21"
      }
    },
    {
      "questionId": "unit_022",
      "question": "Transformerの主要な特徴として正しいものはどれですか？",
      "options": [
        "Self-Attentionと並列処理により、文脈を一括計算できる",
        "逐次処理により、長文の文脈を忘れない",
        "CNNベースの画像認識に特化している"
      ],
      "correctAnswer": "Self-Attentionと並列処理により、文脈を一括計算できる",
      "explanation": "正解は「Self-Attentionと並列処理により、文脈を一括計算できる」です。TransformerはSelf-Attentionにより文中の単語同士の関係性を一括で計算し、並列処理により学習速度が飛躍的に向上しました。これにより長文の文脈も一度に計算できるようになり、RNN/LSTMの限界を解決しました。選択肢2の「逐次処理により長文の文脈を忘れない」は誤りで、これはRNN/LSTMの特徴ではなく、むしろ逐次処理が長文の文脈を忘れてしまうという課題がありました。選択肢3の「CNNベースの画像認識」はTransformerの特徴ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "CNN",
          "LSTM",
          "RNN",
          "Transformer"
        ],
        "difficulty": "medium",
        "unitId": "unit22"
      }
    },
    {
      "questionId": "unit_023",
      "question": "画像生成AIにおいて、2025年以降の最新モデル（GPT-4o統合機能など）で採用が進んでいる「自己回帰型（Autoregressive）」の説明として適切なものはどれか。",
      "options": [
        "ノイズを徐々に除去することで画像を浮かび上がらせる",
        "画像をトークンとして扱い、左上から右下へ一つずつ描画していく",
        "生成器と識別器を競わせて画像を生成する",
        "画像を潜在ベクトルに圧縮してから復元する"
      ],
      "correctAnswer": "画像をトークンとして扱い、左上から右下へ一つずつ描画していく",
      "explanation": "正解は「画像をトークンとして扱い、左上から右下へ一つずつ描画していく」です。自己回帰型は、画像をトークン（断片）として扱い、テキスト生成と同じように左上から右下へ順番に描画していく方式です。これにより、画像内の文字、ロゴ、細かい線、レイアウトの精度が劇的に向上しました。選択肢1の「ノイズ除去」は拡散モデルの特徴、選択肢3の「生成器と識別器を競わせる」はGANの特徴、選択肢4の「潜在ベクトルに圧縮」はVAEの特徴です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "トークン化",
          "GAN",
          "VAE",
          "GPT",
          "拡散モデル",
          "自己回帰"
        ],
        "difficulty": "medium",
        "unitId": "unit23"
      }
    },
    {
      "questionId": "unit_024",
      "question": "従来の画像生成AI（Stable Diffusionなど）で主流だった「拡散モデル（Diffusion Model）」の仕組みとして正しいものはどれか。",
      "options": [
        "ノイズ（砂嵐）から徐々にノイズを除去して画像を生成する",
        "2つのネットワークを競わせて画像を生成する",
        "過去のデータから未来の値を予測する",
        "画像の左上から順にピクセルを埋めていく"
      ],
      "correctAnswer": "ノイズ（砂嵐）から徐々にノイズを除去して画像を生成する",
      "explanation": "正解は「ノイズ（砂嵐）から徐々にノイズを除去して画像を生成する」です。拡散モデルは、ノイズだらけの画像から少しずつノイズを除去し、元の画像を復元する方式で画像を生成します。Stable Diffusionなど従来の画像生成AIで主流だった技術です。選択肢2の「2つのネットワークを競わせる」はGANの特徴、選択肢3の「過去のデータから未来の値を予測する」は自己回帰モデルの一般的な説明、選択肢4の「左上から順にピクセルを埋める」は自己回帰型画像生成の特徴です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "GAN",
          "生成AI",
          "拡散モデル",
          "自己回帰"
        ],
        "difficulty": "medium",
        "unitId": "unit24"
      }
    },
    {
      "questionId": "unit_025",
      "question": "GPT-4oやo3モデルに統合された最新の画像生成機能が採用している技術方式と、それによる主な改善点として適切な組み合わせはどれか。",
      "options": [
        "拡散モデル（Diffusion） － ノイズ除去プロセスの高速化",
        "自己回帰型（Autoregressive） － 画像内の文字生成能力の向上",
        "GAN（敵対的生成ネットワーク） － 画像の解像度の向上",
        "VAE（変分自己符号化器） － 生成速度の安定化"
      ],
      "correctAnswer": "自己回帰型（Autoregressive） － 画像内の文字生成能力の向上",
      "explanation": "正解は「自己回帰型（Autoregressive） － 画像内の文字生成能力の向上」です。GPT-4oやo3モデルなどの最新モデルでは、従来のDALL-E 3などで採用されていた「拡散モデル」ではなく「自己回帰型」を採用しています。画像をトークンとして扱い、左上から右下へ順次描画することで、看板の文字などを正確に描写できるようになりました。選択肢1の「拡散モデル」は従来技術で、ノイズ除去プロセスの高速化が主な改善点ではありませんでした。選択肢3の「GAN」や選択肢4の「VAE」は最新モデルで採用されている技術ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "トークン化",
          "GAN",
          "VAE",
          "GPT",
          "拡散モデル",
          "自己回帰"
        ],
        "difficulty": "medium",
        "unitId": "unit25"
      }
    },
    {
      "questionId": "unit_026",
      "question": "自己回帰型画像生成が拡散モデルよりも優れている点として正しいものはどれか。",
      "options": [
        "処理速度が速い",
        "画像内の文字生成や細部の位置制御の精度が高い",
        "ノイズが少ない"
      ],
      "correctAnswer": "画像内の文字生成や細部の位置制御の精度が高い",
      "explanation": "正解は「画像内の文字生成や細部の位置制御の精度が高い」です。自己回帰型は、画像をトークンとして扱い、左上から右下へ順次描画する方式により、画像内の文字、ロゴ、細かい線、レイアウトの精度が劇的に向上しました。これが拡散モデルから自己回帰型への技術転換の主な理由です。選択肢1の「処理速度が速い」は誤りで、自己回帰型は拡散モデルより処理が遅い場合もあります。選択肢3の「ノイズが少ない」は画像生成方式の違いとは直接関係ありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "トークン化",
          "拡散モデル",
          "自己回帰"
        ],
        "difficulty": "medium",
        "unitId": "unit26"
      }
    },
    {
      "questionId": "unit_027",
      "question": "OpenAIのモデル名称における「o」の意味と、そのモデル特性に関する説明として正しいものはどれか。",
      "options": [
        "「GPT-4o」の「o」は「Optimal（最適）」を意味し、コストパフォーマンスを最優先している。",
        "「GPT-o1」の「o」は「Omni（全て）」を意味し、テキスト・音声・画像をリアルタイムに処理する。",
        "「GPT-4o」の「o」は「Omni（全て）」を意味し、マルチモーダルな処理を単一モデルで高速に行う。",
        "「GPT-o1」と「GPT-4o」は、発売時期が異なるだけで内部構造は同じである。"
      ],
      "correctAnswer": "「GPT-4o」の「o」は「Omni（全て）」を意味し、マルチモーダルな処理を単一モデルで高速に行う。",
      "explanation": "正解は「GPT-4oの『o』は『Omni（全て）』を意味し、マルチモーダルな処理を単一モデルで高速に行う」です。GPT-4oの「o」は「Omni（全て）」を意味し、テキスト・画像・音声を1つのモデルで統合処理する体験重視のマルチモーダルモデルです。選択肢1の「Optimal（最適）」は誤りで、コストパフォーマンスが主目的ではありません。選択肢2の「GPT-o1の『o』はOmni」は誤りで、GPT-o1はReasoning（推論）特化型です。選択肢4の「発売時期が異なるだけで構造は同じ」も誤りで、GPT-4oとGPT-o1は全く異なる系列のモデルです。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "GPT",
          "マルチモーダル"
        ],
        "difficulty": "medium",
        "unitId": "unit27"
      }
    },
    {
      "questionId": "unit_028",
      "question": "「マルチモーダルAI」の定義として最も適切なものはどれか。",
      "options": [
        "複数の言語を話せるAI",
        "テキスト、画像、音声、動画など、複数の種類のデータ形式を統合して処理できるAI",
        "複数のPCで同時に動作するAI",
        "複数のユーザーと同時に会話できるAI"
      ],
      "correctAnswer": "テキスト、画像、音声、動画など、複数の種類のデータ形式を統合して処理できるAI",
      "explanation": "正解は「テキスト、画像、音声、動画など、複数の種類のデータ形式を統合して処理できるAI」です。マルチモーダル（Multimodal）は「複数のモード（様式）」を意味し、テキスト以外の情報（画像・音声・動画など）も扱えるAIを指します。選択肢1の「複数の言語を話せる」は多言語対応であり、マルチモーダルの定義ではありません。選択肢3の「複数のPCで同時に動作」や選択肢4の「複数のユーザーと同時に会話」は、マルチモーダルとは関係ない概念です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "マルチモーダル"
        ],
        "difficulty": "medium",
        "unitId": "unit28"
      }
    },
    {
      "questionId": "unit_029",
      "question": "GPT-4o（Omni系列）の音声応答の特徴として正しいものはどれか。",
      "options": [
        "最短232ms、平均320msの低レイテンシ",
        "最短500ms、平均800msの応答速度",
        "最短1秒、平均2秒の応答速度"
      ],
      "correctAnswer": "最短232ms、平均320msの低レイテンシ",
      "explanation": "正解は「最短232ms、平均320msの低レイテンシ」です。GPT-4o（Omni系列）は人間の会話に近い速度を狙って設計されており、音声入力への応答が最短232ms、平均320msと非常に高速です。これによりリアルタイム体験が実現されています。選択肢2の「最短500ms、平均800ms」や選択肢3の「最短1秒、平均2秒」は、GPT-4oの実際の応答速度より遅く、正確ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "GPT"
        ],
        "difficulty": "medium",
        "unitId": "unit29"
      }
    },
    {
      "questionId": "unit_030",
      "question": "「GPT-5 Thinking」モデルの性能報告として、正しい記述を選びなさい。",
      "options": [
        "従来のモデルと比較して、計算速度が10倍になった。",
        "o3モデルと比較して、ハルシネーション（幻覚）が約80%減少した。",
        "画像生成機能が削除され、テキスト処理に特化した。",
        "日本語の学習データが含まれなくなった。"
      ],
      "correctAnswer": "o3モデルと比較して、ハルシネーション（幻覚）が約80%減少した。",
      "explanation": "正解は「o3モデルと比較して、ハルシネーション（幻覚）が約80%減少した」です。GPT-5 Thinkingは深い推論能力を持ち、o3モデルと比較してハルシネーションが約80%減少したと報告されています。この数値は試験の重要ポイントです。選択肢1の「計算速度が10倍になった」は性能報告として記述されていません。選択肢3の「画像生成機能が削除」や選択肢4の「日本語の学習データが含まれなくなった」も、GPT-5 Thinkingの性能報告には含まれていません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "GPT",
          "ハルシネーション"
        ],
        "difficulty": "medium",
        "unitId": "unit30"
      }
    },
    {
      "questionId": "unit_031",
      "question": "プロンプトエンジニアリングにおける「Chain-of-Thought（思考の連鎖）」プロンプティングの効果は何か。",
      "options": [
        "AIに「ステップバイステップで考えて」と指示することで、論理的推論の精度を向上させる",
        "AIに過去の会話を全て忘れさせる",
        "AIの応答速度を最大化する",
        "画像生成の画質を向上させる"
      ],
      "correctAnswer": "AIに「ステップバイステップで考えて」と指示することで、論理的推論の精度を向上させる",
      "explanation": "正解は「AIに『ステップバイステップで考えて』と指示することで、論理的推論の精度を向上させる」です。Chain-of-Thoughtプロンプティングは、思考過程を出力させることで、複雑な計算や論理問題の正答率を高める手法です。Reasoningモデル（GPT-o1/o3/o4/GPT-5 Thinking）は、このChain-of-Thoughtを内部処理として持つモデル群です。選択肢2の「過去の会話を全て忘れさせる」、選択肢3の「応答速度を最大化」、選択肢4の「画像生成の画質を向上」は、Chain-of-Thoughtプロンプティングの効果ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "GPT",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": "unit31"
      }
    },
    {
      "questionId": "unit_032",
      "question": "GPT-4.1の最大トークン数として正しいものはどれか。",
      "options": [
        "50万トークン",
        "100万トークン",
        "200万トークン"
      ],
      "correctAnswer": "100万トークン",
      "explanation": "正解は「100万トークン」です。GPT-4.1は開発者向けの実務モデルとして、最大100万トークンという長コンテキストに対応しています。この数値は、Reasoning系列の特徴を理解する上で重要な具体例です。選択肢1の「50万トークン」や選択肢3の「200万トークン」は、GPT-4.1の実際のトークン数ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "GPT",
          "トークン化"
        ],
        "difficulty": "medium",
        "unitId": "unit32"
      }
    },
    {
      "questionId": "unit_033",
      "question": "2025年に公開されたAIエージェント「Operator」の主な機能として、最も適切なものはどれか。",
      "options": [
        "ユーザーの代わりに会議に出席して発言する。",
        "独自の仮想ブラウザを起動し、予約・購入・フォーム入力などのWeb操作を自律的に代行する。",
        "ソフトウェアのバグを自動的に修正し、GitHubへプルリクエストを送る。",
        "テキストから高品質な動画を生成する。"
      ],
      "correctAnswer": "独自の仮想ブラウザを起動し、予約・購入・フォーム入力などのWeb操作を自律的に代行する。",
      "explanation": "正解は「独自の仮想ブラウザを起動し、予約・購入・フォーム入力などのWeb操作を自律的に代行する」です。Operatorは2025年1月に公開された「ブラウザ操作エージェント」で、Web上のタスク（予約や購入など）を画面を画像として認識し、クリックや入力を自律的に行います。選択肢1の「会議に出席して発言」はOperatorの機能ではありません。選択肢3の「ソフトウェアのバグ修正やGitHubプルリクエスト」は「Codex」の役割です。選択肢4の「テキストから動画生成」は画像生成モデルの機能です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit33"
      }
    },
    {
      "questionId": "unit_034",
      "question": "AIエージェントが、従来のチャットボットと決定的に異なる点は何か。",
      "options": [
        "ユーザーと会話ができる点",
        "自律的に計画を立て、ツールを使用してタスクを実行（行動）できる点",
        "インターネットに接続されている点",
        "スマートフォンで使える点"
      ],
      "correctAnswer": "自律的に計画を立て、ツールを使用してタスクを実行（行動）できる点",
      "explanation": "正解は「自律的に計画を立て、ツールを使用してタスクを実行（行動）できる点」です。AIエージェントは、目標を与えると計画→実行→結果確認→修正を自分で回しながらタスクを完遂します。チャットボットは「会話」が主ですが、エージェントは目標達成のために自律的に「行動（ツール実行、ブラウザ操作など）」する点が決定的な違いです。選択肢1の「会話ができる」、選択肢3の「インターネット接続」、選択肢4の「スマートフォンで使える」は、チャットボットとエージェントの両方に当てはまるため、決定的な違いではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit34"
      }
    },
    {
      "questionId": "unit_035",
      "question": "Codex（開発エージェント）の特徴として正しいものはどれか。",
      "options": [
        "ブラウザ操作を代行する",
        "クラウド上のサンドボックス環境でコードを実行し、テストが通るまで自律的に修正を繰り返す",
        "画像生成に特化している"
      ],
      "correctAnswer": "クラウド上のサンドボックス環境でコードを実行し、テストが通るまで自律的に修正を繰り返す",
      "explanation": "Codexはソフトウェア開発に特化したエージェントで、GitHubのプルリクエスト作成、バグ修正、新機能追加などの開発工程を、クラウド上のサンドボックス環境で繰り返し実行します。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "生成AI",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit35"
      }
    },
    {
      "questionId": "unit_036",
      "question": "Anthropic社が開発する「Claude」シリーズの特徴である、安全性と無害性を最優先する設計思想を何と呼ぶか。",
      "options": [
        "Generative Adversarial Networks (GAN)",
        "Reinforcement Learning from Human Feedback (RLHF)",
        "Constitutional AI (憲法AI)",
        "Chain-of-Thought Prompting"
      ],
      "correctAnswer": "Constitutional AI (憲法AI)",
      "explanation": "正解は「Constitutional AI（憲法AI）」です。Anthropic Claudeは「Constitutional AI（憲法AI）」という独自のアプローチを採用しており、「無害・正直・役に立つ」という原則に基づいてモデルが自己修正を行う仕組みを持っています。これがClaudeの最大の特徴である安全性を最優先する設計思想です。選択肢1の「GAN」は敵対的生成ネットワークの略で、画像生成の技術です。選択肢2の「RLHF」は人間のフィードバックからの強化学習で、アライメントの手法の一つですが、Constitutional AIとは異なります。選択肢4の「Chain-of-Thought」は推論手法であり、Claudeの設計思想ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "GAN",
          "Claude",
          "生成AI",
          "RLHF"
        ],
        "difficulty": "medium",
        "unitId": "unit36"
      }
    },
    {
      "questionId": "unit_037",
      "question": "Google Geminiモデルの最大の特徴は何ですか？",
      "options": [
        "安全性と信頼性",
        "最高速度の応答",
        "ネイティブ・マルチモーダル設計"
      ],
      "correctAnswer": "ネイティブ・マルチモーダル設計",
      "explanation": "正解は「ネイティブ・マルチモーダル設計」です。Google Geminiは最初から画像・音声・テキストを同時に理解する前提で作られたネイティブ・マルチモーダルモデルです。「ネイティブAudioモデル」による低遅延な会話が特徴です。選択肢1の「安全性と信頼性」はAnthropic Claudeの特徴（Constitutional AI）です。選択肢2の「最高速度の応答」はGPT-4o（Omni系列）により明確に特徴として示されているため、Geminiの「最大の特徴」としては適切ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "Gemini",
          "生成AI",
          "マルチモーダル",
          "Claude",
          "GPT"
        ],
        "difficulty": "medium",
        "unitId": "unit37"
      }
    },
    {
      "questionId": "unit_038",
      "question": "Microsoft Copilotの最大の特徴は何ですか？",
      "options": [
        "最高速度の応答",
        "業務アプリへの統合と商用データ保護",
        "最低コストでの利用"
      ],
      "correctAnswer": "業務アプリへの統合と商用データ保護",
      "explanation": "正解は「業務アプリへの統合と商用データ保護」です。Microsoft Copilotは、WordやExcel、Teams、OutlookなどのMicrosoft 365アプリ内で、GPT-5ベースのAIを安全な環境（商用データ保護）で利用できるよう設計されています。これは「仕事の中に自然に溶け込むAI」として設計された、企業利用を強く意識した実務志向の特徴です。選択肢1の「最高速度の応答」はGPT-4o（Omni系列）の特徴です。選択肢3の「最低コストでの利用」はGemini 2.5 Flashなどの特徴ですが、Copilotの「最大の特徴」としては適切ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "unit",
        "tags": [
          "Gemini",
          "生成AI",
          "GPT"
        ],
        "difficulty": "medium",
        "unitId": "unit38"
      }
    },
    {
      "questionId": "unit_039",
      "question": "GPT-4oや最新の画像生成AIにおいて採用が進んでいる「自己回帰型（Autoregressive）」モデルの特徴として、従来の「拡散モデル（Diffusion）」と比較した際の主な利点はどれか。",
      "options": [
        "ノイズを除去するプロセスにより、芸術的な抽象画が生成しやすくなる。",
        "画像をトークン列として左上から処理することで、画像内の文字（看板やロゴなど）を正確に描写・制御しやすくなる。",
        "計算コストが拡散モデルの10倍になるが、画質は変わらない。",
        "静止画しか生成できず、動画生成には応用できない。"
      ],
      "correctAnswer": "画像をトークン列として左上から処理することで、画像内の文字（看板やロゴなど）を正確に描写・制御しやすくなる。",
      "explanation": "正解は選択肢2です。拡散モデルから自己回帰型への転換により、これまで苦手だった「文字の描写」が正確になった点が強調されています。自己回帰型は画像をトークンとして扱い、左上から右下へ順次描画することで、画像内の文字、ロゴ、細かい線、レイアウトの精度が劇的に向上しました。選択肢1は拡散モデルの特徴、選択肢3と4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "トークン化",
          "生成AIの動向",
          "GPT",
          "拡散モデル",
          "自己回帰"
        ],
        "difficulty": "medium",
        "unitId": "unit39"
      }
    },
    {
      "questionId": "unit_040",
      "question": "2025年にGoogle DeepMindが発表した動画生成AI「Veo3」の画期的な特徴として、最も適切なものはどれか。",
      "options": [
        "テキストのみを出力する。",
        "5秒以内の無音動画しか生成できない。",
        "高精細な映像の生成に加え、環境音やセリフなどの音声も一括で合成できる。",
        "著作権フリーの素材のみを使用して生成する。"
      ],
      "correctAnswer": "高精細な映像の生成に加え、環境音やセリフなどの音声も一括で合成できる。",
      "explanation": "正解は選択肢3です。Veo3は映像だけでなく、音声（環境音やセリフ）も含めた統合的な生成が可能であることが特徴です。動画生成AIの進化により、映像と音声を一括で生成できるようになりました。選択肢1、2、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "Gemini",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit40"
      }
    },
    {
      "questionId": "unit_041",
      "question": "テキスト生成AI（LLM）における「自然言語処理（NLP）」の説明として、最も適切なものはどれか。",
      "options": [
        "コンピュータがプログラミング言語を人間の言語に変換する技術。",
        "人間が日常的に使っている言語の曖昧さや複雑さを扱い、理解・生成するための技術の総称。",
        "画像データをテキストデータに変換する技術のみを指す。",
        "音声データを数値データに変換する技術のみを指す。"
      ],
      "correctAnswer": "人間が日常的に使っている言語の曖昧さや複雑さを扱い、理解・生成するための技術の総称。",
      "explanation": "正解は選択肢2です。NLPは人間が使う自然言語をコンピュータが扱うための基盤技術であり、LLMの根幹をなします。コンピュータが日本語や英語などの自然な言葉を理解し、生成するための技術です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit41"
      }
    },
    {
      "questionId": "unit_042",
      "question": "音声生成AIにおいて、特定の人物の画像の口の動きを、生成された音声に同期させる技術を何と呼ぶか。",
      "options": [
        "リップシンク（Lip Sync）",
        "ボイスチェンジャー",
        "マスキング",
        "トークナイゼーション"
      ],
      "correctAnswer": "リップシンク（Lip Sync）",
      "explanation": "正解は選択肢1です。音声生成に加え、口の動きを同期させるリップシンク技術の進化により、バーチャルヒューマンなどの表現力が向上しています。選択肢2の「ボイスチェンジャー」は声質を変える技術、選択肢3の「マスキング」は情報を隠す処理、選択肢4の「トークナイゼーション」はテキストを分割する処理です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit42"
      }
    },
    {
      "questionId": "unit_043",
      "question": "画像生成AIの学習手法として知られる「VAE（変分自己符号化器）」の構成要素である「エンコーダ」の役割はどれか。",
      "options": [
        "ノイズから画像を生成する。",
        "生成された画像が本物かどうかを識別する。",
        "入力データを「潜在ベクトル（データの特徴を要約した情報）」という低次元の表現に変換する。",
        "潜在ベクトルから元の画像を復元する。"
      ],
      "correctAnswer": "入力データを「潜在ベクトル（データの特徴を要約した情報）」という低次元の表現に変換する。",
      "explanation": "正解は選択肢3です。VAEはエンコーダ（特徴を抽出して圧縮）とデコーダ（復元）で構成されます。エンコーダは入力データを潜在ベクトルに変換します。選択肢1は拡散モデルの特徴、選択肢2はGANの識別器の役割、選択肢4はデコーダの役割です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "GAN",
          "VAE",
          "拡散モデル",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit43"
      }
    },
    {
      "questionId": "unit_044",
      "question": "ディープフェイク技術が悪用された事例として、2023年に発生し、米国株式市場（ダウ平均株価）の一時的な下落を引き起こした事件の内容はどれか。",
      "options": [
        "有名俳優が選挙に立候補したという偽動画。",
        "アメリカ国防総省（ペンタゴン）近くで爆発があったとする偽画像。",
        "ある企業のCEOが辞任するという偽音声。",
        "火星に宇宙人がいるという偽ニュース。"
      ],
      "correctAnswer": "アメリカ国防総省（ペンタゴン）近くで爆発があったとする偽画像。",
      "explanation": "正解は選択肢2です。ペンタゴン爆発の偽画像がSNSで拡散され、金融市場に混乱を与えた事例は、AI生成物の社会的リスクとして重要です。この事件は、ディープフェイク技術が金融市場に与える影響を示す具体例として知られています。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "リスク管理",
          "ディープフェイク",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit44"
      }
    },
    {
      "questionId": "unit_045",
      "question": "イギリスの企業で発生した「ディープフェイクボイス詐欺」の手口として、正しいものはどれか。",
      "options": [
        "取引先の担当者になりすましたメールを送りつけた。",
        "音声生成AIを用いて親会社のCEOの声を模倣し、電話で巨額の送金を指示した。",
        "無言電話を繰り返して業務を妨害した。",
        "社内会議の議事録を改ざんした。"
      ],
      "correctAnswer": "音声生成AIを用いて親会社のCEOの声を模倣し、電話で巨額の送金を指示した。",
      "explanation": "正解は選択肢2です。音声生成AIの悪用により、信頼できる人物の声（CEOや取引先）を模倣して金銭を騙し取る詐欺が発生しています。このようなディープフェイクボイス詐欺は、オレオレ詐欺の高度化版として深刻な問題となっています。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "ディープフェイク",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit45"
      }
    },
    {
      "questionId": "unit_046",
      "question": "ディープフェイク（Deepfake）の定義として、最も適切な記述はどれか。",
      "options": [
        "AIが作成した芸術的な絵画のこと。",
        "ディープラーニング等を利用して、実在しない人物や実際には行っていない言動を含む、真偽の識別が困難な合成コンテンツを作成する技術。",
        "検索エンジンの検索結果を偽装する技術。",
        "コンピュータウイルスの別名。"
      ],
      "correctAnswer": "ディープラーニング等を利用して、実在しない人物や実際には行っていない言動を含む、真偽の識別が困難な合成コンテンツを作成する技術。",
      "explanation": "正解は選択肢2です。ディープフェイクは、ディープラーニングを用いて人の顔や声、映像を本物のように合成する技術です。人を欺く目的で使用されることが多く、真偽不明な合成メディアを作成する技術を指します。画像、音声、動画すべてが対象となり、現実と見分けがつかないレベルまで精度が向上しています。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "ディープラーニング",
          "ディープフェイク",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit46"
      }
    },
    {
      "questionId": "unit_047",
      "question": "生成AIにおける「ナレッジカットオフ」の問題を解決するために用いられる、RAG（検索拡張生成）の基本的な動作原理はどれか。",
      "options": [
        "モデルのパラメータ数を無限に増やす。",
        "質問に対して、まず外部データベースから関連情報を「検索（Retrieve）」し、その情報を基に回答を「生成（Generate）」する。",
        "毎日すべてのデータを再学習（ファインチューニング）し続ける。",
        "インターネット接続を遮断して、内部知識のみで回答させる。"
      ],
      "correctAnswer": "質問に対して、まず外部データベースから関連情報を「検索（Retrieve）」し、その情報を基に回答を「生成（Generate）」する。",
      "explanation": "正解は選択肢2です。RAGは「検索（Retrieval）」と「生成（Generation）」を組み合わせることで、学習データに含まれない最新情報や社内情報に対応します。通常の生成AIは学習時点までの知識しか持たず、最新情報や社内文書などの外部データに直接アクセスできませんが、RAGはこの課題を解決します。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "ナレッジカットオフ",
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit47"
      }
    },
    {
      "questionId": "unit_048",
      "question": "RAGシステムを構築する際、検索精度を高めるために長い文書を意味のまとまりごとに分割する処理を何と呼ぶか。",
      "options": [
        "チャンク分割（Chunking）",
        "スクレイピング",
        "プロンプトエンジニアリング",
        "バイアス除去"
      ],
      "correctAnswer": "チャンク分割（Chunking）",
      "explanation": "正解は選択肢1です。文書を適切なサイズ（チャンク）に分割し、ベクトル化して保存することがRAGの精度向上に不可欠です。長い文書をそのまま扱うと検索精度が下がるため、意味のまとまりごとに分割することで、関連する情報を正確に検索できるようになります。選択肢2の「スクレイピング」はWebページからデータを抽出する技術、選択肢3の「プロンプトエンジニアリング」はプロンプトを最適化する技術、選択肢4の「バイアス除去」はデータの偏りを減らす処理です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "チャンク分割",
          "プロンプト",
          "生成AIの動向",
          "RAG",
          "エンベッディング",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": "unit48"
      }
    },
    {
      "questionId": "unit_049",
      "question": "文書や質問の意味的な類似性を計算するために、RAGシステムにおいてテキストデータを数値の列に変換する処理を何と呼ぶか。",
      "options": [
        "暗号化",
        "圧縮",
        "ベクトル化（エンベッディング）",
        "翻訳"
      ],
      "correctAnswer": "ベクトル化（エンベッディング）",
      "explanation": "正解は選択肢3です。コンピュータが意味の近さを計算できるように、テキストを多次元の数値ベクトルに変換することをエンベッディングと呼びます。これにより、意味的に似た文書や質問を検索できるようになります。選択肢1の「暗号化」は情報を秘匿する処理、選択肢2の「圧縮」はデータサイズを減らす処理、選択肢4の「翻訳」は言語を変換する処理です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "エンベッディング",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit49"
      }
    },
    {
      "questionId": "unit_050",
      "question": "従来のファインチューニング（追加学習）と比較した際の、RAGのメリットとして誤っているものはどれか。",
      "options": [
        "データの更新が容易である（データベースに追加するだけでよい）。",
        "回答の根拠（出典）を明示しやすい。",
        "ハルシネーション（もっともらしい嘘）を完全にゼロにできる。",
        "再学習にかかる膨大なコストや時間を削減できる。"
      ],
      "correctAnswer": "ハルシネーション（もっともらしい嘘）を完全にゼロにできる。",
      "explanation": "正解は選択肢3です。RAGはハルシネーションを「低減」しますが、「完全にゼロ」にすることはできません。他の選択肢はRAGの明確なメリットです。選択肢1は、RAGではデータベースに情報を追加するだけで知識を更新できるため、再学習が不要です。選択肢2は、RAGでは検索した情報を根拠として提示できるため、回答の信頼性が高まります。選択肢4は、再学習にかかるコストや時間を削減できる点がRAGの大きなメリットです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "ハルシネーション",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit50"
      }
    },
    {
      "questionId": "unit_051",
      "question": "企業内でRAGを活用するユースケースとして、最も適切なものはどれか。",
      "options": [
        "社内マニュアルや過去のトラブル事例を検索対象とし、新人オペレーターの質問に即座に回答させる。",
        "一般的な雑談相手として利用する。",
        "競合他社の機密情報を違法に収集させる。",
        "社内のPCのパスワードを強制的に解除させる。"
      ],
      "correctAnswer": "社内マニュアルや過去のトラブル事例を検索対象とし、新人オペレーターの質問に即座に回答させる。",
      "explanation": "正解は選択肢1です。企業固有の知識（社内規定、マニュアル、過去事例）に基づいた回答生成は、RAGの最も代表的な活用例です。社内ナレッジ検索、FAQ自動応答、法務・医療文書検索、カスタマーサポート支援など、業務システムとの親和性が非常に高い技術です。選択肢2は一般的な用途でRAGの特徴を活かせません。選択肢3、4は違法または不適切な用途です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit51"
      }
    },
    {
      "questionId": "unit_052",
      "question": "2020年にRAGの概念を提唱した論文を発表した組織はどこか。",
      "options": [
        "OpenAI",
        "Google DeepMind",
        "Facebook AI Research (現Meta AI)",
        "Apple"
      ],
      "correctAnswer": "Facebook AI Research (現Meta AI)",
      "explanation": "正解は選択肢3です。2020年にFacebook AI ResearchのPatrick LewisらのチームがRAGの概念を正式に提案しました。RAGは第4版テキストの最重要項目の一つであり、生成AIの弱点である情報の古さや誤情報（ハルシネーション）を補うために開発された技術です。選択肢1、2、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "ハルシネーション",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit52"
      }
    },
    {
      "questionId": "unit_053",
      "question": "第4版テキストにおける「AIエージェント」の定義として、従来のチャットボットと決定的に異なる特徴はどれか。",
      "options": [
        "音声で会話ができる点。",
        "感情を持っている点。",
        "目標を与えられると、自律的に「計画→行動→評価」のループを回し、ツールを使用してタスクを完遂しようとする点。",
        "常にインターネットから切断されている点。"
      ],
      "correctAnswer": "目標を与えられると、自律的に「計画→行動→評価」のループを回し、ツールを使用してタスクを完遂しようとする点。",
      "explanation": "正解は選択肢3です。単なる応答（Chat）ではなく、自律的に計画し行動（Action）する点がエージェントの本質です。AIエージェントは、与えられた目標を達成するために、自分で考え、行動し、結果を見て評価しながら作業を進めるAIシステムです。チャットボットが「会話」が主なのに対し、エージェントは目標達成のために自律的に「行動（ツール実行、ブラウザ操作など）」する点が特徴です。選択肢1、2、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit53"
      }
    },
    {
      "questionId": "unit_054",
      "question": "Anthropic社が提唱している、AIモデルと外部ツール（データベースやAPI）を接続するためのオープンな標準規格であり、「AI版のUSB」とも例えられる技術は何か。",
      "options": [
        "API Gateway",
        "MCP (Model Context Protocol)",
        "SQL",
        "RESTful API"
      ],
      "correctAnswer": "MCP (Model Context Protocol)",
      "explanation": "正解は選択肢2です。MCPは、LLMと外部ツールを安全かつ標準的に接続するためのプロトコルで、個別のコネクタ開発を不要にする「AI版USB」です。これにより、AIエージェントが様々な外部ツールと連携しやすくなります。選択肢1の「API Gateway」はAPIの管理システム、選択肢3の「SQL」はデータベース言語、選択肢4の「RESTful API」はWeb APIの設計方式です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "MCP",
          "Claude",
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit54"
      }
    },
    {
      "questionId": "unit_078",
      "question": "AIエージェントの実装アプローチのうち、「ワークフロー型」の説明として適切なものはどれか。",
      "options": [
        "最終目標だけを与えれば、AIが勝手に手順を考えて実行する。",
        "あらかじめ定義された業務フロー（手順や分岐）に従って、LLMがタスクを実行する。RPAに近い考え方。",
        "完全にランダムに行動する。",
        "常に人間が操作する必要がある。"
      ],
      "correctAnswer": "あらかじめ定義された業務フロー（手順や分岐）に従って、LLMがタスクを実行する。RPAに近い考え方。",
      "explanation": "正解は選択肢2です。エージェントには「ワークフロー型（手順固定）」と「自律型（目標のみ指定）」があり、前者は定型業務の自動化に向いています。ワークフロー型は、決まった手順に従ってタスクを実行するため、RPA（Robotic Process Automation）に近い考え方です。選択肢1は自律型の説明、選択肢3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit78"
      }
    },
    {
      "questionId": "unit_056",
      "question": "シンガポール発のAIエージェント「Manus」の特徴として紹介されている機能はどれか。",
      "options": [
        "多数の履歴書を分析し、評価結果をExcelにまとめるなどの複雑な事務処理を、人手を介さず全自動で遂行する。",
        "ゲームをプレイする。",
        "天気予報のみを行う。",
        "画像生成のみを行う。"
      ],
      "correctAnswer": "多数の履歴書を分析し、評価結果をExcelにまとめるなどの複雑な事務処理を、人手を介さず全自動で遂行する。",
      "explanation": "正解は選択肢1です。Manusは汎用エージェントとして、複雑なオンライン業務や事務処理の全自動化が可能とされています。AIエージェントは、単発の質問に答える生成AIとは異なり、複数の工程を連続的に処理できる点が特徴です。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit56"
      }
    },
    {
      "questionId": "unit_057",
      "question": "AIエージェントが外部ツールを実行したり情報を取得したりするために必要な、拡張LLMの3つの機能要素は「検索(Retrieval)」「メモリ(Memory)」ともう一つは何か。",
      "options": [
        "ツール呼び出し（Tool Use）",
        "画像認識",
        "音声合成",
        "感情分析"
      ],
      "correctAnswer": "ツール呼び出し（Tool Use）",
      "explanation": "正解は選択肢1です。エージェントが行動するためには、外部の機能を実行するための「ツール呼び出し（Tool Use）」機能が不可欠です。AIエージェントは、検索エンジン、データベース、ブラウザ操作、業務システムなどと連携し、情報取得から処理、実行までを一貫して自動化できます。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit57"
      }
    },
    {
      "questionId": "unit_058",
      "question": "生成AIが扱う「モダリティ」とは何を指すか。",
      "options": [
        "AIモデルのパラメータ数のこと。",
        "データの種類や形式（テキスト、画像、音声、動画など）のこと。",
        "AIの学習速度のこと。",
        "AIの応答時間のこと。"
      ],
      "correctAnswer": "データの種類や形式（テキスト、画像、音声、動画など）のこと。",
      "explanation": "正解は選択肢2です。モダリティとは、生成AIが扱うデータの種類や形式を指します。テキスト、画像、音声、動画など、異なる形式のデータを生成AIは処理・生成できます。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit58"
      }
    },
    {
      "questionId": "unit_059",
      "question": "画像生成AIにおいて、「拡散モデル（Diffusion Model）」の基本的な動作原理として最も適切なものはどれか。",
      "options": [
        "ノイズから画像を段階的に生成する。",
        "既存の画像をコピーするだけである。",
        "テキストのみを生成する。",
        "音声を生成する。"
      ],
      "correctAnswer": "ノイズから画像を段階的に生成する。",
      "explanation": "正解は選択肢1です。拡散モデルは、ランダムなノイズから始めて、段階的にノイズを除去しながら画像を生成する手法です。これにより、高品質な画像を生成できます。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "拡散モデル",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit59"
      }
    },
    {
      "questionId": "unit_060",
      "question": "音声生成AIの主な用途として、最も適切でないものはどれか。",
      "options": [
        "バーチャルアシスタントの音声合成",
        "多言語の音声翻訳",
        "画像の生成",
        "オーディオブックの自動生成"
      ],
      "correctAnswer": "画像の生成",
      "explanation": "正解は選択肢3です。音声生成AIは音声を生成する技術であり、画像の生成は画像生成AIの役割です。選択肢1、2、4は音声生成AIの適切な用途です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit60"
      }
    },
    {
      "questionId": "unit_061",
      "question": "動画生成AIの技術的な課題として、最も適切なものはどれか。",
      "options": [
        "動画の時間的な一貫性を保つことが難しい。",
        "静止画しか生成できない。",
        "音声のみを生成できる。",
        "テキストのみを生成できる。"
      ],
      "correctAnswer": "動画の時間的な一貫性を保つことが難しい。",
      "explanation": "正解は選択肢1です。動画生成では、フレーム間の時間的な一貫性を保つことが技術的な課題となっています。動画は複数のフレームが連続して構成されるため、各フレーム間の自然なつながりを実現することが重要です。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit61"
      }
    },
    {
      "questionId": "unit_062",
      "question": "ディープフェイク技術が社会的に問題視される主な理由として、最も適切なものはどれか。",
      "options": [
        "計算コストが高いため。",
        "実在する人物の顔や声を模倣し、真偽の識別が困難な合成コンテンツを作成できるため。",
        "画像の解像度が低いため。",
        "音声の品質が悪いため。"
      ],
      "correctAnswer": "実在する人物の顔や声を模倣し、真偽の識別が困難な合成コンテンツを作成できるため。",
      "explanation": "正解は選択肢2です。ディープフェイク技術は、実在する人物の顔や声を本物のように合成できるため、詐欺や情報操作に悪用されるリスクがあります。真偽の識別が困難であることが最大の問題です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "リスク管理",
          "ディープフェイク",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit62"
      }
    },
    {
      "questionId": "unit_063",
      "question": "ディープフェイクを検出するための対策として、最も適切なものはどれか。",
      "options": [
        "AIによる自動検出システムの開発",
        "ディープフェイクの使用を完全に禁止する",
        "インターネットの使用を禁止する",
        "画像や動画の共有を禁止する"
      ],
      "correctAnswer": "AIによる自動検出システムの開発",
      "explanation": "正解は選択肢1です。ディープフェイクに対抗するため、AI技術を用いた自動検出システムの開発が進められています。技術的な対策と、情報リテラシーの向上の両面から対応が求められています。選択肢2、3、4は現実的ではありません。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "情報リテラシー",
          "ディープフェイク",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit63"
      }
    },
    {
      "questionId": "unit_064",
      "question": "RAGシステムにおいて、「検索（Retrieval）」の段階で行われる処理として、最も適切なものはどれか。",
      "options": [
        "質問に対して、外部データベースから関連する情報を探し出す。",
        "回答を生成する。",
        "モデルを再学習する。",
        "画像を生成する。"
      ],
      "correctAnswer": "質問に対して、外部データベースから関連する情報を探し出す。",
      "explanation": "正解は選択肢1です。RAGの「Retrieval（検索）」段階では、ユーザーの質問に対して、外部データベースや文書から関連する情報を検索します。その後、検索した情報を基に回答を生成します。選択肢2は「Generation（生成）」段階、選択肢3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit64"
      }
    },
    {
      "questionId": "unit_065",
      "question": "RAGシステムの「生成（Generation）」段階において、検索した情報をどのように活用するか。",
      "options": [
        "検索した情報を無視して回答を生成する。",
        "検索した情報をコンテキストとして与え、その情報を基に回答を生成する。",
        "検索した情報を削除する。",
        "検索した情報を画像に変換する。"
      ],
      "correctAnswer": "検索した情報をコンテキストとして与え、その情報を基に回答を生成する。",
      "explanation": "正解は選択肢2です。RAGの「Generation（生成）」段階では、検索で取得した情報をコンテキストとしてLLMに与え、その情報を基に回答を生成します。これにより、学習データに含まれない最新情報や社内情報に基づいた回答が可能になります。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit65"
      }
    },
    {
      "questionId": "unit_066",
      "question": "RAGシステムを構築する際、ベクトルデータベース（Vector Database）を使用する主な理由として、最も適切なものはどれか。",
      "options": [
        "意味的に類似した文書を高速に検索するため。",
        "画像を保存するため。",
        "音声を保存するため。",
        "動画を保存するため。"
      ],
      "correctAnswer": "意味的に類似した文書を高速に検索するため。",
      "explanation": "正解は選択肢1です。ベクトルデータベースは、文書をベクトル化して保存し、意味的に類似した文書を高速に検索するために使用されます。これにより、RAGシステムの検索精度と速度が向上します。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "エンベッディング",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit66"
      }
    },
    {
      "questionId": "unit_067",
      "question": "RAGシステムにおいて、「グラウンディング（Grounding）」とは何を指すか。",
      "options": [
        "回答の根拠となる情報源（ソース）を明示すること。",
        "AIモデルを地面に設置すること。",
        "画像を生成すること。",
        "音声を生成すること。"
      ],
      "correctAnswer": "回答の根拠となる情報源（ソース）を明示すること。",
      "explanation": "正解は選択肢1です。グラウンディングとは、生成AIの回答がどの情報源に基づいているかを明示することで、回答の信頼性を高める手法です。RAGシステムでは、検索した文書の出典を提示することで、ユーザーが回答の根拠を確認できます。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "グラウンディング",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit67"
      }
    },
    {
      "questionId": "unit_068",
      "question": "AIエージェントの「自律型」アプローチの特徴として、最も適切なものはどれか。",
      "options": [
        "最終目標だけを与えれば、AIが自ら手順を考えて実行する。",
        "あらかじめ定義された手順に従ってのみ実行する。",
        "常に人間が操作する必要がある。",
        "ランダムに行動する。"
      ],
      "correctAnswer": "最終目標だけを与えれば、AIが自ら手順を考えて実行する。",
      "explanation": "正解は選択肢1です。自律型エージェントは、最終目標だけを与えられると、自ら計画を立て、実行し、評価しながらタスクを完遂します。これに対し、ワークフロー型はあらかじめ定義された手順に従います。選択肢2はワークフロー型の説明、選択肢3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit68"
      }
    },
    {
      "questionId": "unit_069",
      "question": "AIエージェントが「計画→行動→評価」のループを回す際、「評価」段階で行われる処理として、最も適切なものはどれか。",
      "options": [
        "実行結果を確認し、目標達成度を判断し、必要に応じて計画を修正する。",
        "画像を生成する。",
        "音声を生成する。",
        "動画を生成する。"
      ],
      "correctAnswer": "実行結果を確認し、目標達成度を判断し、必要に応じて計画を修正する。",
      "explanation": "正解は選択肢1です。AIエージェントの「評価」段階では、実行した結果を確認し、目標にどれだけ近づいたかを判断します。目標が達成されていない場合は、計画を見直して再度実行します。このループを繰り返すことで、タスクを完遂します。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit69"
      }
    },
    {
      "questionId": "unit_070",
      "question": "AIエージェントが外部ツールを使用する際の「ツール呼び出し（Tool Use）」の説明として、最も適切なものはどれか。",
      "options": [
        "検索エンジン、データベース、ブラウザ操作などの外部機能を実行する機能。",
        "画像を生成する機能。",
        "音声を生成する機能。",
        "動画を生成する機能。"
      ],
      "correctAnswer": "検索エンジン、データベース、ブラウザ操作などの外部機能を実行する機能。",
      "explanation": "正解は選択肢1です。ツール呼び出し（Tool Use）は、AIエージェントが外部の機能やサービスを実行するための機能です。検索エンジンで情報を取得したり、データベースにアクセスしたり、ブラウザを操作したりすることで、タスクを完遂します。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit70"
      }
    },
    {
      "questionId": "unit_071",
      "question": "AIエージェントの「メモリ（Memory）」機能の役割として、最も適切なものはどれか。",
      "options": [
        "過去の会話履歴や実行結果を記憶し、文脈を保持する機能。",
        "画像を保存する機能。",
        "音声を保存する機能。",
        "動画を保存する機能。"
      ],
      "correctAnswer": "過去の会話履歴や実行結果を記憶し、文脈を保持する機能。",
      "explanation": "正解は選択肢1です。AIエージェントのメモリ機能は、過去の会話履歴や実行結果を記憶し、文脈を保持することで、一貫性のある行動を可能にします。これにより、長期的なタスクや複数のステップを要するタスクを実行できます。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit71"
      }
    },
    {
      "questionId": "unit_072",
      "question": "マルチモーダル生成AIの特徴として、最も適切なものはどれか。",
      "options": [
        "テキスト、画像、音声など、複数の形式のデータを同時に理解・生成できる。",
        "テキストのみを生成できる。",
        "画像のみを生成できる。",
        "音声のみを生成できる。"
      ],
      "correctAnswer": "テキスト、画像、音声など、複数の形式のデータを同時に理解・生成できる。",
      "explanation": "正解は選択肢1です。マルチモーダル生成AIは、テキスト、画像、音声、動画など、複数の形式のデータを同時に理解し、生成できるAIです。これにより、より自然で統合的な対話やタスク実行が可能になります。選択肢2、3、4は単一モダリティの説明です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "マルチモーダル",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit72"
      }
    },
    {
      "questionId": "unit_073",
      "question": "生成AIにおける「ナレッジカットオフ」の問題とは何か。",
      "options": [
        "AIの学習時点以降の最新情報や、学習データに含まれていない情報に対応できない問題。",
        "AIが情報を削除する問題。",
        "AIが画像を生成できない問題。",
        "AIが音声を生成できない問題。"
      ],
      "correctAnswer": "AIの学習時点以降の最新情報や、学習データに含まれていない情報に対応できない問題。",
      "explanation": "正解は選択肢1です。ナレッジカットオフとは、生成AIが学習時点までの情報しか持たず、その後の最新情報や学習データに含まれていない情報（例：社内文書）に対応できない問題です。RAGはこの問題を解決する技術です。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "ナレッジカットオフ",
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit73"
      }
    },
    {
      "questionId": "unit_074",
      "question": "RAGシステムにおいて、チャンク分割（Chunking）を行う際の適切なサイズの目安として考慮すべき要素として、最も適切でないものはどれか。",
      "options": [
        "文書の意味的なまとまりを保つこと。",
        "検索精度と処理速度のバランスを取ること。",
        "チャンクサイズを無限に大きくすること。",
        "文脈が失われないようにすること。"
      ],
      "correctAnswer": "チャンクサイズを無限に大きくすること。",
      "explanation": "正解は選択肢3です。チャンク分割では、文書を適切なサイズに分割することが重要です。大きすぎると検索精度が下がり、小さすぎると文脈が失われます。意味的なまとまりを保ちながら、検索精度と処理速度のバランスを取ることが重要です。選択肢1、2、4は適切な考慮事項です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "チャンク分割",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit74"
      }
    },
    {
      "questionId": "unit_075",
      "question": "AIエージェントと従来の自動化システム（RPAなど）の主な違いとして、最も適切なものはどれか。",
      "options": [
        "AIエージェントは状況に応じて柔軟に対応できるが、RPAは決められた手順に従う。",
        "RPAは柔軟に対応できるが、AIエージェントは決められた手順に従う。",
        "両者に違いはない。",
        "AIエージェントは画像のみを生成する。"
      ],
      "correctAnswer": "AIエージェントは状況に応じて柔軟に対応できるが、RPAは決められた手順に従う。",
      "explanation": "正解は選択肢1です。AIエージェントは、状況に応じて柔軟に判断し、計画を修正しながらタスクを実行できます。一方、RPA（Robotic Process Automation）は、あらかじめ定義された手順に従って実行する自動化システムです。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": "unit75"
      }
    },
    {
      "questionId": "unit_076",
      "question": "生成AIの活用において、「ハルシネーション（Hallucination）」とは何を指すか。",
      "options": [
        "AIが事実に基づかない、もっともらしい誤った情報を生成すること。",
        "AIが画像を生成すること。",
        "AIが音声を生成すること。",
        "AIが動画を生成すること。"
      ],
      "correctAnswer": "AIが事実に基づかない、もっともらしい誤った情報を生成すること。",
      "explanation": "正解は選択肢1です。ハルシネーションとは、生成AIが事実に基づかない、しかし一見正しそうに見える誤った情報を生成する現象です。RAGやグラウンディングなどの技術により、ハルシネーションを低減することができます。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "ハルシネーション",
          "生成AIの動向",
          "グラウンディング"
        ],
        "difficulty": "medium",
        "unitId": "unit76"
      }
    },
    {
      "questionId": "unit_077",
      "question": "生成AIの実務活用において、RAGシステムが特に有効な場面として、最も適切なものはどれか。",
      "options": [
        "社内のマニュアルや過去の事例に基づいた質問応答システム。",
        "一般的な雑談のみを行うシステム。",
        "画像のみを生成するシステム。",
        "音声のみを生成するシステム。"
      ],
      "correctAnswer": "社内のマニュアルや過去の事例に基づいた質問応答システム。",
      "explanation": "正解は選択肢1です。RAGシステムは、社内のマニュアル、過去の事例、専門文書など、特定の知識ベースに基づいた質問応答システムに特に有効です。これにより、学習データに含まれていない社内情報に基づいた回答が可能になります。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "unit",
        "tags": [
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": "unit77"
      }
    },
    {
      "questionId": "unit_078",
      "question": "攻撃者が緊急性や権威を装い、人間の心理的な隙や行動のミスにつけ込んで機密情報を盗み出す攻撃手法を何と呼ぶか。",
      "options": [
        "SQLインジェクション",
        "ソーシャルエンジニアリング",
        "DDoS攻撃",
        "ゼロデイ攻撃"
      ],
      "correctAnswer": "ソーシャルエンジニアリング",
      "explanation": "正解は「ソーシャルエンジニアリング」です。技術的な脆弱性ではなく、人間の心理（焦りや恐怖など）を利用して情報を盗む手法です。AIによるなりすましもこの一種として警戒が必要です。選択肢1の「SQLインジェクション」はデータベースへの不正なSQL文の挿入、選択肢3の「DDoS攻撃」は大量のトラフィックを送りつける攻撃、選択肢4の「ゼロデイ攻撃」は未知の脆弱性を突く攻撃です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": "unit78"
      }
    },
    {
      "questionId": "unit_079",
      "question": "生成AI技術の悪用により、実在する人物の声色や話し方をAIで模倣し、電話で金銭を騙し取る詐欺手法として、テキストで紹介されている事例はどれか。",
      "options": [
        "ワンクリック詐欺",
        "ディープフェイクボイス詐欺（オレオレ詐欺の高度化）",
        "ランサムウェア攻撃",
        "クロスサイトスクリプティング"
      ],
      "correctAnswer": "ディープフェイクボイス詐欺（オレオレ詐欺の高度化）",
      "explanation": "正解は「ディープフェイクボイス詐欺（オレオレ詐欺の高度化）」です。AIによる音声合成（音声クローン）技術が悪用され、親族や取引先になりすます詐欺が発生しています。生成AI技術の悪用により、実在する人物の声色や話し方をAIで模倣し、電話で金銭を騙し取る手法です。選択肢1の「ワンクリック詐欺」はクリックだけで料金が発生する詐欺、選択肢3の「ランサムウェア攻撃」はデータを暗号化して身代金を要求する攻撃、選択肢4の「クロスサイトスクリプティング」はWebサイトへのスクリプト注入攻撃です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "セキュリティ",
          "法律・倫理",
          "ディープフェイク"
        ],
        "difficulty": "medium",
        "unitId": "unit79"
      }
    },
    {
      "questionId": "unit_080",
      "question": "フィッシング詐欺への対策として、組織内で実施すべき「技術的対策」と「人的対策」の組み合わせとして最も適切なものはどれか。",
      "options": [
        "パスワードを紙に書いて貼る・全員で共有する",
        "多要素認証（MFA）の導入・不審なメールを見抜くための疑似訓練",
        "ウイルス対策ソフトをアンインストールする・全てのリンクをクリックする",
        "社外との通信を全て遮断する・パソコンを使わない"
      ],
      "correctAnswer": "多要素認証（MFA）の導入・不審なメールを見抜くための疑似訓練",
      "explanation": "正解は「多要素認証（MFA）の導入・不審なメールを見抜くための疑似訓練」です。システム側での多要素認証（MFA）と、人間側でのリテラシー向上（訓練）の両輪が不可欠です。技術的対策と人的対策を組み合わせることで、フィッシング詐欺への防御が強化されます。選択肢1、3、4は不適切な対策です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "情報リテラシー",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit80"
      }
    },
    {
      "questionId": "unit_081",
      "question": "公衆Wi-Fi（フリーWi-Fi）を利用する際のリスクと対策として、適切な記述はどれか。",
      "options": [
        "パスワードがかかっていれば絶対に安全である。",
        "攻撃者が設置した偽のアクセスポイント（なりすましWi-Fi）に接続すると、通信内容を盗聴される恐れがあるため、VPNの利用や機密情報の入力を避ける対策が必要である。",
        "スマートフォンの「Wi-Fi自動接続」は常にオンにしておくべきである。",
        "Wi-Fi経由ではウイルスには感染しない。"
      ],
      "correctAnswer": "攻撃者が設置した偽のアクセスポイント（なりすましWi-Fi）に接続すると、通信内容を盗聴される恐れがあるため、VPNの利用や機密情報の入力を避ける対策が必要である。",
      "explanation": "正解は選択肢2です。正規のWi-Fiに見せかけた罠（Evil Twin）が存在するため、自動接続をオフにし、VPNを利用する等の対策が推奨されます。公衆Wi-Fiを利用する際は、偽のアクセスポイントに接続されないよう注意し、VPNの利用や機密情報の入力を避けることが重要です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit81"
      }
    },
    {
      "questionId": "unit_082",
      "question": "個人情報保護法において、本人の人種、信条、社会的身分、病歴、犯罪歴など、不当な差別や偏見が生じる可能性があるため、取得にあたって原則として本人の同意が必要な情報を何と呼ぶか。",
      "options": [
        "機微情報（センシティブ情報）",
        "特定個人情報",
        "要配慮個人情報",
        "基本個人情報"
      ],
      "correctAnswer": "要配慮個人情報",
      "explanation": "正解は「要配慮個人情報」です。法令上の用語は「要配慮個人情報」です。「機微情報」は金融ガイドライン等で使われるより広い概念ですが、法の定義としては要配慮個人情報が正解です。人種、信条、社会的身分、病歴、犯罪歴など、差別や不利益につながる可能性が高い情報です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "AIガバナンス",
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit82"
      }
    },
    {
      "questionId": "unit_083",
      "question": "AIサービスを利用する際、入力したデータがAIモデルの学習に再利用されないようにするために行うべき設定や手続きを何と呼ぶか。",
      "options": [
        "オプトイン",
        "オプトアウト",
        "サインアップ",
        "バックアップ"
      ],
      "correctAnswer": "オプトアウト",
      "explanation": "正解は「オプトアウト」です。「学習利用を拒否する（利用させない）」意思表示や設定をオプトアウトと呼びます。企業利用では必須の確認事項です。選択肢1の「オプトイン」は同意を得て利用する方式、選択肢3の「サインアップ」はサービスへの登録、選択肢4の「バックアップ」はデータの複製保存です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit83"
      }
    },
    {
      "questionId": "unit_084",
      "question": "「匿名加工情報」の定義として、正しい記述はどれか。",
      "options": [
        "特定の個人を識別できないように加工し、かつ、元の個人情報を復元できないようにした情報。",
        "名前だけを黒塗りにした情報（他の記述から特定できてもよい）。",
        "暗号化して保存した個人情報。",
        "特定の個人を識別できるが、外部には漏らさない情報。"
      ],
      "correctAnswer": "特定の個人を識別できないように加工し、かつ、元の個人情報を復元できないようにした情報。",
      "explanation": "正解は選択肢1です。単なるマスキングではなく、特定の個人を識別できず、かつ「復元も不可能」な状態に加工した情報を指します。匿名加工情報は、特定の個人を識別できないように加工し、かつ、元の個人情報を復元できないようにした情報です。選択肢2は単なるマスキング、選択肢3は暗号化（復号可能）、選択肢4は識別可能な情報なので誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit84"
      }
    },
    {
      "questionId": "unit_085",
      "question": "改正個人情報保護法において、個人情報を取り扱う事業者の対象範囲はどう変化したか。",
      "options": [
        "大企業のみが対象となった。",
        "5,000人以上の個人情報を保有する事業者のみが対象となった。",
        "取り扱う個人情報の数に関わらず、全ての個人情報取扱事業者が法の適用対象となった。",
        "AIを利用する企業のみが対象となった。"
      ],
      "correctAnswer": "取り扱う個人情報の数に関わらず、全ての個人情報取扱事業者が法の適用対象となった。",
      "explanation": "正解は選択肢3です。かつての「5,000人要件」は撤廃され、小規模事業者や個人事業主を含むすべての事業者が法の適用対象となっています。改正個人情報保護法において、個人情報を取り扱う事業者の対象範囲は、取り扱う個人情報の数に関わらず、全ての個人情報取扱事業者が法の適用対象となりました。選択肢1、2、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit85"
      }
    },
    {
      "questionId": "unit_086",
      "question": "金融分野のガイドラインにおける「機微（センシティブ）情報」の取り扱いとして、適切なものはどれか。",
      "options": [
        "自由に売買できる。",
        "要配慮個人情報に加え、労働組合への加盟や性生活なども含み、原則として取得・利用・第三者提供が禁止されている。",
        "本人の同意がなくても自由にWebで公開できる。",
        "社内であれば自由に共有できる。"
      ],
      "correctAnswer": "要配慮個人情報に加え、労働組合への加盟や性生活なども含み、原則として取得・利用・第三者提供が禁止されている。",
      "explanation": "正解は選択肢2です。金融分野では「機微情報」として、要配慮個人情報よりも広い範囲（労組加盟など）を含み、原則取得禁止という厳しい制限があります。金融分野のガイドラインにおける「機微（センシティブ）情報」は、要配慮個人情報に加え、労働組合への加盟や性生活なども含み、原則として取得・利用・第三者提供が禁止されています。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "AIガバナンス",
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit86"
      }
    },
    {
      "questionId": "unit_087",
      "question": "他人の著作物の権利を侵害している（著作権侵害）と判断されるために必要な2つの要件は、「類似性」ともう一つは何か。",
      "options": [
        "独創性",
        "依拠性（いきょせい）",
        "商業性",
        "芸術性"
      ],
      "correctAnswer": "依拠性（いきょせい）",
      "explanation": "正解は「依拠性（いきょせい）」です。侵害成立には「似ていること（類似性）」に加え、「既存の著作物を知っていて、それに基づいたこと（依拠性）」の両方が必要です。著作権侵害と判断されるためには、「類似性」と「依拠性（既存の著作物を知っていて、それに基づいたこと）」の両方が必要です。選択肢1の「独創性」、選択肢3の「商業性」、選択肢4の「芸術性」は著作権侵害の要件ではありません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": "unit87"
      }
    },
    {
      "questionId": "unit_088",
      "question": "文化庁の見解（令和6年）において、AI生成物が「著作物」として認められるために必要な要素は、「創作意図」ともう一つは何か。",
      "options": [
        "AIの性能の高さ",
        "プロンプトの長さ",
        "人間による「創作的寄与」（試行錯誤や加筆修正など）",
        "有料ツールの使用"
      ],
      "correctAnswer": "人間による「創作的寄与」（試行錯誤や加筆修正など）",
      "explanation": "正解は選択肢3です。AIが自律的に生成しただけでは著作物にならず、人間が道具としてAIを使いこなし、創作的に寄与したと認められる必要があります。文化庁の見解（令和6年）において、AI生成物が「著作物」として認められるためには、「創作意図」と「人間による創作的寄与（試行錯誤や加筆修正など）」が必要です。選択肢1、2、4は著作物として認められる条件ではありません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit88"
      }
    },
    {
      "questionId": "unit_089",
      "question": "日本の著作権法において、個人の著作物の保護期間は原則としていつまでか。",
      "options": [
        "創作から50年",
        "著作者の死後70年",
        "公表から20年",
        "永久に保護される"
      ],
      "correctAnswer": "著作者の死後70年",
      "explanation": "正解は「著作者の死後70年」です。原則として著作者の死後70年まで保護されます。保護期間が終了したものはパブリックドメインとなります。日本の著作権法では、原則として著作者の死後70年まで著作権が保護されます。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": "unit89"
      }
    },
    {
      "questionId": "unit_090",
      "question": "著名人の肖像（顔や姿）や氏名が持つ「顧客吸引力（経済的価値）」を排他的に利用する権利を何と呼ぶか。AI生成物で無断利用した場合に侵害となる恐れがある。",
      "options": [
        "肖像権",
        "パブリシティ権",
        "商標権",
        "意匠権"
      ],
      "correctAnswer": "パブリシティ権",
      "explanation": "正解は「パブリシティ権」です。プライバシーの保護（肖像権）とは別に、有名人の名前や姿を勝手に商品に使って利益を得ることを防ぐ権利が「パブリシティ権」です。著名人の肖像（顔や姿）や氏名が持つ「顧客吸引力（経済的価値）」を排他的に利用する権利です。選択肢1の「肖像権」はプライバシー保護の権利、選択肢3の「商標権」は商標の権利、選択肢4の「意匠権」はデザインの権利です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit90"
      }
    },
    {
      "questionId": "unit_091",
      "question": "「不正競争防止法」によって保護される「営業秘密」の3要件に含まれないものはどれか。",
      "options": [
        "秘密管理性（秘密として管理されていること）",
        "有用性（事業活動に有用であること）",
        "非公知性（公然と知られていないこと）",
        "審美性（見た目が美しいこと）"
      ],
      "correctAnswer": "審美性（見た目が美しいこと）",
      "explanation": "正解は選択肢4です。営業秘密の3要件は「秘密管理性」「有用性」「非公知性」です。審美性は意匠権などの要件です。不正競争防止法によって保護される「営業秘密」の3要件は、「秘密管理性（秘密として管理されていること）」「有用性（事業活動に有用であること）」「非公知性（公然と知られていないこと）」です。選択肢4の「審美性」は含まれません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit91"
      }
    },
    {
      "questionId": "unit_092",
      "question": "AIを利用して他人の登録商標と類似したロゴを作成し、商用利用した場合の法的判断として正しいものはどれか。",
      "options": [
        "AIが作ったものなので、責任はAI開発者にある。",
        "模倣する意図がなくても、結果的に類似しており、商用利用すれば商標権侵害となる可能性がある。",
        "プロンプトに商標名を入れなければ侵害にはならない。",
        "商標権はAI生成物には適用されない。"
      ],
      "correctAnswer": "模倣する意図がなくても、結果的に類似しており、商用利用すれば商標権侵害となる可能性がある。",
      "explanation": "正解は選択肢2です。商標権や意匠権は、著作権とは異なり「依拠性（マネする意図）」がなくても、登録された権利と類似していれば侵害となります。AIを利用して他人の登録商標と類似したロゴを作成し、商用利用した場合、模倣する意図がなくても、結果的に類似しており、商用利用すれば商標権侵害となる可能性があります。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": "unit92"
      }
    },
    {
      "questionId": "unit_093",
      "question": "「AI事業者ガイドライン（第1.1版）」において、AIビジネスに関わる主体は3つに分類されている。「AI開発者」「AI提供者」に加え、もう1つは何か。",
      "options": [
        "AI利用者（AI Business User）",
        "AI監視者",
        "AI規制者",
        "AI消費者"
      ],
      "correctAnswer": "AI利用者（AI Business User）",
      "explanation": "正解は「AI利用者（AI Business User）」です。ガイドラインでは、AIモデルを作る「開発者」、サービスとして提供する「提供者」、それを事業で活用する「利用者（主に企業）」の3主体それぞれの責務を規定しています。「AI事業者ガイドライン（第1.1版）」において、AIビジネスに関わる主体は「AI開発者（AIモデルを作る）」「AI提供者（サービスとして提供する）」「AI利用者（AI Business User、事業で活用する主に企業）」の3つに分類されています。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "AIガバナンス",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit93"
      }
    },
    {
      "questionId": "unit_094",
      "question": "AI事業者ガイドラインにおいて、「AI利用者（事業者）」に求められる重要な責務の一つはどれか。",
      "options": [
        "AIモデルのアルゴリズムをゼロから開発すること",
        "AIの判断結果に過度に依存せず、最終的な判断は人間が行う（人間中心の判断）こと",
        "すべてのデータを公開すること",
        "AIの利用を禁止すること"
      ],
      "correctAnswer": "AIの判断結果に過度に依存せず、最終的な判断は人間が行う（人間中心の判断）こと",
      "explanation": "正解は選択肢2です。利用者はAIを鵜呑みにせず、適正利用やリスク管理を行い、最終的な意思決定に責任を持つことが求められます。AI事業者ガイドラインにおいて、AI利用者（事業者）に求められる重要な責務の一つは、AIの判断結果に過度に依存せず、最終的な判断は人間が行う（人間中心の判断）ことです。選択肢1は開発者の責務、選択肢3、4は不適切です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "AIガバナンス",
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit94"
      }
    },
    {
      "questionId": "unit_095",
      "question": "2025年に交付された「AI新法（人工知能関連技術の研究開発及び活用の推進に関する法律）」の特徴的な規制アプローチはどれか。",
      "options": [
        "すべてのAI開発を一律に禁止する",
        "リスクベース・アプローチ（AIのリスクの大きさに応じて、異なるレベルの義務や規制を課す）",
        "AI利用者のみを処罰する",
        "開発者の国籍で規制を変える"
      ],
      "correctAnswer": "リスクベース・アプローチ（AIのリスクの大きさに応じて、異なるレベルの義務や規制を課す）",
      "explanation": "正解は選択肢2です。AI新法や欧州AI法（EU AI Act）などは、高リスクなAIには厳しい規制を、低リスクなAIには緩やかな規制を適用する「リスクベース・アプローチ」を採用しています。2025年に交付された「AI新法（人工知能関連技術の研究開発及び活用の推進に関する法律）」の特徴的な規制アプローチは、リスクベース・アプローチです。AIのリスクの大きさに応じて、異なるレベルの義務や規制を課す方式で、高リスクなAIには厳しい規制を、低リスクなAIには緩やかな規制を適用します。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "AIガバナンス",
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit95"
      }
    },
    {
      "questionId": "unit_096",
      "question": "AI倫理において、ブラックボックス化を防ぎ、判断根拠を説明できるようにすることを何と呼ぶか？",
      "options": [
        "公平性",
        "透明性・説明可能性",
        "人間中心",
        "安全性"
      ],
      "correctAnswer": "透明性・説明可能性",
      "explanation": "正解は「透明性・説明可能性」です。AI倫理において、ブラックボックス化を防ぎ、判断根拠を説明できるようにすることを透明性・説明可能性と呼びます。これはAI社会原則の柱の一つです。選択肢1の「公平性」、選択肢3の「人間中心」、選択肢4の「安全性」もAI倫理の重要な概念ですが、判断根拠の説明可能性を指すのは「透明性・説明可能性」です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit96"
      }
    },
    {
      "questionId": "unit_097",
      "question": "AI社会原則の一つである「人間中心（Human-centric）」の考え方として適切なものはどれか。",
      "options": [
        "AIが人間の代わりに全ての政治的決定を行うべきである。",
        "AIは人間の尊厳や基本的人権を尊重し、人間の幸福や能力拡張のために利用されるべきである。",
        "人間はAIの進化のために奉仕すべきである。",
        "AIの効率性を最優先し、人間の雇用は考慮しなくてよい。"
      ],
      "correctAnswer": "AIは人間の尊厳や基本的人権を尊重し、人間の幸福や能力拡張のために利用されるべきである。",
      "explanation": "正解は選択肢2です。AIはあくまで人間のための道具であり、人間の尊厳や権利が脅かされないよう、人間がコントロール権を持つべきという原則です。AI社会原則の「人間中心（Human-centric）」の考え方とは、AIは人間の尊厳や基本的人権を尊重し、人間の幸福や能力拡張のために利用されるべきであるという考え方です。AIは人間の能力を拡張し、社会全体の幸福と発展に貢献する存在であるべきとされています。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "unit",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": "unit97"
      }
    },
    {
      "questionId": "unit_098",
      "question": "「LM（言語モデル）」と「LLM（大規模言語モデル）」の主な違いに関する記述として、最も適切なものはどれか。",
      "options": [
        "LMは画像データを学習するが、LLMはテキストデータを学習する。",
        "LMはn-gramなどの統計手法を用いることが多いが、LLMは計算量とデータ量が桁違いに巨大なニューラルネットワークを用いて構築される。",
        "LMは翻訳専用だが、LLMは要約専用である。",
        "両者に違いはなく、呼び方が変わっただけである。"
      ],
      "correctAnswer": "LMはn-gramなどの統計手法を用いることが多いが、LLMは計算量とデータ量が桁違いに巨大なニューラルネットワークを用いて構築される。",
      "explanation": "正解は選択肢2です。LLMは数十億以上のパラメータと大規模なデータセットを用いてトレーニングされたモデルであり、従来のLMとは規模と汎用性が決定的に異なります。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit98"
      }
    },
    {
      "questionId": "unit_099",
      "question": "LLMの学習プロセスにおける「プレトレーニング（事前学習）」と「ファインチューニング（微調整）」の関係として正しいものはどれか。",
      "options": [
        "ファインチューニングを行ってから、プレトレーニングを行う。",
        "プレトレーニングで一般的な言語知識を大量に学習し、その後ファインチューニングで特定のタスクや目的に合わせて調整する。",
        "プレトレーニングのみでモデルは完成し、ファインチューニングは不要である。",
        "ファインチューニングはモデルのサイズを小さくする工程である。"
      ],
      "correctAnswer": "プレトレーニングで一般的な言語知識を大量に学習し、その後ファインチューニングで特定のタスクや目的に合わせて調整する。",
      "explanation": "正解は選択肢2です。汎用的な知識を学ぶ「プレトレーニング」と、特定用途に特化させる「ファインチューニング」の2段階構成がLLMの基本です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit99"
      }
    },
    {
      "questionId": "unit_100",
      "question": "生成AIの出力の「ランダム性（創造性）」を調整するハイパーパラメータである「Temperature（温度）」の設定について、正しい説明はどれか。",
      "options": [
        "値を「0」に近づけると、毎回同じような確実性の高い回答が出やすくなる（論理的タスク向き）。",
        "値を「1」に近づけると、回答が固定的になり、面白みがなくなる。",
        "値を高くすると、計算速度が速くなる。",
        "値を低くすると、AIが感情を持つようになる。"
      ],
      "correctAnswer": "値を「0」に近づけると、毎回同じような確実性の高い回答が出やすくなる（論理的タスク向き）。",
      "explanation": "正解は選択肢1です。Temperatureが低い（0に近い）と予測確率が高い単語が選ばれやすく「決まった回答」になり、高い（1に近い）とランダム性が増し「創造的な回答」になります。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit100"
      }
    },
    {
      "questionId": "unit_101",
      "question": "「Top-p」パラメータの役割として適切なものはどれか。",
      "options": [
        "AIの回答速度を制限する。",
        "出力する単語の候補を、累積確率が指定した値（p）になる上位グループに絞り込み、その中から選択させることでランダム性を制御する。",
        "過去の会話履歴をどれだけ記憶するかを設定する。",
        "不適切な発言をフィルタリングする。"
      ],
      "correctAnswer": "出力する単語の候補を、累積確率が指定した値（p）になる上位グループに絞り込み、その中から選択させることでランダム性を制御する。",
      "explanation": "正解は選択肢2です。Temperatureと同様に出力の多様性を制御するパラメータです。Top-pサンプリングとも呼ばれます。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit101"
      }
    },
    {
      "questionId": "unit_102",
      "question": "プロンプトを構成する「4つの要素」に含まれないものはどれか。",
      "options": [
        "Instruction（命令）：AIに何をしてほしいか",
        "Context（文脈）：背景情報や役割",
        "Emotion（感情）：ユーザーの怒りや喜びの度合い",
        "Output Indicator（出力指示）：形式や長さの指定"
      ],
      "correctAnswer": "Emotion（感情）：ユーザーの怒りや喜びの度合い",
      "explanation": "正解は選択肢3です。プロンプトの4要素は「Instruction（命令）」「Context（文脈）」「Input Data（入力データ）」「Output Indicator（出力指示）」です。感情は要素に含まれません。選択肢1、2、4はプロンプトの4要素に含まれます。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": "unit102"
      }
    },
    {
      "questionId": "unit_103",
      "question": "「Zero-Shotプロンプティング」の説明として正しいものはどれか。",
      "options": [
        "例文（正解例）を一つも提示せず、いきなり質問や指示を投げる手法。",
        "0回しか質問できないという制限付きの手法。",
        "誤った回答を0にするための特殊な手法。",
        "プロンプトを入力せずに念じるだけで回答を得る手法。"
      ],
      "correctAnswer": "例文（正解例）を一つも提示せず、いきなり質問や指示を投げる手法。",
      "explanation": "正解は選択肢1です。「〜について教えて」のように、例示なしで指示する手法です。モデルの基礎能力に依存します。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit103"
      }
    },
    {
      "questionId": "unit_104",
      "question": "「Few-Shotプロンプティング」が有効な理由は何か。",
      "options": [
        "プロンプトが短くなるため、料金が安くなるから。",
        "AIに「回答のパターン（入力と出力のセット）」をいくつか例示することで、期待する回答形式やニュアンスを学習（In-context Learning）させることができるから。",
        "AIの学習データを削除できるから。",
        "どんな質問にも必ず正解できるようになるから。"
      ],
      "correctAnswer": "AIに「回答のパターン（入力と出力のセット）」をいくつか例示することで、期待する回答形式やニュアンスを学習（In-context Learning）させることができるから。",
      "explanation": "正解は選択肢2です。2〜3個の例（Shot）を見せることで、AIは「あ、こういう風に答えればいいんだな」と文脈から推論し、精度が向上します。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit104"
      }
    },
    {
      "questionId": "unit_105",
      "question": "複雑な推論を要する問題に対し、「ステップバイステップで考えてください（Let's think step by step）」と指示することで正答率が向上する手法を何と呼ぶか。",
      "options": [
        "Chain-of-Thought（思考の連鎖）プロンプティング",
        "Zero-Shotプロンプティング",
        "マルチモーダルプロンプティング",
        "敵対的プロンプティング"
      ],
      "correctAnswer": "Chain-of-Thought（思考の連鎖）プロンプティング",
      "explanation": "正解は選択肢1です。いきなり答えを出させるのではなく、思考過程（中間ステップ）を出力させることで論理的な誤りを減らす手法です。選択肢2の「Zero-Shot」は例を示さずに質問、選択肢3の「マルチモーダル」は複数のモダリティを扱う手法、選択肢4の「敵対的プロンプティング」は攻撃手法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "セキュリティ",
          "プロンプト制作",
          "マルチモーダル"
        ],
        "difficulty": "medium",
        "unitId": "unit105"
      }
    },
    {
      "questionId": "unit_106",
      "question": "「あなたはプロのマーケターです」のように、AIに特定の役割や肩書きを与えるプロンプト技法（ペルソナ設定）の主な効果は何か。",
      "options": [
        "AIが人間になったと勘違いして、暴走する。",
        "一般的な回答ではなく、その専門分野の視点や用語を用いた、より質の高い具体的な回答を引き出せる。",
        "AIの処理速度が2倍になる。",
        "嘘をつく確率が上がる。"
      ],
      "correctAnswer": "一般的な回答ではなく、その専門分野の視点や用語を用いた、より質の高い具体的な回答を引き出せる。",
      "explanation": "正解は選択肢2です。役割（ロール）を与えることで、回答の視座やトーン＆マナーを制御し、専門的なアウトプットを得やすくなります。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": "unit106"
      }
    },
    {
      "questionId": "unit_107",
      "question": "長文を要約させる際、AIが重要な情報を見落とさないようにするための工夫として、最も効果的な指示はどれか。",
      "options": [
        "「短くして」とだけ伝える。",
        "「以下の文章の『結論』と『3つの根拠』を箇条書きで抽出して要約してください」のように、抽出項目と形式を具体的に指定する。",
        "何度も同じ文章を入力する。",
        "英語に翻訳してから要約させる。"
      ],
      "correctAnswer": "「以下の文章の『結論』と『3つの根拠』を箇条書きで抽出して要約してください」のように、抽出項目と形式を具体的に指定する。",
      "explanation": "正解は選択肢2です。単に「要約して」ではなく、「何を（要素）」「どうやって（形式）」残すかを指定することで、精度の高い要約が得られます。選択肢1、3、4は効果的ではありません。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit107"
      }
    },
    {
      "questionId": "unit_108",
      "question": "箇条書きのメモから、自然なビジネスメールの文章を作成させるタスクは、プロンプトエンジニアリングのどの活用例にあたるか。",
      "options": [
        "文章の校正",
        "文章の生成・変換（フォーマット変換）",
        "情報の検索",
        "画像の生成"
      ],
      "correctAnswer": "文章の生成・変換（フォーマット変換）",
      "explanation": "正解は選択肢2です。「箇条書き→文章」「文章→表」などのフォーマット変換は、LLMが非常に得意とするタスクの一つです。選択肢1の「校正」は誤字脱字の修正、選択肢3の「検索」は情報の探索、選択肢4の「画像生成」は別のモダリティです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": "unit108"
      }
    },
    {
      "questionId": "unit_109",
      "question": "ブレインストーミング（アイデア出し）において、AIを活用する最大のメリットは何か。",
      "options": [
        "人間が思いつかないような突飛なアイデアも含め、短時間で大量のバリエーションを出せるため、発想の幅が広がる。",
        "最終的な決定をAIに任せられる。",
        "会議室を予約する必要がなくなる。",
        "参加者全員の意見を無視できる。"
      ],
      "correctAnswer": "人間が思いつかないような突飛なアイデアも含め、短時間で大量のバリエーションを出せるため、発想の幅が広がる。",
      "explanation": "正解は選択肢1です。AIは疲れることなく、多角的な視点から大量の案を出せるため、アイデアの「壁打ち相手」として最適です。選択肢2、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit109"
      }
    },
    {
      "questionId": "unit_110",
      "question": "海外企業へのメール作成などで、AI翻訳を活用する際の注意点として適切なものはどれか。",
      "options": [
        "AIの翻訳は完璧なので、確認せずに送信してよい。",
        "専門用語やニュアンスが誤訳される可能性があるため、逆翻訳（日本語→英語→日本語）をして意味が通じるか確認するか、人間の手で最終チェックを行う。",
        "翻訳機能は使わず、単語リストだけ出させるべき。",
        "敬語は翻訳できないので諦める。"
      ],
      "correctAnswer": "専門用語やニュアンスが誤訳される可能性があるため、逆翻訳（日本語→英語→日本語）をして意味が通じるか確認するか、人間の手で最終チェックを行う。",
      "explanation": "正解は選択肢2です。高性能化していますが、文脈の取り違えは起こり得ます。逆翻訳や目視チェックは必須のリスク管理です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "リスク管理",
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit110"
      }
    },
    {
      "questionId": "unit_111",
      "question": "大規模言語モデル（LLM）が、「3桁以上の掛け算」や「複雑な数学パズル」を間違えることがある主な理由は何か。",
      "options": [
        "コンピュータの故障。",
        "LLMは計算機ではなく「次に来る単語を確率で予測するモデル」であり、論理的な計算プロセスを厳密に実行しているわけではないから。",
        "意地悪をしているから。",
        "学習データに数字が含まれていないから。"
      ],
      "correctAnswer": "LLMは計算機ではなく「次に来る単語を確率で予測するモデル」であり、論理的な計算プロセスを厳密に実行しているわけではないから。",
      "explanation": "正解は選択肢2です。LLMは「計算」しているのではなく、テキストとして「確率的に続きを予測」しているだけなので、数字の厳密な操作は苦手分野です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit111"
      }
    },
    {
      "questionId": "unit_112",
      "question": "「〇〇文字以内で書いて」という文字数指定を、AIが正確に守れないことが多い技術的な理由はどれか。",
      "options": [
        "AIが反抗期だから。",
        "AIは文字数ではなく「トークン（単語の断片）」単位でデータを処理しており、トークン数と実際の文字数が一致しないため。",
        "日本語の文字を認識できないから。",
        "文字数を数える機能が実装されていないから。"
      ],
      "correctAnswer": "AIは文字数ではなく「トークン（単語の断片）」単位でデータを処理しており、トークン数と実際の文字数が一致しないため。",
      "explanation": "正解は選択肢2です。AI内部では「トークン」で処理されており、特に日本語はトークン化の区切りが複雑なため、文字数指定の誤差が出やすくなります。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "トークン化",
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit112"
      }
    },
    {
      "questionId": "unit_113",
      "question": "従来のLLMが抱える「ナレッジカットオフ（学習データの期間終了後の情報を知らない）」の問題を解決し、最新情報に基づいた回答を得るためのアプローチとして、適切なツールや手法はどれか。",
      "options": [
        "20年前のデータを学習させる。",
        "Perplexity AIなどの「Web検索機能」を統合したAIツールや、RAG（検索拡張生成）を利用する。",
        "同じ質問を100回繰り返す。",
        "コンピュータを再起動する。"
      ],
      "correctAnswer": "Perplexity AIなどの「Web検索機能」を統合したAIツールや、RAG（検索拡張生成）を利用する。",
      "explanation": "正解は選択肢2です。テキスト第4版では、最新情報の弱点を補う手段として、リアルタイム検索を行うPerplexity AIやRAGの活用が挙げられています。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "ナレッジカットオフ",
          "RAG",
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit113"
      }
    },
    {
      "questionId": "unit_114",
      "question": "「ハルシネーション（幻覚）」と呼ばれる現象の説明として正しいものはどれか。",
      "options": [
        "AIが幽霊を見ること。",
        "AIが事実とは異なる内容や、架空の情報を、あたかも事実であるかのように自信満々に回答してしまう現象。",
        "AIがユーザーの心を読み取ること。",
        "AIが回答を拒否すること。"
      ],
      "correctAnswer": "AIが事実とは異なる内容や、架空の情報を、あたかも事実であるかのように自信満々に回答してしまう現象。",
      "explanation": "正解は選択肢2です。もっともらしい嘘（幻覚）をつく現象です。これを防ぐためには「情報源を明示させる」などのプロンプト工夫が必要です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "ハルシネーション",
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": "unit114"
      }
    },
    {
      "questionId": "unit_115",
      "question": "企業の機密データを扱って資料を作成する際、AIサービスに入力するデータについて注意すべき点は何か。",
      "options": [
        "AIは友達なので、秘密を打ち明けても大丈夫。",
        "入力したデータが「AIの学習に利用される（オプトイン）」設定になっている場合、機密情報が他社への回答として流出する恐れがあるため、オプトアウト設定を確認するか、個人情報をマスキングする。",
        "機密情報は暗号化すれば入力してもよい。",
        "深夜に入力すれば学習されない。"
      ],
      "correctAnswer": "入力したデータが「AIの学習に利用される（オプトイン）」設定になっている場合、機密情報が他社への回答として流出する恐れがあるため、オプトアウト設定を確認するか、個人情報をマスキングする。",
      "explanation": "正解は選択肢2です。学習利用される設定（デフォルトの場合が多い）では情報漏洩のリスクがあります。オプトアウト（学習拒否）の確認は必須です。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "リスク管理",
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit115"
      }
    },
    {
      "questionId": "unit_116",
      "question": "AIが生成した文章に、特定の人種や性別に対する偏見（バイアス）が含まれてしまう主な原因は何か。",
      "options": [
        "AIの性格が悪いから。",
        "AIが学習したインターネット上の大量のテキストデータ自体に、人間社会の偏見やステレオタイプが含まれていたから。",
        "開発者が意図的に差別プログラムを組み込んだから。",
        "ユーザーのプロンプトが短すぎたから。"
      ],
      "correctAnswer": "AIが学習したインターネット上の大量のテキストデータ自体に、人間社会の偏見やステレオタイプが含まれていたから。",
      "explanation": "正解は選択肢2です。AIは学習データを鏡のように反映します。学習元のデータにある社会的バイアスが、そのまま出力に現れるリスクを理解しておく必要があります。選択肢1、3、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "リスク管理",
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit116"
      }
    },
    {
      "questionId": "unit_117",
      "question": "生成AIを利用する際、最終的な成果物の責任は誰にあると考えられるか。",
      "options": [
        "AIを開発したベンダー企業だけにある。",
        "AI自身にある。",
        "AIを利用し、その出力を採用・公開した利用者（人間）にある。",
        "誰にも責任はない。"
      ],
      "correctAnswer": "AIを利用し、その出力を採用・公開した利用者（人間）にある。",
      "explanation": "正解は選択肢3です。AIはあくまで「道具」です。その出力内容の真偽確認（ファクトチェック）や権利侵害の確認を含め、最終的な責任は利用者にあります。選択肢1、2、4は誤りです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "unit",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": "unit117"
      }
    },
    {
      "questionId": "add_001",
      "question": "新規事業のブレインストーミングで、AIから「突飛でユニークなアイデア」を大量に出させたい。プロンプトのパラメータ設定として、最も適切な調整はどれか。",
      "options": [
        "Temperatureを「0.1」に設定する。",
        "Temperatureを「0.9」程度に高く設定する。",
        "Top-pを「0.1」に設定する。",
        "Max Tokensを「10」に設定する。"
      ],
      "correctAnswer": "Temperatureを「0.9」程度に高く設定する。",
      "explanation": "Temperature（温度）を高く設定すると、AIは確率の低い単語も選択するようになり、回答のランダム性と創造性が高まります。アイデア出しには高めの設定が有効です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_002",
      "question": "海外の取引先から届いた契約書のドラフト（PDF）をAIに読み込ませ、要約とリスクチェックを行わせたい。情報セキュリティの観点から、最初に確認すべき事項はどれか。",
      "options": [
        "AIがPDFを読み込める機能を持っているか。",
        "そのAIサービスの設定で「学習データとしての利用（オプトイン）」がOFFになっているか、またはAPI利用などでデータが学習されない契約になっているか。",
        "契約書の文字数。",
        "翻訳の精度。"
      ],
      "correctAnswer": "そのAIサービスの設定で「学習データとしての利用（オプトイン）」がOFFになっているか、またはAPI利用などでデータが学習されない契約になっているか。",
      "explanation": "機密文書（契約書）をAIに入力する場合、そのデータがAIの再学習に使われてしまい、情報漏洩につながるリスクが最大の問題です。オプトアウト設定やAPI利用規約の確認が最優先です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "リスク管理",
          "プロンプト制作",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_003",
      "question": "自社のECサイトにチャットボットを導入したいが、「嘘の情報を答えるリスク（ハルシネーション）」を極限まで減らしたい。採用すべきアーキテクチャはどれか。",
      "options": [
        "GPT-4oをそのまま接続し、「嘘をつかないで」とシステムプロンプトに入れる。",
        "RAG（検索拡張生成）を採用し、回答のソースを「自社の製品データベース」のみに限定するようグラウンディング（根拠付け）を行う。",
        "Temperatureを1.0に設定する。",
        "過去のチャットログをすべて学習させたモデルをゼロから作る。"
      ],
      "correctAnswer": "RAG（検索拡張生成）を採用し、回答のソースを「自社の製品データベース」のみに限定するようグラウンディング（根拠付け）を行う。",
      "explanation": "ハルシネーション対策として最も有効なのはRAGです。検索範囲を自社DBに限定し、根拠のない回答を抑制する手法が実務的です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "RAG",
          "リスク管理",
          "ハルシネーション",
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_004",
      "question": "開発チームで、GitHub上のプルリクエスト作成やバグ修正を自動化したい。導入を検討すべき最適なAIエージェントツールはどれか。",
      "options": [
        "Sora",
        "Operator",
        "Codex (OpenAI)",
        "Suno"
      ],
      "correctAnswer": "Codex (OpenAI)",
      "explanation": "Codexはコード生成と修正に特化したエージェント機能を持っており、サンドボックス環境でテストを通るまで自律的に修正を行う機能があります。Operatorはブラウザ操作、Sunoは音楽、Soraは動画です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_005",
      "question": "あなたはデザイナーです。生成AIで作成したロゴが、既存の有名ブランドのロゴに偶然似てしまった。これを商用利用した場合の法的リスクについて、正しい認識はどれか。",
      "options": [
        "AIが作ったものなので、意図的でなければ責任は問われない。",
        "著作権侵害にはならなくても、商標権侵害として差し止めや損害賠償を請求される可能性がある。",
        "プロンプトにブランド名を入れていなければ安全である。",
        "少し色を変えれば問題ない。"
      ],
      "correctAnswer": "著作権侵害にはならなくても、商標権侵害として差し止めや損害賠償を請求される可能性がある。",
      "explanation": "商標権や意匠権は「依拠性（マネする意図）」がなくても、「類似性」があり、かつ登録されている区分で業として使用すれば侵害となります。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_006",
      "question": "生成AIを使って作成したイラスト集を販売したい。そのイラストが「著作物」として認められ、あなたに著作権が発生するための条件は何か。",
      "options": [
        "高性能な有料のAIツールを使ったこと。",
        "あなたが「創作的寄与（試行錯誤、加筆、選別など）」を行い、AIを単なる道具として利用したと認められること。",
        "プロンプトが100文字以上であること。",
        "AIが全自動で出力したものであること。"
      ],
      "correctAnswer": "あなたが「創作的寄与（試行錯誤、加筆、選別など）」を行い、AIを単なる道具として利用したと認められること。",
      "explanation": "文化庁の見解では、人が「創作的寄与」をしていないAI生成物は著作物として認められません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_007",
      "question": "人事部で採用選考にAIを導入し、履歴書の評価を自動化しようとしている。AI倫理の観点から最も警戒すべきリスクはどれか。",
      "options": [
        "AIが疲れて評価を止めること。",
        "学習データに含まれる過去の採用傾向（性別や学歴などの偏り）が反映され、不公平な差別的評価が行われる「バイアス」の問題。",
        "AIの計算速度が速すぎること。",
        "紙の履歴書が読めないこと。"
      ],
      "correctAnswer": "学習データに含まれる過去の採用傾向（性別や学歴などの偏り）が反映され、不公平な差別的評価が行われる「バイアス」の問題。",
      "explanation": "AIは過去のデータの偏り（バイアス）を再生産するリスクがあります。採用などのハイリスク領域では、公平性の担保が最重要課題です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_008",
      "question": "「拡散モデル（Diffusion）」と「自己回帰型（Autoregressive）」の画像生成における決定的な違いは？",
      "options": [
        "拡散モデルはノイズ除去で絵を作るが、自己回帰型はトークンとして左上から順に描くため文字描写が得意。",
        "拡散モデルは動画専用だが、自己回帰型は静止画専用。",
        "拡散モデルはGoogle製だが、自己回帰型はOpenAI製。",
        "違いはない。"
      ],
      "correctAnswer": "拡散モデルはノイズ除去で絵を作るが、自己回帰型はトークンとして左上から順に描くため文字描写が得意。",
      "explanation": "第4版の最重要変更点です。拡散モデル（ノイズ除去）の弱点である「文字崩れ」を克服したのが自己回帰型（順次描画）です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "拡散モデル",
          "自己回帰"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_009",
      "question": "「GPT-4o」と「GPT-o1」の使い分けとして正しいのは？",
      "options": [
        "4oは「じっくり考える」用、o1は「素早い会話」用。",
        "4oは「マルチモーダル・即応性」重視、o1は「推論・厳密性（Chain-of-Thought）」重視。",
        "4oは画像生成専用、o1は音楽生成専用。",
        "o1の方が古いモデルである。"
      ],
      "correctAnswer": "4oは「マルチモーダル・即応性」重視、o1は「推論・厳密性（Chain-of-Thought）」重視。",
      "explanation": "4o (Omni) は体験と速度、o1 (Reasoning) は思考の深さと正確性が強みです。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "GPT"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_010",
      "question": "「教師あり学習」と「強化学習」の学習データ（手掛かり）の違いは？",
      "options": [
        "教師あり学習は「正解ラベル」、強化学習は行動に対する「報酬（スコア）」。",
        "教師あり学習は「報酬」、強化学習は「正解ラベル」。",
        "どちらも「正解ラベル」を使う。",
        "どちらもデータを使わない。"
      ],
      "correctAnswer": "教師あり学習は「正解ラベル」、強化学習は行動に対する「報酬（スコア）」。",
      "explanation": "教師あり学習は「正解」を教えますが、強化学習は「結果の良し悪し（報酬）」だけを与えて試行錯誤させます。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_011",
      "question": "「著作権」と「特許権」の発生タイミングの違いは？",
      "options": [
        "著作権は「創作した時点」で自然発生するが、特許権は「出願・登録」が必要。",
        "著作権は「出願」が必要だが、特許権は「発明した時点」で発生する。",
        "どちらも出願が必要。",
        "どちらも自然発生する。"
      ],
      "correctAnswer": "著作権は「創作した時点」で自然発生するが、特許権は「出願・登録」が必要。",
      "explanation": "著作権は無方式主義（作った瞬間発生）、産業財産権（特許・商標・意匠）は方式主義（登録が必要）です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_012",
      "question": "「RAG」と「ファインチューニング」の解決する課題の違いは？",
      "options": [
        "RAGは「知識の不足（最新情報・社内情報）」を補うが、ファインチューニングは「口調や形式、特定タスクへの適応」を行う。",
        "RAGは「口調」を変えるが、ファインチューニングは「最新情報」を入れる。",
        "RAGはコストが高いが、ファインチューニングは無料。",
        "両者は完全に同じ機能である。"
      ],
      "correctAnswer": "RAGは「知識の不足（最新情報・社内情報）」を補うが、ファインチューニングは「口調や形式、特定タスクへの適応」を行う。",
      "explanation": "最新情報の参照にはRAG、振る舞いや専門用語の定着にはファインチューニングが適しています。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "RAG"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_013",
      "question": "2025年公開の「Gemini 2.5 Pro」の特徴的なスペックとして正しいものは？",
      "options": [
        "最大約104万トークンの超長コンテキストに対応。",
        "テキストのみ対応で画像は扱えない。",
        "パラメータ数が100個しかない。",
        "動作にスーパーコンピュータが必須。"
      ],
      "correctAnswer": "最大約104万トークンの超長コンテキストに対応。",
      "explanation": "Gemini 2.5 Proは100万トークン級の長大なコンテキストウィンドウを持つことが大きな特徴です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "Gemini",
          "生成AI",
          "トークン化"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_014",
      "question": "OpenAIの動画生成AI「Sora」の生成可能な最大動画長は？",
      "options": [
        "3秒",
        "20秒",
        "1分（60秒）",
        "1時間"
      ],
      "correctAnswer": "20秒",
      "explanation": "第4版テキストではSoraは「最大1080p・最長20秒まで生成可能」と明記されています。一般的な認識（1分）と異なる場合があるため、テキストの記述を優先して覚える必要があります。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_015",
      "question": "開発者向けモデル「GPT-4.1」の最大トークン数は？",
      "options": [
        "32,000",
        "128,000",
        "100万（1M）",
        "無制限"
      ],
      "correctAnswer": "100万（1M）",
      "explanation": "GPT-4.1は開発者向け実務モデルとして、最大100万トークンに対応しています。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "GPT",
          "トークン化"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_016",
      "question": "「AI事業者ガイドライン（第1.1版）」において定義されている、AIビジネスに関わる3つの主体とは？",
      "options": [
        "政府・企業・市民",
        "AI開発者・AI提供者・AI利用者",
        "プログラマー・デザイナー・マネージャー",
        "サーバー・クライアント・ネットワーク"
      ],
      "correctAnswer": "AI開発者・AI提供者・AI利用者",
      "explanation": "ガイドラインでは「開発者（Developer）」「提供者（Provider）」「利用者（Business User）」の3主体に分類し、それぞれの責務を定めています。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "AIガバナンス"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_017",
      "question": "AIエージェントが外部ツールと接続するための標準プロトコル「MCP」は何の略か？",
      "options": [
        "Master Control Program",
        "Model Context Protocol",
        "Multi Cloud Platform",
        "Machine Coding Process"
      ],
      "correctAnswer": "Model Context Protocol",
      "explanation": "Model Context Protocolは、Anthropicが提唱するAIと外部ツールの接続規格です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "MCP",
          "Claude",
          "生成AI",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_018",
      "question": "複雑な推論問題に対し、「ステップバイステップで考えてください」と指示する手法名は？",
      "options": [
        "Chain-of-Thought (CoT) プロンプティング",
        "Zero-Shotプロンプティング",
        "Few-Shotプロンプティング",
        "マルチモーダルプロンプティング"
      ],
      "correctAnswer": "Chain-of-Thought (CoT) プロンプティング",
      "explanation": "いきなり答えを出させるのではなく、思考過程（中間ステップ）を出力させることで論理的な誤りを減らす手法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_019",
      "question": "AIに「あなたはプロの編集者です」と役割を与える手法名は？",
      "options": [
        "ペルソナ設定（ロールプレイ）",
        "Few-Shotプロンプティング",
        "RAG",
        "ファインチューニング"
      ],
      "correctAnswer": "ペルソナ設定（ロールプレイ）",
      "explanation": "役割（ペルソナ）を与えることで、専門用語の使用や視座の調整が行われ、回答品質が向上します。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_020",
      "question": "回答例を全く与えずに質問する手法は？",
      "options": [
        "Zero-Shotプロンプティング",
        "Few-Shotプロンプティング",
        "Many-Shotプロンプティング",
        "Chain-of-Thoughtプロンプティング"
      ],
      "correctAnswer": "Zero-Shotプロンプティング",
      "explanation": "「〜について教えて」のように、例示なしで指示する手法です。モデルの基礎能力に依存します。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_021",
      "question": "AIを利用して作成した発明について、特許庁の現在の見解（2024年2月時点）に基づき、特許権を取得できる可能性が最も高いケースはどれか。",
      "options": [
        "人が全く関与せず、AIが自律的に課題を発見し解決策を出力したケース。",
        "人が学習用データの選択やモデルへの指示（プロンプト）を行うなど、発明の技術的特徴の具体化に「創作的に関与」したケース。",
        "AIが出したアイデアをそのまま出願したケース。",
        "日本ではAIを利用した発明は一切特許が認められない。"
      ],
      "correctAnswer": "人が学習用データの選択やモデルへの指示（プロンプト）を行うなど、発明の技術的特徴の具体化に「創作的に関与」したケース。",
      "explanation": "AIを利用した発明でも、自然人（人間）がその技術的特徴の具体化に創作的に関与していれば、その人が発明者として認められる可能性があります。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_022",
      "question": "「著作権」と「商標権」における、AI生成物の扱いの違いとして正しいものはどれか。",
      "options": [
        "著作権はAI生成物には一切発生しないが、商標権はAI生成物であっても使用実績があれば保護対象になり得る。",
        "著作権も商標権も、AI生成物には一切権利が発生しない。",
        "どちらもAI生成物であれば無条件に権利が発生する。",
        "商標権は創作した瞬間に発生する。"
      ],
      "correctAnswer": "著作権はAI生成物には一切発生しないが、商標権はAI生成物であっても使用実績があれば保護対象になり得る。",
      "explanation": "著作権は「思想感情の創作的表現」が必要ですが、商標権は「創作」ではなく「使用（業務上の信用）」に対して付与される趣旨があるため、AI生成物でも保護対象となり得ます。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_023",
      "question": "企業の広報担当者が、生成AIで作った著名人に似たキャラクターを広告に使用したい。パブリシティ権の侵害となる基準（3類型）に含まれないものはどれか。",
      "options": [
        "肖像や氏名それ自体を独立して鑑賞の対象とする商品（写真集など）。",
        "商品の差別化を図る目的で肖像を商品に付す（Tシャツなど）。",
        "肖像を商品の広告として使用する。",
        "社内の非公開会議の資料として、著名人の似顔絵を参考画像として貼る。"
      ],
      "correctAnswer": "社内の非公開会議の資料として、著名人の似顔絵を参考画像として貼る。",
      "explanation": "パブリシティ権侵害の基準は「鑑賞対象としての利用」「差別化目的での付記」「広告利用」の3つです。非公開の社内資料利用は「顧客吸引力の利用」に当たらないため、侵害の可能性は低いです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_024",
      "question": "営業秘密（顧客リストなど）を生成AIに入力してしまった。これが「不正競争防止法」違反となるリスクについての説明として正しいものはどれか。",
      "options": [
        "自分の会社の秘密なので、法律違反にはならない。",
        "他社から不正に取得した営業秘密を、悪意または重過失でAIに入力・使用した場合、不正競争防止法違反となる。",
        "AIに入力した時点で、その情報は「公知」となり、営業秘密ではなくなるため問題ない。",
        "入力データは暗号化されるため、法的な問題は生じない。"
      ],
      "correctAnswer": "他社から不正に取得した営業秘密を、悪意または重過失でAIに入力・使用した場合、不正競争防止法違反となる。",
      "explanation": "不正競争防止法では、不正取得した営業秘密の使用・開示を禁じています。生成AIへの入力も「使用」や「開示（学習利用される場合）」に該当する可能性があります。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_025",
      "question": "デザイナーが「AIを道具として使用した」と認められ、生成物に著作権が発生するための要件である「創作的寄与」の具体例として、文化庁見解で不十分とされる行為はどれか。",
      "options": [
        "長大なプロンプトで詳細に指示を出した。",
        "生成された画像に対し、Photoshopで大幅な加筆・修正を行った。",
        "何ら指示を与えず（または簡単な指示のみで）「生成」ボタンを押しただけ。",
        "多数の生成物から、自分の意図に合うものを厳選し、さらに修正を加えた。"
      ],
      "correctAnswer": "何ら指示を与えず（または簡単な指示のみで）「生成」ボタンを押しただけ。",
      "explanation": "単に生成ボタンを押しただけ、あるいは簡単な指示のみでは「思想感情を創作的に表現した」とは言えず、著作物とは認められません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_026",
      "question": "ユーザーがWebサイトにファイルをアップロードする際、そのサイトが安全かどうかを見極めるためのリスク管理として、テキストで推奨されている対策はどれか。",
      "options": [
        "ファイルを圧縮してからアップロードする。",
        "個人情報や機密情報が含まれていないか確認し、サイトがデータをどう保護しているか規約を確認する。",
        "深夜にアップロードする。",
        "ファイル名を変更する。"
      ],
      "correctAnswer": "個人情報や機密情報が含まれていないか確認し、サイトがデータをどう保護しているか規約を確認する。",
      "explanation": "アップロードサービス利用時は、データ漏洩リスクがあるため、機密情報の有無とサイトの保護方針（プライバシーポリシー）の確認が必須です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "リスク管理",
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_027",
      "question": "「機微（センシティブ）情報」と「要配慮個人情報」の関係について、金融分野ガイドラインにおける定義として正しいものはどれか。",
      "options": [
        "機微情報は要配慮個人情報よりも範囲が広く、労働組合への加盟や門地なども含む。",
        "機微情報は要配慮個人情報よりも範囲が狭い。",
        "両者は全く同じものである。",
        "機微情報は個人情報保護法で定義されている用語である。"
      ],
      "correctAnswer": "機微情報は要配慮個人情報よりも範囲が広く、労働組合への加盟や門地なども含む。",
      "explanation": "金融ガイドラインの「機微情報」は、法令の「要配慮個人情報」に加え、労働組合への加盟、門地、本籍地、保健医療、性生活なども含む広い概念であり、原則取得禁止です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "AIガバナンス",
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_028",
      "question": "フィッシング詐欺の手口が生成AIで高度化している現在、最も推奨される防御策の組み合わせはどれか。",
      "options": [
        "パスワードを定期的に変更するだけ。",
        "多要素認証（MFA）の有効化と、URL/送信元ドメインの確認。",
        "全てのメールを開かない。",
        "AIを使ってメールを自動削除する。"
      ],
      "correctAnswer": "多要素認証（MFA）の有効化と、URL/送信元ドメインの確認。",
      "explanation": "AIによる自然な文面のフィッシングメールが増えているため、見た目での判断は困難です。MFAによるシステム的防御と、ドメイン確認という基本動作の徹底が最重要です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_029",
      "question": "RAGシステムにおいて、検索精度を高めるために「粗検索（Coarse Retrieval）」と「精密検索（Fine-grained Retrieval）」を組み合わせ、最終的に情報の順位を決定するプロセスを何と呼ぶか。",
      "options": [
        "チャンキング (Chunking)",
        "再ランキング (Re-ranking)",
        "エンベッディング (Embedding)",
        "ファインチューニング (Fine-tuning)"
      ],
      "correctAnswer": "再ランキング (Re-ranking)",
      "explanation": "多段階検索プロセスの仕上げとして、質問との関連性や信頼性を評価して順位を付け直す処理を「再ランキング」と呼びます。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_030",
      "question": "RAGにおいて「ベクトル検索（Dense retrieval）」と「キーワード検索（Sparse retrieval）」を組み合わせる検索手法を何と呼ぶか。",
      "options": [
        "ハイブリッド検索",
        "マルチモーダル検索",
        "敵対的検索",
        "生成的検索"
      ],
      "correctAnswer": "ハイブリッド検索",
      "explanation": "文脈を理解するベクトル検索と、単語の一致を見るキーワード検索を組み合わせ、精度を高める手法をハイブリッド検索と呼びます。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "RAG",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_031",
      "question": "AIエージェントが「計画→行動→評価」のループを回す際、複数のLLMを鎖状に連結して処理を行う手法（例：ルーティング、並列化、オーケストレーター）を総称して何と呼ぶか。",
      "options": [
        "ワークフロー型アプローチ（LLMのチェーン/連鎖）",
        "ニューラルネットワーク",
        "強化学習",
        "マルチモーダル"
      ],
      "correctAnswer": "ワークフロー型アプローチ（LLMのチェーン/連鎖）",
      "explanation": "複数のLLMを役割分担させて連結し、ワークフローを構築することで、複雑なタスクを安定して処理させることができます。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_032",
      "question": "シンガポール発のAIエージェントで、多数の履歴書の分析やExcelへのまとめなど、複雑な事務処理を全自動で遂行できるツールはどれか。",
      "options": [
        "Operator",
        "Manus",
        "Sora",
        "Suno"
      ],
      "correctAnswer": "Manus",
      "explanation": "Manusは非同期で動作する汎用エージェントで、複雑な事務処理の全自動化を強みとしています。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_033",
      "question": "Anthropic社が提唱した、LLMと外部ツールを接続するための「AI版USB」とも呼ばれるオープン標準プロトコルは何か。",
      "options": [
        "API",
        "MCP (Model Context Protocol)",
        "JSON",
        "REST"
      ],
      "correctAnswer": "MCP (Model Context Protocol)",
      "explanation": "Model Context Protocol（MCP）は、Anthropic社が提唱した、LLMとデータソース・ツールを標準的な方法で接続するためのオープン標準プロトコルです。「AI版USB」とも呼ばれ、JSON-RPC互換メッセージを使用して、異なるAIエージェントツール間の相互運用性を高めることを目的としています。これにより、LLMと外部ツール（Google Drive、Slackなど）を標準的な方法で接続できるようになります。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "Gemini",
          "生成AIの動向",
          "MCP",
          "Claude",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_034",
      "question": "Googleの最新モデル「Gemini 2.5 Pro」の最大コンテキストトークン数はいくつか。",
      "options": [
        "12.8万",
        "20万",
        "104万（約100万）",
        "無制限"
      ],
      "correctAnswer": "104万（約100万）",
      "explanation": "Gemini 2.5 Proは最大約104万トークンという超長コンテキストを扱えることが大きな特徴です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "Gemini",
          "生成AI",
          "トークン化"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_035",
      "question": "Claude 3.5 Sonnetで追加された、コードや文書を対話画面の横でプレビュー・編集できる機能の名称は何か。",
      "options": [
        "Code Interpreter",
        "Canvas",
        "Artifacts",
        "Spaces"
      ],
      "correctAnswer": "Artifacts",
      "explanation": "AnthropicのClaudeに追加された、生成物を独立したウィンドウで表示・編集できる機能は「Artifacts」です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "Claude"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_037",
      "question": "推論特化モデル「GPT-5 Thinking」は、前世代のo3モデルと比較して、ハルシネーション（幻覚）がどの程度減少したと報告されているか。",
      "options": [
        "約10%",
        "約50%",
        "約80%",
        "100%（完全に無くなった）"
      ],
      "correctAnswer": "約80%",
      "explanation": "GPT-5 Thinkingはo3比でハルシネーションが約80%減少したとされています。この数値は試験の重要ポイントです。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "GPT",
          "ハルシネーション"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_038",
      "question": "OpenAIが2025年1月に公開した、ブラウザ操作に特化したAIエージェントの名称は何か。",
      "options": [
        "Sora",
        "Operator",
        "Codex",
        "Interpreter"
      ],
      "correctAnswer": "Operator",
      "explanation": "Operatorは独自の仮想ブラウザを起動し、クリックや入力を代行するエージェントです。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "additional",
        "tags": [
          "生成AI",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_039",
      "question": "複数のタスク（例：会議録作成→TODO抽出→メール作成）を、一度の指示ではなく、会話のキャッチボールを通じて段階的に進める手法は何か。",
      "options": [
        "マルチターン（質問させながら一緒に進める）",
        "Zero-Shotプロンプティング",
        "Few-Shotプロンプティング",
        "Chain-of-Thoughtプロンプティング"
      ],
      "correctAnswer": "マルチターン（質問させながら一緒に進める）",
      "explanation": "複数のタスクを一度の指示ではなく、会話を重ねながら段階的に進める手法をマルチターンと呼びます。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_040",
      "question": "LLMの出力のランダム性を制御する「Temperature」において、値を「1」に近づけるとどうなるか。",
      "options": [
        "回答が固定的で論理的になる。",
        "ランダム性が高まり、創造的な回答が出やすくなる。",
        "回答が短くなる。",
        "計算速度が上がる。"
      ],
      "correctAnswer": "ランダム性が高まり、創造的な回答が出やすくなる。",
      "explanation": "Temperatureが高い（1に近い）と、確率の低い単語も選ばれるようになり、表現の多様性や創造性が高まります。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_041",
      "question": "プロンプトに「機密情報」や「個人情報」を入力する際のリスク管理として、最も適切な行動はどれか。",
      "options": [
        "そのまま入力する。",
        "「忘れてください」と最後に書く。",
        "架空の名称（例：A社、佐藤氏）に置き換えて入力し、出力後に手動で修正する。",
        "暗号化して入力する。"
      ],
      "correctAnswer": "架空の名称（例：A社、佐藤氏）に置き換えて入力し、出力後に手動で修正する。",
      "explanation": "学習利用されるリスクを考慮し、実データは入力せず、マスキングやダミーデータへの置き換えを行うのが鉄則です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "リスク管理",
          "個人情報保護",
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_042",
      "question": "慣れない業務のプロセスを知りたい時、「事業計画書の作成手順を分解して表形式でまとめて」のように指示するプロンプトの活用法は何か。",
      "options": [
        "業務の手順を分解（タスク分解）",
        "Zero-Shotプロンプティング",
        "Few-Shotプロンプティング",
        "マルチモーダルプロンプティング"
      ],
      "correctAnswer": "業務の手順を分解（タスク分解）",
      "explanation": "複雑な業務プロセスを段階的に分解して理解するためのプロンプトの活用方法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_043",
      "question": "2017年にGoogleの研究者らが発表し、その後のGPTやBERTなど現代のLLM（大規模言語モデル）の基礎となったアーキテクチャは何か。",
      "options": [
        "RNN (Recurrent Neural Network)",
        "GAN (Generative Adversarial Networks)",
        "Transformer",
        "CNN (Convolutional Neural Network)"
      ],
      "correctAnswer": "Transformer",
      "explanation": "Transformerは「Self-Attention（自己注意機構）」を導入し、並列処理と長距離の文脈理解を可能にしたことで、LLMの爆発的進化の起点となりました。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "additional",
        "tags": [
          "Gemini",
          "GPT",
          "AI基礎",
          "Transformer"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_044",
      "question": "自然言語処理モデルにおける「BERT」と「GPT」の役割の違いとして、最も適切な説明はどれか。",
      "options": [
        "BERTは「文章の生成（話す）」が得意で、GPTは「文脈の理解（聞く）」が得意である。",
        "BERTは「文脈の理解（聞く）」に特化したエンコーダ型で、GPTは「文章の生成（話す）」に特化したデコーダ型である。",
        "両者に違いはなく、開発会社が違うだけである。",
        "BERTは画像用、GPTは音声用である。"
      ],
      "correctAnswer": "BERTは「文脈の理解（聞く）」に特化したエンコーダ型で、GPTは「文章の生成（話す）」に特化したデコーダ型である。",
      "explanation": "BERTは文脈を双方向から読む「理解（エンコーダ）」が得意で、GPTは次の単語を予測する「生成（デコーダ）」が得意です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "additional",
        "tags": [
          "GPT",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_045",
      "question": "ChatGPT（GPT-3.5）の性能を飛躍的に高めた学習手法「RLHF」の目的は何か。",
      "options": [
        "AIにインターネット上の全ての情報を丸暗記させること。",
        "人間のフィードバック（評価）に基づいて強化学習を行い、AIの回答を人間の意図や価値観に合わせる（アライメントする）こと。",
        "計算コストをゼロにすること。",
        "画像生成機能を付与すること。"
      ],
      "correctAnswer": "人間のフィードバック（評価）に基づいて強化学習を行い、AIの回答を人間の意図や価値観に合わせる（アライメントする）こと。",
      "explanation": "RLHF (Reinforcement Learning from Human Feedback) は、AIを人間の好ましい挙動に調整（アライメント）するための重要技術です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "additional",
        "tags": [
          "GPT",
          "AI基礎",
          "RLHF"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_046",
      "question": "2024年のOpenAIのモデル展開において、「GPT-4o」と「GPT-o1」という2つのラインに分岐した主な理由は何か。",
      "options": [
        "「マルチモーダルな即応体験（Omni）」と「熟考による深い推論（Reasoning）」という異なるニーズに特化するため。",
        "サーバーの故障による一時的な措置。",
        "無料版と有料版を分けるためだけ。",
        "開発チームが仲違いしたため。"
      ],
      "correctAnswer": "「マルチモーダルな即応体験（Omni）」と「熟考による深い推論（Reasoning）」という異なるニーズに特化するため。",
      "explanation": "「体験と速度（4o）」と「思考の深さと正確性（o1）」という、異なる目的へ最適化するためにモデル系譜が分岐しました。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "additional",
        "tags": [
          "GPT",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_047",
      "question": "悪意のあるユーザーが、特殊な命令を入力することで、AIに設定された「違法行為を教えない」などの安全フィルターを回避し、不適切な回答を引き出そうとする攻撃手法を何と呼ぶか。",
      "options": [
        "プロンプトインジェクション（脱獄/Jailbreak）",
        "SQLインジェクション",
        "DDoS攻撃",
        "フィッシング"
      ],
      "correctAnswer": "プロンプトインジェクション（脱獄/Jailbreak）",
      "explanation": "プロンプトを工夫してAIの制約を突破する行為はプロンプトインジェクション、あるいはジェイルブレイク（脱獄）と呼ばれます。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理",
          "セキュリティ",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_048",
      "question": "AIの学習データに、攻撃者が意図的に誤ったデータや悪意あるデータ（毒）を混入させ、モデルの挙動を操作したり精度を下げたりする攻撃はどれか。",
      "options": [
        "データポイズニング（Data Poisoning）",
        "モデルインバージョン",
        "ランサムウェア",
        "ゼロデイ攻撃"
      ],
      "correctAnswer": "データポイズニング（Data Poisoning）",
      "explanation": "学習段階でデータを汚染させる攻撃をデータポイズニングと呼びます。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_049",
      "question": "公開されているAIモデルの出力結果（APIの回答など）を解析することで、そのモデルが学習に使用した「元の訓練データ（個人情報など）」を復元・推測しようとする攻撃手法は何か。",
      "options": [
        "モデルインバージョン攻撃（Model Inversion Attack）",
        "ソーシャルエンジニアリング",
        "サプライチェーン攻撃",
        "ブルートフォース攻撃"
      ],
      "correctAnswer": "モデルインバージョン攻撃（Model Inversion Attack）",
      "explanation": "完成したモデルから学習データを逆算（Inversion）してプライバシーを侵害する攻撃です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "個人情報保護",
          "法律・倫理",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_050",
      "question": "企業において、従業員が会社の許可を得ずに、個人的なアカウントや無料のAIツールを業務利用してしまい、情報漏洩のリスクが高まる状態を何と呼ぶか。",
      "options": [
        "シャドーIT（Shadow AI）",
        "クラウドコンピューティング",
        "リモートワーク",
        "オープンソース"
      ],
      "correctAnswer": "シャドーIT（Shadow AI）",
      "explanation": "管理者の目の届かないところ（影）でAIが使われる「シャドーAI」は、現代企業の重大なセキュリティ課題です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "リスク管理",
          "法律・倫理",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_051",
      "question": "プロンプトインジェクション攻撃への対策として、システム開発側が取るべき最も基本的な防御策はどれか。",
      "options": [
        "ユーザーからの入力をそのままAIに渡さず、入力値の検証（バリデーション）やフィルタリングを行う。",
        "AIをインターネットから切断する。",
        "ユーザーに「攻撃しないで」とお願いする。",
        "AIの性能を極端に下げる。"
      ],
      "correctAnswer": "ユーザーからの入力をそのままAIに渡さず、入力値の検証（バリデーション）やフィルタリングを行う。",
      "explanation": "入力値のサニタイズや、意図しない命令が含まれていないかの事前チェックが有効な防御策です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト",
          "セキュリティ",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_052",
      "question": "2025年施行の「AI新法」等で採用されている、AIシステムを「高リスク（人命・インフラに関わる）」から「低リスク（チャットボット等）」などに分類し、リスクレベルに応じて規制の強さを変える考え方は何か。",
      "options": [
        "リスクベース・アプローチ",
        "ゼロリスク・アプローチ",
        "全面禁止アプローチ",
        "自由放任アプローチ"
      ],
      "correctAnswer": "リスクベース・アプローチ",
      "explanation": "イノベーションを阻害しないよう、リスクの大きさに応じて規制の濃淡をつける「リスクベース・アプローチ」が世界の主流です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "AIガバナンス",
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_053",
      "question": "「AI事業者ガイドライン（第1.1版）」において、AIを利用して事業を行う企業（AI利用者）に求められる責務として、最も重要なものはどれか。",
      "options": [
        "AIが出した答えを無条件に信じて実行すること。",
        "AIモデルのプログラムコードを自力で修正すること。",
        "AIの利用について適切なリスク管理を行い、最終的な判断と責任は人間が持つ（Human-in-the-loop）こと。",
        "AIの開発者に全ての責任を押し付けること。"
      ],
      "correctAnswer": "AIの利用について適切なリスク管理を行い、最終的な判断と責任は人間が持つ（Human-in-the-loop）こと。",
      "explanation": "AIはあくまで支援ツールであり、それを使ったビジネス上の判断や結果責任は、利用者（人間・企業）にあります。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "AIガバナンス",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_054",
      "question": "生成AIで作成した画像が「著作権侵害」となる要件において、「依拠性（いきょせい）」とは何を指すか。",
      "options": [
        "画像が既存の著作物に似ていること。",
        "既存の著作物を知っており、それに基づいて（依拠して）作成したという事実。",
        "高性能なAIを使ったこと。",
        "画像が美しいこと。"
      ],
      "correctAnswer": "既存の著作物を知っており、それに基づいて（依拠して）作成したという事実。",
      "explanation": "「類似性（似ている）」だけでなく、「依拠性（元ネタを知っていて参考にした）」が認められて初めて侵害となります。偶然の一致は侵害になりません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_055",
      "question": "AI生成物が著作権法上の「著作物」として保護されるための条件である「創作的寄与」に該当する可能性が高い行為はどれか。",
      "options": [
        "短いプロンプト（呪文）を1回入力しただけで出力された画像。",
        "長大なプロンプトで詳細に指示し、何度も試行錯誤（ガチャ）を繰り返して選別し、さらには加筆修正を加えた画像。",
        "AIが勝手に生成した画像。",
        "誰も思いつかないような珍しいプロンプトを使ったが、出力は1回のみ。"
      ],
      "correctAnswer": "長大なプロンプトで詳細に指示し、何度も試行錯誤（ガチャ）を繰り返して選別し、さらには加筆修正を加えた画像。",
      "explanation": "人間の「創作的意図」と具体的な「寄与（試行錯誤や加筆）」があって初めて、人間がAIを道具として使った創作と認められます。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_056",
      "question": "EUのデータ保護規則「GDPR」において、AIの学習データに含まれる個人情報に関して、個人が行使できる強力な権利はどれか。",
      "options": [
        "忘れられる権利（削除権）",
        "データを販売する権利",
        "AIを停止させる権利",
        "AIの開発に参加する権利"
      ],
      "correctAnswer": "忘れられる権利（削除権）",
      "explanation": "自身の個人データの削除を求める「忘れられる権利」はGDPRの中核的な権利であり、AI学習データの削除請求の根拠となります。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_057",
      "question": "AI採用試験システムが、過去のデータを学習した結果、特定の性別や人種を不当に低く評価してしまう現象を何と呼ぶか。",
      "options": [
        "アルゴリズムバイアス（AIバイアス）",
        "オーバーフィッティング",
        "ハルシネーション",
        "シンギュラリティ"
      ],
      "correctAnswer": "アルゴリズムバイアス（AIバイアス）",
      "explanation": "学習データに含まれる社会的偏見がAIに継承・増幅される問題をAIバイアスと呼び、公平性の観点から対策が必要です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "additional",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_058",
      "question": "RAG（検索拡張生成）システムにおいて、ユーザーの質問の意味（ベクトル）と近い文書を探すために使用されるデータベースの種類は何か。",
      "options": [
        "リレーショナルデータベース (RDBMS)",
        "ベクトルデータベース (Vector DB)",
        "キーバリューストア (KVS)",
        "スプレッドシート"
      ],
      "correctAnswer": "ベクトルデータベース (Vector DB)",
      "explanation": "文章を数値ベクトル化（Embedding）し、意味の近さで検索を行うには、PineconeやChromaなどのベクトルデータベースが最適です。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "RAG",
          "エンベッディング",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_059",
      "question": "RAGの回答精度が低い場合、改善すべき点はどれか。",
      "options": [
        "チャンクサイズの最適化",
        "Temperatureを上げる",
        "プロンプトを短くする",
        "モデルを変更する"
      ],
      "correctAnswer": "チャンクサイズの最適化",
      "explanation": "RAGの回答精度が低い場合、チャンクのサイズが大きすぎたり小さすぎたりすることが原因の一つです。適切なサイズに最適化することで精度が向上します。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "RAG",
          "チャンク分割",
          "生成AIの動向"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_060",
      "question": "AIエージェントの実装方式において、定型的な業務（経費精算など）をミスなく遂行させるのに適しているのは「自律型」と「ワークフロー型」のどちらか。",
      "options": [
        "ワークフロー型（あらかじめ手順を定義する）",
        "自律型（目標だけ与えて自由にやらせる）",
        "どちらも適していない",
        "ランダム型"
      ],
      "correctAnswer": "ワークフロー型（あらかじめ手順を定義する）",
      "explanation": "手順が決まっている定型業務には、RPAのようにフローを固定する「ワークフロー型」が安定性と確実性の面で適しています。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_062",
      "question": "2025年にOpenAIが公開した「Operator」や、Googleの「Project Astra」などが目指している、AIエージェントの新たな利用形態はどれか。",
      "options": [
        "ユーザーの代わりにPC画面を見ながら、ブラウザ操作やアプリ操作を自律的に代行する（Computer Use）。",
        "チェスで人間に勝つ。",
        "高速に計算する。",
        "動画を高画質化する。"
      ],
      "correctAnswer": "ユーザーの代わりにPC画面を見ながら、ブラウザ操作やアプリ操作を自律的に代行する（Computer Use）。",
      "explanation": "最新のエージェントは、APIだけでなく、人間と同じようにGUI（画面）を操作してタスクをこなす「Computer Use / Browser Use」へと進化しています。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "additional",
        "tags": [
          "Gemini",
          "生成AIの動向",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_063",
      "question": "推論モデル（o1など）が内部で自動的に行っている処理はどれか。",
      "options": [
        "Chain-of-Thought（思考の連鎖）を自動的に実行し、中間ステップを経てから回答を生成する",
        "画像を生成する",
        "音声を合成する",
        "動画を編集する"
      ],
      "correctAnswer": "Chain-of-Thought（思考の連鎖）を自動的に実行し、中間ステップを経てから回答を生成する",
      "explanation": "推論モデル（GPT-o1など）は内部で自動的にChain-of-Thoughtを実行し、じっくり考えてから回答を生成します。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "GPT",
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_064",
      "question": "特定の役割になりきらせることで、専門用語の使用や視座を固定できるというメリットは何か。",
      "options": [
        "ペルソナ設定（ロールプレイ）による回答品質の向上",
        "Temperatureの調整",
        "プロンプトの長さ",
        "モデルの選択"
      ],
      "correctAnswer": "ペルソナ設定（ロールプレイ）による回答品質の向上",
      "explanation": "ペルソナ設定により、AIは専門用語を適切に使用し、視座を固定することで回答の質が向上します。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_065",
      "question": "顧客アンケートの自由記述欄（テキストデータ）をAIで分析する際、最も効果的な活用方法はどれか。",
      "options": [
        "全ての文章を暗記させる。",
        "「ポジティブ・ネガティブ」の感情分析を行わせたり、頻出する要望を要約・グルーピングさせてインサイトを抽出する。",
        "誤字脱字だけを修正させる。",
        "そのまま放置する。"
      ],
      "correctAnswer": "「ポジティブ・ネガティブ」の感情分析を行わせたり、頻出する要望を要約・グルーピングさせてインサイトを抽出する。",
      "explanation": "大量のテキストから傾向や感情を分類・抽出（定性分析）するのは、LLMが最も得意とするタスクの一つです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_066",
      "question": "会議の議事録をAIに要約させる際、セキュリティ上最も注意すべきことは何か。",
      "options": [
        "要約が長すぎないか。",
        "会議の音声データや文字起こしデータが、AIモデルの学習に利用される設定になっていないか（オプトアウト等の確認）。",
        "AIが疲れていないか。",
        "インターネットの速度。"
      ],
      "correctAnswer": "会議の音声データや文字起こしデータが、AIモデルの学習に利用される設定になっていないか（オプトアウト等の確認）。",
      "explanation": "機密情報を含む会議データを学習に使われると、他社への回答で漏洩するリスクがあります。オプトアウトやエンタープライズ版の利用が必須です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "additional",
        "tags": [
          "リスク管理",
          "プロンプト制作",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "add_231",
      "question": "生成AIがテキストを処理する際、文章を単語や文字の断片といった最小単位に分解する処理を何と呼ぶか。また、この単位の違いが日本語と英語のコスト差にどう影響するか。",
      "options": [
        "トークン化（Tokenization）。日本語は英語に比べ、同じ意味でもトークン数が多くなりがちである。",
        "エンベッディング。日本語は英語に比べ、トークン数が少なくなる。",
        "チャンキング。日本語と英語でトークン数に違いはない。",
        "ベクトル化。コストには影響しない。"
      ],
      "correctAnswer": "トークン化（Tokenization）。日本語は英語に比べ、同じ意味でもトークン数が多くなりがちである。",
      "explanation": "トークン化は、文章を処理可能な最小単位（トークン）に分解する処理です。日本語は文字体系が複雑なため、同じ意味の文章でも英語よりトークン数が多くなりがちで、これがコスト差の原因となります。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "AI基礎",
          "トークン化"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_232",
      "question": "RAGや検索システムにおいて、文章の意味をコンピュータが計算可能な「数値の列（多次元の座標）」に変換する技術を何と呼ぶか。",
      "options": [
        "エンベッディング（埋め込み表現）",
        "トークン化",
        "チャンキング",
        "ファインチューニング"
      ],
      "correctAnswer": "エンベッディング（埋め込み表現）",
      "explanation": "エンベッディングは、文章の意味を数値ベクトル（多次元の座標）に変換する技術です。これにより、意味の近さを数値計算で比較できるようになり、RAGの検索精度向上に不可欠です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "RAG",
          "AI基礎",
          "エンベッディング"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_233",
      "question": "Transformerモデルの中核機能であり、文章中の「どの単語が他のどの単語と強く関連しているか」という重要度（重み）を計算する仕組みは何か。",
      "options": [
        "自己注意機構（Self-Attention）",
        "畳み込みニューラルネットワーク（CNN）",
        "リカレントニューラルネットワーク（RNN）",
        "活性化関数（Activation Function）"
      ],
      "correctAnswer": "自己注意機構（Self-Attention）",
      "explanation": "自己注意機構（Self-Attention）は、Transformerモデルの中核技術です。文章内の各単語が他の単語とどの程度関連しているかを計算し、文脈を理解する上で重要な役割を果たします。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "AI基礎",
          "Transformer"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_234",
      "question": "LLMの出力パラメータ「Temperature」を「0」にした場合、AIの挙動はどうなるか。最も普遍的な性質を選べ。",
      "options": [
        "最も確率の高い単語だけを選び続けるため、同じ入力に対してほぼ毎回同じ回答（決定論的挙動）をするようになる。",
        "ランダムに単語を選ぶため、毎回異なる回答になる。",
        "回答が止まらなくなる。",
        "エラーが発生する。"
      ],
      "correctAnswer": "最も確率の高い単語だけを選び続けるため、同じ入力に対してほぼ毎回同じ回答（決定論的挙動）をするようになる。",
      "explanation": "Temperatureを0に設定すると、AIは最も確率の高い単語のみを選択するようになり、同じ入力に対して毎回ほぼ同じ回答を生成します（決定論的挙動）。論理的なタスクや一貫性が求められる場面で有効です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_235",
      "question": "LLMが一度の処理で記憶・参照できる情報量（会話履歴や入力データ）の上限を指す専門用語は何か。これを超えると過去の会話を忘れる原因となる。",
      "options": [
        "コンテキストウィンドウ（文脈長）",
        "トークン数",
        "パラメータ数",
        "レイヤー数"
      ],
      "correctAnswer": "コンテキストウィンドウ（文脈長）",
      "explanation": "コンテキストウィンドウは、LLMが一度に処理できる情報量の上限を指します。これを超えると、過去の会話や文脈を忘れてしまい、回答の質が低下します。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_236",
      "question": "巨大で高性能なモデル（教師モデル）の知識を、軽量なモデル（生徒モデル）に学習させ、性能を保ちながらサイズを小型化する手法を何と呼ぶか。",
      "options": [
        "知識の蒸留（Knowledge Distillation）",
        "ファインチューニング",
        "転移学習",
        "データ拡張"
      ],
      "correctAnswer": "知識の蒸留（Knowledge Distillation）",
      "explanation": "知識の蒸留は、大きなモデルの知識を小さなモデルに移す技術です。エッジデバイスやモバイル端末でのAI活用において、性能を保ちながらモデルサイズを削減する重要な手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_237",
      "question": "画像とテキストを同時に理解するAIにおいて、画像データをテキストと同じ空間（ベクトル空間）に配置することで、相互の関係性を学習させるアプローチを何と呼ぶか。",
      "options": [
        "マルチモーダル学習（または結合埋め込み）",
        "単一モーダル学習",
        "トークン化",
        "チャンキング"
      ],
      "correctAnswer": "マルチモーダル学習（または結合埋め込み）",
      "explanation": "マルチモーダル学習では、異なる種類のデータ（画像とテキストなど）を共通のベクトル空間にマッピングすることで、相互の関係性を学習します。これにより、画像とテキストを統合的に理解できるようになります。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "AI基礎",
          "マルチモーダル"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_238",
      "question": "LLMの学習プロセスにおいて、単に「次の単語を予測する」だけでなく、「人間の価値観や意図に沿った、役に立つ安全な回答」をするように調整する工程を何と呼ぶか。",
      "options": [
        "アライメント（Alignment）",
        "ファインチューニング",
        "プレトレーニング",
        "トークン化"
      ],
      "correctAnswer": "アライメント（Alignment）",
      "explanation": "アライメントは、AIの出力を人間の価値観や意図に合わせる調整プロセスです。RLHF（人間からのフィードバックによる強化学習）などを用いて、有用で安全な回答ができるようにモデルを調整します。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "final",
        "tags": [
          "AI基礎",
          "RLHF"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_239",
      "question": "ディープラーニングの内部計算が複雑すぎて、なぜその結論に至ったのか人間には理解できない問題を「ブラックボックス問題」と呼ぶ。これに対し、判断根拠を人間にわかる形で提示しようとする技術分野を何と呼ぶか。",
      "options": [
        "説明可能なAI（XAI: Explainable AI）",
        "ブラックボックスAI",
        "決定木モデル",
        "統計的学習"
      ],
      "correctAnswer": "説明可能なAI（XAI: Explainable AI）",
      "explanation": "XAI（説明可能なAI）は、AIの判断根拠を人間が理解できる形で説明する技術分野です。特に医療や金融など、判断の透明性が重要な領域で必要とされています。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "final",
        "tags": [
          "ディープラーニング",
          "法律・倫理"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_240",
      "question": "新しい科学技術（AIなど）を社会実装する際に考慮すべき、「倫理的（Ethical）」「法的（Legal）」「社会的（Social）」な課題の総称は何か。",
      "options": [
        "ELSI（エルシー）",
        "ESG",
        "GDPR",
        "AI新法"
      ],
      "correctAnswer": "ELSI（エルシー）",
      "explanation": "ELSIは、Ethical（倫理的）、Legal（法的）、Social（社会的）、Issues（課題）の略称です。新しい科学技術を社会に導入する際に考慮すべき多角的な課題を指します。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "final",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_241",
      "question": "おすすめAI（レコメンド）の影響で、自分に心地よい情報ばかりが表示され、異なる意見から隔離されてしまう現象を何と呼ぶか。",
      "options": [
        "フィルターバブル（またはエコーチェンバー現象）",
        "エコーチェンバーのみ",
        "情報リテラシー",
        "認知バイアス"
      ],
      "correctAnswer": "フィルターバブル（またはエコーチェンバー現象）",
      "explanation": "フィルターバブルは、アルゴリズムがユーザーの好みに合わせて情報を選別することで、多様な意見に触れる機会が減り、自分の意見と似た情報ばかりに囲まれる現象です。民主主義や多様性の観点から問題とされています。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "final",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_242",
      "question": "AIの目的関数（ゴール設定）が、人間の本来の意図や倫理観と微妙にズレていた場合に、AIが予期せぬ危険な行動をとってしまうリスクを何と呼ぶか。",
      "options": [
        "アライメント問題（価値整合性問題）",
        "ハルシネーション",
        "オーバーフィッティング",
        "データバイアス"
      ],
      "correctAnswer": "アライメント問題（価値整合性問題）",
      "explanation": "アライメント問題は、AIの目的設定が人間の意図とずれている場合に発生する問題です。例えば、「クリック数を最大化する」という目的が、「ユーザーに有害なコンテンツを推奨する」という結果につながる可能性があります。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "final",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_243",
      "question": "運用中のAIに対し、悪意あるデータを学習データに混入させることで、AIの判断ルールを密かに書き換え、誤動作やバックドアを仕掛ける攻撃手法は何か。",
      "options": [
        "データ・ポイズニング（Data Poisoning）",
        "プロンプトインジェクション",
        "SQLインジェクション",
        "DDoS攻撃"
      ],
      "correctAnswer": "データ・ポイズニング（Data Poisoning）",
      "explanation": "データ・ポイズニングは、学習データに悪意あるデータを混入させることで、AIの判断を歪める攻撃手法です。特定の条件で誤動作するバックドアを仕込むことも可能で、セキュリティ上の重大な脅威です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "final",
        "tags": [
          "法律・倫理",
          "セキュリティ"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_244",
      "question": "完全自動化のリスクを避けるため、AIの判断プロセスや最終決定の中に必ず人間が介在し、監視や修正を行う運用体制を何と呼ぶか。",
      "options": [
        "Human-in-the-loop（人間参加型）",
        "完全自動化",
        "AI主導型",
        "機械学習主導"
      ],
      "correctAnswer": "Human-in-the-loop（人間参加型）",
      "explanation": "Human-in-the-loopは、AIの判断プロセスに人間が参加し、監視や最終判断を行う運用体制です。特に医療診断や採用選考など、影響が大きい意思決定では必須とされています。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "final",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_245",
      "question": "一般的なクラウドAIサービスにおいて、Webブラウザ経由の利用（チャット画面）と、API経由の利用での「データ学習ポリシー」の一般的な違いは何か。",
      "options": [
        "API経由の利用は、デフォルトで「入力データを学習に使わない（ゼロデータリテンション）」規約になっていることが多い（企業利用向け）。",
        "どちらも同じポリシーである。",
        "ブラウザ経由の方が安全である。",
        "API経由の方が必ず学習に使われる。"
      ],
      "correctAnswer": "API経由の利用は、デフォルトで「入力データを学習に使わない（ゼロデータリテンション）」規約になっていることが多い（企業利用向け）。",
      "explanation": "企業利用を想定したAPI経由の利用では、機密情報の保護のため、デフォルトで入力データを学習に使わない（ゼロデータリテンション）設定になっていることが一般的です。ブラウザ経由の利用では学習に使われる可能性があるため、規約の確認が重要です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "final",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_246",
      "question": "リアルタイム対話システム（音声対話など）を構築する際、モデル選定で最も重視すべき指標は「生成の質」よりも何か。",
      "options": [
        "レイテンシ（最初のトークンが出力されるまでの遅延時間）",
        "トークン数",
        "パラメータ数",
        "学習データ量"
      ],
      "correctAnswer": "レイテンシ（最初のトークンが出力されるまでの遅延時間）",
      "explanation": "リアルタイム対話システムでは、ユーザーが待つ時間を最小化することが重要です。そのため、回答の質よりも、最初のトークンが出力されるまでの遅延時間（レイテンシ）を重視すべきです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "final",
        "tags": [
          "トークン化",
          "プロンプト制作"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_247",
      "question": "生成AIの出力結果を固定し、何度実行しても同じ結果が得られるようにしたい場合、プログラミング側で固定すべき値は何か。",
      "options": [
        "シード値（Seed）",
        "Temperature",
        "Top-p",
        "Max Tokens"
      ],
      "correctAnswer": "シード値（Seed）",
      "explanation": "シード値を固定することで、乱数生成の初期状態が決まり、同じ入力に対して同じ出力を得ることができます。再現性が必要なテストやデモなどで重要です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "final",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_248",
      "question": "RAGと比較した際、ファインチューニング（追加学習）の運用上の最大のデメリットは何か。",
      "options": [
        "情報が更新されるたびに再学習が必要で、コストと時間がかかること（知識の即時更新が苦手）。",
        "精度が低いこと",
        "実装が難しいこと",
        "セキュリティが弱いこと"
      ],
      "correctAnswer": "情報が更新されるたびに再学習が必要で、コストと時間がかかること（知識の即時更新が苦手）。",
      "explanation": "ファインチューニングは、新しい情報を反映するためにモデル全体の再学習が必要です。一方、RAGは外部データベースを更新するだけで最新情報に対応できるため、運用コストと時間の面で有利です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "final",
        "tags": [
          "RAG",
          "プロンプト制作"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_249",
      "question": "生成AIが入出力する内容を監視し、差別用語や機密情報、プロンプトインジェクションなどが含まれていないかチェックして遮断する仕組みを総称して何と呼ぶか。",
      "options": [
        "ガードレール（AIファイアウォール）",
        "ファイアウォール",
        "アンチウイルス",
        "暗号化"
      ],
      "correctAnswer": "ガードレール（AIファイアウォール）",
      "explanation": "ガードレールは、AIの入出力を監視し、不適切な内容（差別的表現、機密情報、攻撃的なプロンプトなど）を検出・遮断する安全機構です。企業でのAI導入において必須のセキュリティ対策です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "final",
        "tags": [
          "プロンプト制作",
          "セキュリティ",
          "プロンプト"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "add_250",
      "question": "スマートフォンや車載器など、端末側（ローカル）でAIを動かす「エッジAI」の、クラウドAIと比較した際の最大のメリットは何か。",
      "options": [
        "通信遅延がない（リアルタイム性）こと、およびプライバシーデータが外部に出ないこと。",
        "計算能力が高いこと",
        "ストレージ容量が大きいこと",
        "インターネット接続が不要であることのみ"
      ],
      "correctAnswer": "通信遅延がない（リアルタイム性）こと、およびプライバシーデータが外部に出ないこと。",
      "explanation": "エッジAIの最大のメリットは、通信遅延がないためリアルタイム処理が可能なことと、データが端末内で処理されるためプライバシーが保護されることです。自動運転や医療機器など、即座の判断とプライバシーが重要な場面で活用されます。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "final",
        "tags": [
          "個人情報保護",
          "プロンプト制作"
        ],
        "difficulty": "hard",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_001",
      "question": "「ANI」「AGI」の説明として、最も正しい記述を1つ選びなさい",
      "options": [
        "ANIは特定のタスクを実行するために設計されたAIで、AGIは人間と同じレベルの認知能力を持つAIを指す",
        "ANIは人間と対話する能力を持つAIで、AGIは人間と対話する能力を持たないAIを指す",
        "ANIは既に商用化されているAIで、AGIは実用化される直前のAIを指す",
        "ANIは複数のタスクを同時に実行する能力を持つAIで、AGIは1つのタスクに特化したAIを指す"
      ],
      "correctAnswer": "ANIは特定のタスクを実行するために設計されたAIで、AGIは人間と同じレベルの認知能力を持つAIを指す",
      "explanation": "ANI（Artificial Narrow Intelligence）は特定のタスクに特化したAI、AGI（Artificial General Intelligence）は人間と同等の汎用的な知能を持つAIです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_002",
      "question": "三度のAIブームに関する記述として正しい文章を1つ選びなさい",
      "options": [
        "第二次AIブームは1990年代に始まり、ルールベースのシステムが注目された",
        "第三次AIブームは2010年代に始まり、ビッグデータの活用とディープラーニング技術の発展が主な特徴である",
        "第一次AIブームではエキスパートシステムが主に開発され、その結果としてAIの非実用的なシステムが増えたため「AIの冬」が訪れた",
        "第二次AIブームでは、ビッグデータとディープラーニングが主に活用され、AI技術が広く普及した"
      ],
      "correctAnswer": "第三次AIブームは2010年代に始まり、ビッグデータの活用とディープラーニング技術の発展が主な特徴である",
      "explanation": "第三次AIブームは2010年代から始まり、ビッグデータの活用とディープラーニング技術の発展が主な特徴です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "ディープラーニング"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_003",
      "question": "クラスタリングについて正しく説明している文章を1つ選びなさい",
      "options": [
        "与えられたデータを似た特徴やパターンを持つグループに分類することである",
        "データの未知の因果関連を予測するための統計的手法である",
        "過去のデータを基に未来の値を予測する手法である",
        "与えられたデータをランダムに2つのグループに分ける手法である"
      ],
      "correctAnswer": "与えられたデータを似た特徴やパターンを持つグループに分類することである",
      "explanation": "クラスタリングは、データを似た特徴やパターンを持つグループに分類する教師なし学習の手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_004",
      "question": "過学習を防ぐための代表的な手法をすべて選びなさい（複数選択可）",
      "options": [
        "ドロップアウト",
        "シーケンスの並行処理",
        "RLHF",
        "正則化"
      ],
      "correctAnswer": [
        "ドロップアウト",
        "正則化"
      ],
      "explanation": "ドロップアウトと正則化は過学習を防ぐ代表的な手法です。シーケンスの並行処理やRLHFは過学習防止の手法ではありません。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "RLHF"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_005",
      "question": "ルールベースを用いたAIの問題点について正しく記述している文章を1つ選びなさい",
      "options": [
        "機械学習に比べ、簡単なタスクを遂行させる際にもコストが多くかかってしまう",
        "複雑な問題に対処するために大量のルールが必要であり、それらの管理が困難になる",
        "適切な量の高品質な訓練データがない場合、モデルは適切に学習できないことがある",
        "条件分岐が多い問題に対して対処することができない"
      ],
      "correctAnswer": "複雑な問題に対処するために大量のルールが必要であり、それらの管理が困難になる",
      "explanation": "ルールベースAIは複雑な問題に対処するため大量のルールが必要となり、それらの管理が困難になることが主な問題点です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_006",
      "question": "転移学習について正しく説明している文章を1つ選びなさい",
      "options": [
        "学習済みのモデルを捨て、新しいタスクに対して完全に新しいモデルを作り直す手法",
        "1つの問題で学習したモデルの知識を、別の問題へ適用する手法",
        "異なるタスク間で交互にデータセットを与え学習を行う手法",
        "複数の異なるデータセットを同時に学習する手法"
      ],
      "correctAnswer": "1つの問題で学習したモデルの知識を、別の問題へ適用する手法",
      "explanation": "転移学習は、1つの問題で学習したモデルの知識を、別の問題へ適用する手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_007",
      "question": "「第一次AIブーム」の説明として誤っている記述を1つ選びなさい",
      "options": [
        "ブーム中に自然言語処理や機械学習などの新しい技術が発展した",
        "30年以上もの期間にわたって続き、主に自然言語処理と機械学習に焦点を当てたAI研究が進展した",
        "ルールベースのシステムが複雑な問題に対応できないことが明らかになったことで、急速に終息した",
        "1956年にダートマス会議で始まり、主に探索と推論に焦点を当てたAI研究が進展した"
      ],
      "correctAnswer": "30年以上もの期間にわたって続き、主に自然言語処理と機械学習に焦点を当てたAI研究が進展した",
      "explanation": "第一次AIブームは1956年〜1970年代で、約15年程度の期間でした。30年以上続いたという記述は誤りです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_008",
      "question": "AIのバイアスが生じる主な原因は何か",
      "options": [
        "学習データに含まれる人間のバイアス",
        "AIの計算能力の限界",
        "ハードウェアの性能",
        "プログラミング言語の制約"
      ],
      "correctAnswer": "学習データに含まれる人間のバイアス",
      "explanation": "AIのバイアスは、学習データに含まれる人間の偏見や社会的なバイアスが反映されることで生じます。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_009",
      "question": "AIと機械学習の関係について、最も適切な説明を1つ選びなさい",
      "options": [
        "AIと機械学習は全く異なる技術である",
        "機械学習はAIを実現するための手法の一つである",
        "AIは機械学習の一部の技術である",
        "AIと機械学習は同じ意味である"
      ],
      "correctAnswer": "機械学習はAIを実現するための手法の一つである",
      "explanation": "機械学習は、AIを実現するための主要な手法の一つです。AIはより広い概念で、機械学習以外の手法も含みます。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "機械学習",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_010",
      "question": "教師あり学習の特徴として最も適切なものはどれか",
      "options": [
        "正解データを与えずにパターンを発見する",
        "入力データと正解データのペアで学習する",
        "報酬を最大化するように行動を学習する",
        "データの次元を削減して特徴を抽出する"
      ],
      "correctAnswer": "入力データと正解データのペアで学習する",
      "explanation": "教師あり学習は、入力データと正解データ（ラベル）のペアを使用してモデルを訓練する機械学習手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "機械学習",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_011",
      "question": "教師なし学習の代表的な手法として適切なものはどれか",
      "options": [
        "クラスタリング",
        "分類",
        "回帰",
        "強化学習"
      ],
      "correctAnswer": "クラスタリング",
      "explanation": "クラスタリングは、正解データを使わずにデータのパターンや構造を発見する教師なし学習の代表的な手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_012",
      "question": "強化学習の特徴として最も適切なものはどれか",
      "options": [
        "大量の教師データが必要である",
        "環境との相互作用を通じて最適な行動を学習する",
        "データの分類に特化している",
        "事前に正解が分かっている問題のみ解決できる"
      ],
      "correctAnswer": "環境との相互作用を通じて最適な行動を学習する",
      "explanation": "強化学習は、環境との相互作用を通じて報酬を最大化する最適な行動を学習する手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_013",
      "question": "ニューラルネットワークの基本構成要素として正しくないものはどれか",
      "options": [
        "ニューロン（ノード）",
        "重み（ウェイト）",
        "活性化関数",
        "クラスタ"
      ],
      "correctAnswer": "クラスタ",
      "explanation": "クラスタはクラスタリング手法で使用される概念で、ニューラルネットワークの基本構成要素ではありません。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_014",
      "question": "ディープラーニングがニューラルネットワークと異なる点として最も適切なものはどれか",
      "options": [
        "活性化関数を使用しない",
        "多層構造を持つ",
        "重みを使用しない",
        "学習を行わない"
      ],
      "correctAnswer": "多層構造を持つ",
      "explanation": "ディープラーニングは、多層（深層）のニューラルネットワークを使用することが特徴です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "ディープラーニング"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_015",
      "question": "過学習（オーバーフィッティング）の説明として正しいものはどれか",
      "options": [
        "訓練データに対して十分な精度が出ない現象",
        "訓練データには適合するが新しいデータに対する予測精度が低下する現象",
        "モデルが複雑すぎて計算できない現象",
        "学習時間が長すぎて実用的でない現象"
      ],
      "correctAnswer": "訓練データには適合するが新しいデータに対する予測精度が低下する現象",
      "explanation": "過学習は、モデルが訓練データに過度に適合し、未知のデータに対する汎化性能が低下する現象です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_016",
      "question": "シンギュラリティ（技術的特異点）について最も適切な説明はどれか",
      "options": [
        "AIが人間を超越し、知能的に自己進化する状態",
        "コンピュータの処理速度が光速に達する状態",
        "インターネットが世界中に普及した状態",
        "ロボットが人間の仕事をすべて代替する状態"
      ],
      "correctAnswer": "AIが人間を超越し、知能的に自己進化する状態",
      "explanation": "シンギュラリティは、AIが人間の知能を超越し、自己進化を繰り返す技術的特異点を指します。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_017",
      "question": "AI効果について最も適切な説明はどれか",
      "options": [
        "AIの性能が急激に向上する現象",
        "AI技術に対する過剰な期待から実際の使用時に失望する心理現象",
        "AIが人間の能力を拡張する効果",
        "AI技術の普及により社会が変化する現象"
      ],
      "correctAnswer": "AI技術に対する過剰な期待から実際の使用時に失望する心理現象",
      "explanation": "AI効果は、AI技術に対する過剰な期待から、実際の使用や技術を知った際に失望してしまう心理現象です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_018",
      "question": "半教師あり学習の特徴として最も適切なものはどれか",
      "options": [
        "一部のデータにのみ正解ラベルが付いている",
        "すべてのデータに正解ラベルが付いている",
        "どのデータにも正解ラベルが付いていない",
        "報酬によって学習を行う"
      ],
      "correctAnswer": "一部のデータにのみ正解ラベルが付いている",
      "explanation": "半教師あり学習は、一部のデータにのみ正解ラベルが付いている状況で学習を行う手法です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_019",
      "question": "機械学習におけるバイアスとバリアンスについて正しい説明はどれか",
      "options": [
        "バイアスが高いと過学習が起こりやすい",
        "バリアンスが高いと過学習が起こりやすい",
        "バイアスとバリアンスは同じ概念である",
        "バイアスとバリアンスは機械学習に関係ない"
      ],
      "correctAnswer": "バリアンスが高いと過学習が起こりやすい",
      "explanation": "バリアンスが高いモデルは訓練データの小さな変化に敏感で、過学習を起こしやすくなります。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "機械学習",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_020",
      "question": "AI研究の歴史で「AIの冬」と呼ばれる時期について正しい説明はどれか",
      "options": [
        "AI研究が最も活発だった時期",
        "AI技術が大きく発展した時期",
        "AI研究への期待が高まった時期",
        "AI研究への関心や投資が低下した時期"
      ],
      "correctAnswer": "AI研究への関心や投資が低下した時期",
      "explanation": "「AIの冬」は、AIブームの終息後にAI研究への関心や投資が大幅に減少した時期を指します。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_021",
      "question": "LSTMの特徴として不適切な記述を1つ選びなさい",
      "options": [
        "大規模データの学習には時間がかかる",
        "長文の自然言語を処理すると精度が低下する",
        "シーケンスデータを処理するネットワークである",
        "並列学習に適している"
      ],
      "correctAnswer": "並列学習に適している",
      "explanation": "LSTMは時系列データの処理に適していますが、並列学習には適していません。RNNベースのモデルは順次処理が基本となります。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "LSTM",
          "RNN"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_022",
      "question": "BERTモデルの特徴の1つにNSPが挙げられる。NSPの特徴として最も適切な文章を1つ選びなさい",
      "options": [
        "各単語がテキスト全体にどの程度影響を与えるかをモデルが理解するメカニズムである",
        "ある文が別の文の直後に来るかを予測するためのメカニズムである",
        "単語の順序情報を保持するメカニズムである",
        "現在の単語の次に来る単語を予測するためのメカニズムである"
      ],
      "correctAnswer": "ある文が別の文の直後に来るかを予測するためのメカニズムである",
      "explanation": "NSP（Next Sentence Prediction）は、ある文が別の文の直後に来るかを予測するためのBERTの事前学習タスクです。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_023",
      "question": "RNNの仕組みについて正しく説明している文章を1つ選びなさい",
      "options": [
        "次の時刻の隠れ層の出力を予想し、現時刻の隠れ層に入力を行う",
        "同じ入力に対しては常に同じ出力を返す性質を持つ",
        "過去の情報を記憶しながら新たな情報を処理することが可能である",
        "時系列データを扱うことができない"
      ],
      "correctAnswer": "過去の情報を記憶しながら新たな情報を処理することが可能である",
      "explanation": "RNNは、過去の情報を記憶しながら新たな情報を処理することが可能な特性を持ち、時系列データの処理に適しています。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "RNN"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_024",
      "question": "画像生成AIの主なデータ生成手法として不適切な選択肢を全て選びなさい",
      "options": [
        "RNN",
        "CNN",
        "GAN",
        "VAE"
      ],
      "correctAnswer": "RNN",
      "explanation": "GAN、VAE、CNNは画像生成AIで使用される手法ですが、RNNは主に時系列データ処理に使用され、画像生成の主要手法ではありません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "GAN",
          "VAE",
          "CNN",
          "RNN"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_025",
      "question": "動画生成は（　）ため、各フレーム間の一貫性を保つことが重要である。（　）に当てはまる文章として、正しい選択肢を1つ選びなさい",
      "options": [
        "色彩ごとに分割された画像の集合である",
        "仮想空間に羅列されたピクセルの集合である",
        "製作者の意図が反映されている",
        "時間的に連続するフレームの集合である"
      ],
      "correctAnswer": "時間的に連続するフレームの集合である",
      "explanation": "動画は時間的に連続するフレームの集合であるため、各フレーム間の一貫性を保つことが重要です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_026",
      "question": "動画生成AIを利用する際のメリットについて、最も不適切な記述をしている文章を1つ選びなさい",
      "options": [
        "既存の映像や動画を元に新しい映像を生成することができる",
        "特殊効果やリアルな視聴効果を生成することができる",
        "既存の映像コンテンツの雰囲気にあった音楽を挿入することができる",
        "映像内の特定の要素を自動的に非表示にすることができる"
      ],
      "correctAnswer": "既存の映像コンテンツの雰囲気にあった音楽を挿入することができる",
      "explanation": "動画生成AIは主に映像の生成に特化しており、音楽の挿入は直接的なメリットではありません。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_027",
      "question": "ALBERTは、どのモデルを軽量にすることを目的として開発されたか。最も正しい選択肢を1つ選びなさい",
      "options": [
        "BERTを軽量にするモデルである",
        "GPT-3を軽量にするモデルである",
        "RoBERTaを軽量にするモデルである",
        "Transformerを軽量にするモデルである"
      ],
      "correctAnswer": "BERTを軽量にするモデルである",
      "explanation": "ALBERT（A Lite BERT）は、BERTを軽量化することを目的として開発されたモデルです。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_028",
      "question": "コンピュータが自然言語の複雑さや曖昧さを扱いながら、テキストデータを理解・生成するために必要な技術の総称として最も適切な選択肢を1つ選びなさい",
      "options": [
        "RNN",
        "NLP",
        "GAN",
        "VAE"
      ],
      "correctAnswer": "NLP",
      "explanation": "NLP（Natural Language Processing：自然言語処理）は、コンピュータが自然言語を理解・生成するために必要な技術の総称です。",
      "metadata": {
        "chapter": 0,
        "category": "その他",
        "source": "old_100",
        "tags": [],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_029",
      "question": "「Masked Language Model」に関して、不適切な記述をしている文章を1つ選びなさい",
      "options": [
        "ランダムに選んだ単語をマスクする",
        "語順通りだけでなく、その逆からも読むことを実現している",
        "ランダムにマスクされた単語の位置を予測する",
        "マスクされた部分を予測するために前後の単語のすべての情報を利用する"
      ],
      "correctAnswer": "ランダムにマスクされた単語の位置を予測する",
      "explanation": "Masked Language Modelは、マスクされた単語の「位置」ではなく「内容（単語そのもの）」を予測します。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_030",
      "question": "VAEにおけるエンコーダとデコーダについて、最も適切な説明をしている文章を1つ選びなさい",
      "options": [
        "VAEのエンコーダは入力データを潜在ベクトルに変換し、デコーダはその潜在ベクトルから元のデータを生成する",
        "VAEのエンコーダとデコーダは両方とも元のデータを再現する",
        "VAEのエンコーダは元のデータを再現し、デコーダはノイズを除去する",
        "VAEのデコーダは入力データを潜在ベクトルに変換し、エンコーダはその潜在ベクトルから元のデータを生成する"
      ],
      "correctAnswer": "VAEのエンコーダは入力データを潜在ベクトルに変換し、デコーダはその潜在ベクトルから元のデータを生成する",
      "explanation": "VAEでは、エンコーダが入力データを潜在ベクトルに変換し、デコーダがその潜在ベクトルから元のデータを生成します。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "VAE"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_031",
      "question": "GANにおける生成器（Generator）と識別器（Discriminator）の関係として最も適切なものはどれか",
      "options": [
        "生成器と識別器は協力してデータを生成する",
        "生成器と識別器は互いに競い合いながら性能を向上させる",
        "生成器が識別器を制御してデータを生成する",
        "識別器が生成器を制御してデータを判別する"
      ],
      "correctAnswer": "生成器と識別器は互いに競い合いながら性能を向上させる",
      "explanation": "GANでは、生成器と識別器が敵対的に競い合うことで、より高品質な生成データを作り出します。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "GAN",
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_032",
      "question": "Transformerモデルの革新的な機能として最も適切なものはどれか",
      "options": [
        "自己注意機構（Self-Attention）",
        "畳み込み演算",
        "リカレント構造",
        "勾配消失対策"
      ],
      "correctAnswer": "自己注意機構（Self-Attention）",
      "explanation": "Transformerの革新的な機能は自己注意機構で、これにより並列処理と長距離依存関係の学習が可能になりました。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "Transformer"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_033",
      "question": "GPT-3の特徴として最も適切でないものはどれか",
      "options": [
        "1750億個のパラメータを持つ",
        "RLHF（人間のフィードバックからの強化学習）を使用",
        "微調整なしで多様なタスクを実行可能",
        "大規模な事前学習を行っている"
      ],
      "correctAnswer": "RLHF（人間のフィードバックからの強化学習）を使用",
      "explanation": "RLHFはGPT-3.5（InstructGPT）以降で導入された技術で、GPT-3には使用されていません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "GPT",
          "RLHF"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_034",
      "question": "CNNが画像認識に適している理由として最も適切なものはどれか",
      "options": [
        "時系列データの処理に優れているため",
        "局所的な特徴を効率的に抽出できるため",
        "自然言語処理に特化しているため",
        "リカレント構造を持っているため"
      ],
      "correctAnswer": "局所的な特徴を効率的に抽出できるため",
      "explanation": "CNNは畳み込み演算により画像の局所的な特徴を効率的に抽出できるため、画像認識に適しています。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "CNN"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_035",
      "question": "GPT-4の改善点として最も適切でないものはどれか",
      "options": [
        "ハルシネーションの減少",
        "マルチモーダル対応",
        "日本語生成精度の向上",
        "パラメータ数の大幅増加"
      ],
      "correctAnswer": "パラメータ数の大幅増加",
      "explanation": "GPT-4では性能向上が図られましたが、パラメータ数の大幅増加は主要な改善点として公表されていません。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "GPT"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_036",
      "question": "ChatGPTの名称の由来として正しいものはどれか",
      "options": [
        "Chat（対話）+ GPT（Generative Pre-trained Transformer）",
        "Character（文字）+ GPT（General Purpose Technology）",
        "Chatbot（チャットボット）+ GPT（Global Processing Technology）",
        "Communication（コミュニケーション）+ GPT（General Programming Tool）"
      ],
      "correctAnswer": "Chat（対話）+ GPT（Generative Pre-trained Transformer）",
      "explanation": "ChatGPTは「Chat（対話型）」と「GPT（Generative Pre-trained Transformer）」を組み合わせた名称です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "GPT",
          "Transformer"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_037",
      "question": "ディープフェイクの説明として最も適切なものはどれか",
      "options": [
        "AI技術を使用して実在しない人物の画像や動画を作成する技術",
        "データベースから情報を検索する技術",
        "音声認識の精度を向上させる技術",
        "自然言語翻訳の品質を改善する技術"
      ],
      "correctAnswer": "AI技術を使用して実在しない人物の画像や動画を作成する技術",
      "explanation": "ディープフェイクは、AI技術（特にGAN）を使用して、実際には存在しない人物の画像や動画を作成する技術です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "GAN",
          "AI基礎",
          "ディープフェイク"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_038",
      "question": "GPT-4oの「o」が表す意味として正しいものはどれか",
      "options": [
        "Omni（全ての）",
        "Original（オリジナル）",
        "Optimal（最適）",
        "Online（オンライン）"
      ],
      "correctAnswer": "Omni（全ての）",
      "explanation": "GPT-4oの「o」は「omni（全ての）」を意味し、テキスト、画像、音声を統合的に処理できるオムニモーダルモデルを表します。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "GPT",
          "マルチモーダル"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_039",
      "question": "生成AIの学習において、事前学習（Pre-training）の目的として最も適切なものはどれか",
      "options": [
        "特定のタスクに特化した性能を向上させる",
        "大量のデータから一般的な言語パターンを学習する",
        "人間のフィードバックを反映させる",
        "計算コストを削減する"
      ],
      "correctAnswer": "大量のデータから一般的な言語パターンを学習する",
      "explanation": "事前学習では、大量のテキストデータから一般的な言語パターンや知識を学習し、後の微調整の基盤を作ります。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_040",
      "question": "Code Interpreterの機能として最も適切な説明はどれか",
      "options": [
        "プログラムコードを自然言語に翻訳する機能",
        "ChatGPTがPythonコードを作成し実行できる機能",
        "コードの品質を評価する機能",
        "プログラミング言語間の変換を行う機能"
      ],
      "correctAnswer": "ChatGPTがPythonコードを作成し実行できる機能",
      "explanation": "Code InterpreterはChatGPTがPythonソースコードを作成し、自ら実行できる強力な拡張機能です。",
      "metadata": {
        "chapter": 2,
        "category": "第2章 生成AI（ジェネレーティブAI）",
        "source": "old_100",
        "tags": [
          "生成AI",
          "GPT"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_042",
      "question": "不正競争防止法が規制する行為のうち「周知の商品等表示主体の混同行為」にあたる行為を1つ選びなさい",
      "options": [
        "他人の商標を無断で使用する行為",
        "他人の商品を模倣した商品の譲渡などを行うことにより利益を得る行為",
        "他人の商品・営業表示として著名なものと同一又は類似のものを自己の商品・営業表示として使用し、利益を得る行為",
        "他人の商品や営業表示として、需要者の間で広く認識されているものと同一又は類似の表示をするなどして、他人の商品や営業と誤解させる行為"
      ],
      "correctAnswer": "他人の商品や営業表示として、需要者の間で広く認識されているものと同一又は類似の表示をするなどして、他人の商品や営業と誤解させる行為",
      "explanation": "周知の商品等表示主体の混同行為とは、他人の商品や営業表示として広く認識されているものと類似の表示により誤解を招く行為です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "AIガバナンス",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_043",
      "question": "AI生成物を商用利用する際に考慮すべきことについて述べた文章として、不適切な記述を1つ選びなさい",
      "options": [
        "権利者との適切な契約を通じて、合法的な利用が確保されていることを確認することが重要である",
        "特定の個人やブランドの名声、イメージを商用利用する場合、その権利を保持している個人や団体から許可を得る必要がある",
        "商用利用する前に著作権情報や利用規約を確認し、商用利用が許可されているかどうかを確認するべきである",
        "商用利用が許可されていることが確認できていれば、商用利用しても問題が発生することはない"
      ],
      "correctAnswer": "商用利用が許可されていることが確認できていれば、商用利用しても問題が発生することはない",
      "explanation": "商用利用が許可されていても、他の法的問題や倫理的問題が発生する可能性があるため、この記述は不適切です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_044",
      "question": "計算リソースが制限されている環境の例として不適切な記述を1つ選びなさい",
      "options": [
        "スマートフォンを使用する場合",
        "小さなバッテリーを使用した機器の場合",
        "低コストのパソコンを使用する場合",
        "大型のサーバーを使用する場合"
      ],
      "correctAnswer": "大型のサーバーを使用する場合",
      "explanation": "大型のサーバーは豊富な計算リソースを持つため、計算リソースが制限されている環境の例として不適切です。",
      "metadata": {
        "chapter": 0,
        "category": "その他",
        "source": "old_100",
        "tags": [],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_045",
      "question": "「AI事業者ガイドライン」において「AI開発者」に該当するものを全て選びなさい",
      "options": [
        "構築済みモデルを使用してAIツールの開発及び販売を行う事業者",
        "生成AIの研修を受けている個人",
        "LLMの新モデルについて研究を行い、モデルの構築を行う事業者",
        "AIを活用して社内の業務効率に取り組んでいる事業者"
      ],
      "correctAnswer": [
        "構築済みモデルを使用してAIツールの開発及び販売を行う事業者",
        "LLMの新モデルについて研究を行い、モデルの構築を行う事業者"
      ],
      "explanation": "AI開発者には、構築済みモデルを使用したAIツール開発事業者とLLMの新モデル構築を行う事業者が該当します。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "AIガバナンス",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_046",
      "question": "モデルの学習前に手動で設定・調整が可能で、モデルの複雑さや学習の進行度合いを制御することができるものを何というか。正しい選択肢を1つ選びなさい",
      "options": [
        "コンテキスト",
        "n-gramモデル",
        "API",
        "ハイパーパラメータ"
      ],
      "correctAnswer": "ハイパーパラメータ",
      "explanation": "ハイパーパラメータは、モデルの学習前に設定・調整し、モデルの複雑さや学習の進行度合いを制御するパラメータです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_047",
      "question": "個人情報保護法の目的として最も適切なものはどれか",
      "options": [
        "企業の利益を保護する",
        "個人の権利利益を保護する",
        "政府の権限を強化する",
        "技術の発展を促進する"
      ],
      "correctAnswer": "個人の権利利益を保護する",
      "explanation": "個人情報保護法は、個人の権利利益を保護することを目的として制定されています。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_048",
      "question": "セキュリティ脅威として「ソーシャルエンジニアリング」の説明で最も適切なものはどれか",
      "options": [
        "ソフトウェアの脆弱性を狙った攻撃",
        "人間の心理や行動を利用した攻撃",
        "ネットワークインフラへの物理的攻撃",
        "データベースへの直接的なハッキング"
      ],
      "correctAnswer": "人間の心理や行動を利用した攻撃",
      "explanation": "ソーシャルエンジニアリングは、人間の心理や行動の弱点を利用して情報を不正に取得する攻撃手法です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_049",
      "question": "著作権の保護期間について最も適切な記述はどれか",
      "options": [
        "著作者の死後30年まで",
        "著作者の死後50年まで",
        "著作者の死後70年まで",
        "著作者の死後100年まで"
      ],
      "correctAnswer": "著作者の死後70年まで",
      "explanation": "日本の著作権法では、原則として著作者の死後70年まで著作権が保護されます。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_050",
      "question": "AI技術の透明性（explainability）が重要な理由として最も適切でないものはどれか",
      "options": [
        "意思決定過程の理解促進",
        "責任の所在の明確化",
        "信頼性の向上",
        "計算速度の向上"
      ],
      "correctAnswer": "計算速度の向上",
      "explanation": "AI技術の透明性は主に信頼性や責任の観点で重要であり、計算速度の向上とは直接関係ありません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_051",
      "question": "プライバシー保護技術として注目される「差分プライバシー」の特徴として最も適切なものはどれか",
      "options": [
        "データを完全に匿名化する技術",
        "データに数学的なノイズを加えて個人を特定できなくする技術",
        "データを暗号化して保存する技術",
        "データアクセスを制限する技術"
      ],
      "correctAnswer": "データに数学的なノイズを加えて個人を特定できなくする技術",
      "explanation": "差分プライバシーは、データに数学的なノイズを加えることで、個人のプライバシーを保護しながらデータ分析を可能にする技術です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "個人情報保護",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_052",
      "question": "GDPR（一般データ保護規則）の主要な権利として含まれないものはどれか",
      "options": [
        "忘れられる権利",
        "データポータビリティの権利",
        "アクセス権",
        "データ販売権"
      ],
      "correctAnswer": "データ販売権",
      "explanation": "GDPRには「データ販売権」は含まれていません。個人データの保護が目的であり、販売権は認められていません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_053",
      "question": "AI倫理の原則として一般的に含まれないものはどれか",
      "options": [
        "公平性",
        "説明可能性",
        "利益最大化",
        "透明性"
      ],
      "correctAnswer": "利益最大化",
      "explanation": "AI倫理では公平性、説明可能性、透明性などが重視されますが、利益最大化は倫理原則には含まれません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "リスク管理",
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_054",
      "question": "知的財産権のうち、新しい技術的アイデアを保護するものはどれか",
      "options": [
        "著作権",
        "特許権",
        "商標権",
        "意匠権"
      ],
      "correctAnswer": "特許権",
      "explanation": "特許権は、新しい技術的アイデアや発明を保護する知的財産権です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_055",
      "question": "フィッシング攻撃の対策として最も効果的でないものはどれか",
      "options": [
        "URLの確認",
        "二要素認証の使用",
        "アンチウイルスソフトの更新",
        "パスワードの複雑化のみ"
      ],
      "correctAnswer": "パスワードの複雑化のみ",
      "explanation": "パスワードの複雑化は重要ですが、それだけではフィッシング攻撃の対策として不十分です。多層防御が必要です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理",
          "セキュリティ"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_056",
      "question": "クリエイティブ・コモンズライセンスの説明として最も適切なものはどれか",
      "options": [
        "商用利用を完全に禁止するライセンス",
        "著作者が利用条件を選択できる柔軟なライセンス",
        "政府のみが使用できるライセンス",
        "AI生成コンテンツ専用のライセンス"
      ],
      "correctAnswer": "著作者が利用条件を選択できる柔軟なライセンス",
      "explanation": "クリエイティブ・コモンズは、著作者が様々な利用条件を組み合わせて選択できる柔軟なライセンス体系です。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_057",
      "question": "AI生成コンテンツの著作権について現在の法的解釈として最も適切なものはどれか",
      "options": [
        "AI自体が著作者となる",
        "AIを使用した人間が著作者となる",
        "著作権は発生しない",
        "法的判断が確立されていない"
      ],
      "correctAnswer": "法的判断が確立されていない",
      "explanation": "AI生成コンテンツの著作権については、世界的にまだ法的判断が確立されておらず、議論が続いています。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理",
          "著作権"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_058",
      "question": "デジタル署名の主な目的として最も適切でないものはどれか",
      "options": [
        "送信者の認証",
        "データの改ざん検知",
        "否認防止",
        "データの圧縮"
      ],
      "correctAnswer": "データの圧縮",
      "explanation": "デジタル署名の目的は認証、改ざん検知、否認防止であり、データの圧縮は目的ではありません。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_059",
      "question": "AI技術の社会実装において重要な「アルゴリズムの監査」の目的として最も適切なものはどれか",
      "options": [
        "アルゴリズムの計算速度の向上",
        "アルゴリズムの公平性とバイアスの検証",
        "アルゴリズムのメモリ使用量の削減",
        "アルゴリズムの暗号化"
      ],
      "correctAnswer": "アルゴリズムの公平性とバイアスの検証",
      "explanation": "アルゴリズムの監査は、AIシステムが公平で偏見のない判断を行うかを検証することが主な目的です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_060",
      "question": "エッジコンピューティング環境でのAI利用における主要な課題として最も適切でないものはどれか",
      "options": [
        "計算リソースの制約",
        "リアルタイム処理の要求",
        "プライバシー保護の複雑さ",
        "クラウドストレージの容量不足"
      ],
      "correctAnswer": "クラウドストレージの容量不足",
      "explanation": "エッジコンピューティングは端末側での処理を重視するため、クラウドストレージの容量は主要な課題ではありません。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_061",
      "question": "テキスト生成AIにより処理可能なタスクとして最も不適切な記述を1つ選びなさい",
      "options": [
        "翻訳を行い、指定された言語に文章を変換することができる",
        "自動でユーザーの足りない栄養素を分析し、食事メニューを提案することができる",
        "様々なテーマに対してブレインストーミングを行うことができる",
        "口コミやアンケートデータを整理し、分析することができる"
      ],
      "correctAnswer": "自動でユーザーの足りない栄養素を分析し、食事メニューを提案することができる",
      "explanation": "テキスト生成AIは栄養素の分析や食事メニューの提案などの専門的な健康管理タスクは適切に処理できません。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_062",
      "question": "プロンプトエンジニアリングの目的として最も適切なものはどれか",
      "options": [
        "AIの処理速度を向上させる",
        "AIから望ましい出力を得る",
        "AIのメモリ使用量を削減する",
        "AIの学習データを増やす"
      ],
      "correctAnswer": "AIから望ましい出力を得る",
      "explanation": "プロンプトエンジニアリングは、AIから望ましい出力を得るために、効果的な指示（プロンプト）を設計する技術です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_063",
      "question": "Zero-Shotプロンプティングの特徴として最も適切なものはどれか",
      "options": [
        "事前の例示なしで直接タスクを指示する",
        "多くの例を提示してからタスクを指示する",
        "プロンプトを暗号化してから指示する",
        "複数のAIに同時に指示する"
      ],
      "correctAnswer": "事前の例示なしで直接タスクを指示する",
      "explanation": "Zero-Shotプロンプティングは、事前の例示なしで、直接タスクを指示する手法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_064",
      "question": "Few-Shotプロンプティングの特徴として最も適切なものはどれか",
      "options": [
        "事前の例示なしで直接タスクを指示する",
        "いくつかの例を提示してAIにタスクを学習させる手法",
        "無限の例を提示する手法",
        "プロンプトを分割する手法"
      ],
      "correctAnswer": "いくつかの例を提示してAIにタスクを学習させる手法",
      "explanation": "Few-Shotプロンプティングは、プロンプト内にいくつかの具体例を含めることで、AIにタスクをより正確に理解させる手法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_065",
      "question": "Chain-of-Thoughtプロンプティングの主な利点は何か",
      "options": [
        "AIに段階的な思考過程を示させることで複雑な問題解決能力を向上",
        "プロンプトを短くできる",
        "AIの処理速度を向上",
        "メモリ使用量を削減"
      ],
      "correctAnswer": "AIに段階的な思考過程を示させることで複雑な問題解決能力を向上",
      "explanation": "Chain-of-Thoughtプロンプティングは、AIに「考えながら」問題を解決するよう指示することで、より論理的で正確な回答を得ることができます。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_066",
      "question": "LLM（Large Language Model）の特徴として最も適切なものはどれか",
      "options": [
        "小規模なテキストデータのみを学習する",
        "大量のテキストデータを学習した大規模な言語モデル",
        "画像データのみを学習する",
        "音声データのみを学習する"
      ],
      "correctAnswer": "大量のテキストデータを学習した大規模な言語モデル",
      "explanation": "LLM（Large Language Model）は、大量のテキストデータを学習した大規模な言語モデルです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_067",
      "question": "プロンプトの品質を向上させるための手法として最も適切でないものはどれか",
      "options": [
        "明確で具体的な指示をする",
        "コンテキストを提供する",
        "曖昧で抽象的な表現を使う",
        "タスクを段階的に分割する"
      ],
      "correctAnswer": "曖昧で抽象的な表現を使う",
      "explanation": "プロンプトの品質向上のためには、明確で具体的な指示が重要であり、曖昧で抽象的な表現は避けるべきです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_068",
      "question": "テキスト生成AIで文章の要約を作成する際のプロンプトのポイントとして最も適切なものはどれか",
      "options": [
        "要約の長さやスタイルを明確に指定する",
        "元の文章をそのままコピーする",
        "要約を作成せずに拡張する",
        "元の文章を翻訳する"
      ],
      "correctAnswer": "要約の長さやスタイルを明確に指定する",
      "explanation": "文章の要約を作成する際は、要約の長さ（文字数や文数）やスタイルを明確に指定することが重要です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_069",
      "question": "ビジネスでのAI活用において最も重要な要素は何か？",
      "options": [
        "AIを完全に信頼すること",
        "AIの出力をそのまま使用すること",
        "AIの出力を適切に検証すること",
        "AIの使用を避けること"
      ],
      "correctAnswer": "AIの出力を適切に検証すること",
      "explanation": "ビジネスでのAI活用においては、AIの出力を適切に検証し、必要に応じて修正することが重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_070",
      "question": "テキスト生成AIの不得意なこととして最も適切なものはどれか",
      "options": [
        "文章の生成",
        "翻訳",
        "正確な計算",
        "アイデアの発想"
      ],
      "correctAnswer": "正確な計算",
      "explanation": "テキスト生成AIは、複雑な計算や数値処理が苦手です。計算が必要な場合は、専用の計算ツールを使用することが推奨されます。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_071",
      "question": "プロンプトエンジニアリングで「ロールプレイ」技法の効果として最も適切なものはどれか",
      "options": [
        "AIに特定の役割や立場を設定して、その角度からの回答を得る",
        "AIの処理速度を向上させる",
        "AIのメモリ使用量を削減する",
        "AIにゲームをプレイさせる"
      ],
      "correctAnswer": "AIに特定の役割や立場を設定して、その角度からの回答を得る",
      "explanation": "ロールプレイ技法は、AIに「専門家」や「教師」などの特定の役割を与えることで、より適切で専門的な回答を得る手法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_072",
      "question": "LM（Language Model）とLLM（Large Language Model）の主な違いは何か",
      "options": [
        "使用するデータの種類",
        "モデルのサイズと学習データの規模",
        "モデルの言語",
        "モデルの開発年"
      ],
      "correctAnswer": "モデルのサイズと学習データの規模",
      "explanation": "LLMはLMと比べて、より大きなモデルサイズと大量の学習データを使用していることが主な違いです。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_073",
      "question": "プロンプトで「システムメッセージ」を使用する目的として最も適切なものはどれか",
      "options": [
        "AIの基本的な振る舞いやコンテキストを設定する",
        "AIの処理速度を向上させる",
        "AIのメモリをクリアする",
        "AIにエラーを発生させる"
      ],
      "correctAnswer": "AIの基本的な振る舞いやコンテキストを設定する",
      "explanation": "システムメッセージは、AIの基本的な振る舞い、コンテキスト、制約などを設定するために使用されます。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_074",
      "question": "テンプレートベースのプロンプト作成のメリットとして最も適切なものはどれか",
      "options": [
        "一貫性のある品質の高い出力を安定的に得られる",
        "AIの学習時間を短縮できる",
        "AIのメモリ使用量を削減できる",
        "AIの計算コストを削減できる"
      ],
      "correctAnswer": "一貫性のある品質の高い出力を安定的に得られる",
      "explanation": "テンプレートベースのプロンプトを使用することで、一貫性のある品質の高い出力を安定的に得ることができます。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_075",
      "question": "プロンプトインジェクション攻撃の対策として最も効果的なものはどれか",
      "options": [
        "ユーザー入力の適切なフィルタリングと検証",
        "AIモデルのサイズを小さくする",
        "AIの学習データを増やす",
        "AIの処理速度を向上させる"
      ],
      "correctAnswer": "ユーザー入力の適切なフィルタリングと検証",
      "explanation": "プロンプトインジェクション攻撃を防ぐためには、ユーザーからの入力を適切にフィルタリングし、悪意のあるプロンプトを検証することが重要です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "セキュリティ",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_076",
      "question": "文章生成における「ハルシネーション」を減らすためのプロンプト技法として最も適切なものはどれか",
      "options": [
        "情報源や根拠の明記を求める",
        "より長いプロンプトを作成する",
        "より多くの例を提示する",
        "AIの処理速度を上げる"
      ],
      "correctAnswer": "情報源や根拠の明記を求める",
      "explanation": "ハルシネーション（事実ではない情報の生成）を減らすためには、AIに情報源や根拠の明記を求めることが効果的です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "ハルシネーション",
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_077",
      "question": "プロンプトデザインにおける「コンテキストウィンドウ」の考慮事項として最も適切なものはどれか",
      "options": [
        "モデルが一度に処理できるテキストの長さ制限",
        "AIの学習時間",
        "AIの計算コスト",
        "AIのメモリ使用量"
      ],
      "correctAnswer": "モデルが一度に処理できるテキストの長さ制限",
      "explanation": "コンテキストウィンドウは、モデルが一度に処理できるテキストの最大長さを指し、プロンプト設計時に重要な考慮事項です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_078",
      "question": "マルチターンプロンプティングの主な目的は何か",
      "options": [
        "複数のタスクを順次実行して最終的な目標を達成する",
        "AIの処理速度を向上させる",
        "AIのメモリ使用量を削減する",
        "AIの学習データを増やす"
      ],
      "correctAnswer": "複数のタスクを順次実行して最終的な目標を達成する",
      "explanation": "マルチターンプロンプティングは、複数のタスクを段階的に実行し、それぞれの結果を次のタスクに活用して最終目標を達成する手法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_079",
      "question": "プロンプトのバージョン管理が重要な理由として最も適切なものはどれか",
      "options": [
        "プロンプトの改善履歴を追跡し、効果的なバージョンに戻せるようにする",
        "AIの学習速度を向上させる",
        "AIのメモリ使用量を削減する",
        "AIの処理コストを削減する"
      ],
      "correctAnswer": "プロンプトの改善履歴を追跡し、効果的なバージョンに戻せるようにする",
      "explanation": "プロンプトのバージョン管理は、改善履歴を追跡し、問題があった場合に以前の効果的なバージョンに戻せるようにするために重要です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_080",
      "question": "プロンプトチューニングとファインチューニングの主な違いは何か",
      "options": [
        "プロンプトチューニングはモデル自体を変更せず、ファインチューニングはモデルのパラメータを更新する",
        "プロンプトチューニングの方が高速",
        "ファインチューニングの方が安価",
        "どちらも同じ手法"
      ],
      "correctAnswer": "プロンプトチューニングはモデル自体を変更せず、ファインチューニングはモデルのパラメータを更新する",
      "explanation": "プロンプトチューニングはプロンプトの改善により性能を向上させる手法で、ファインチューニングはモデル自体のパラメータを再学習させる手法です。",
      "metadata": {
        "chapter": 5,
        "category": "第5章 テキスト生成AIのプロンプト制作と実例",
        "source": "old_100",
        "tags": [
          "プロンプト制作",
          "プロンプト"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_081",
      "question": "AI技術の進歩方向として最も適切でないものはどれか",
      "options": [
        "マルチモーダルAI",
        "AIエージェント",
        "量子AI",
        "単一モーダルAI"
      ],
      "correctAnswer": "単一モーダルAI",
      "explanation": "AI技術の進歩方向としては、マルチモーダルAI、AIエージェント、量子AIなどが挙げられます。単一モーダルAIは既存の技術であり、進歩方向ではありません。",
      "metadata": {
        "chapter": 3,
        "category": "第3章 現在の生成AIの動向",
        "source": "old_100",
        "tags": [
          "生成AIの動向",
          "マルチモーダル",
          "AIエージェント"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_082",
      "question": "AI倫理において最も重要な要素は何か？",
      "options": [
        "AIの性能向上",
        "人間の価値観の尊重",
        "コストの削減",
        "処理速度の向上"
      ],
      "correctAnswer": "人間の価値観の尊重",
      "explanation": "AI倫理において最も重要な要素は、人間の価値観の尊重です。AI技術は人間の利益のために開発・利用されるべきです。",
      "metadata": {
        "chapter": 4,
        "category": "第4章 情報リテラシー・法律・倫理",
        "source": "old_100",
        "tags": [
          "法律・倫理",
          "AI倫理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_083",
      "question": "AI時代における人間の役割として最も適切なものはどれか",
      "options": [
        "AIに完全に依存する",
        "AIと協働して創造的な価値を生み出す",
        "AIを避ける",
        "AIを制御する"
      ],
      "correctAnswer": "AIと協働して創造的な価値を生み出す",
      "explanation": "AI時代における人間の役割は、AIと協働して創造的な価値を生み出すことです。AIは人間の能力を拡張するツールとして活用すべきです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_084",
      "question": "AI技術の継続学習の重要性について最も適切な記述はどれか",
      "options": [
        "一度学べば十分",
        "技術の進歩に合わせて継続的に学習する必要がある",
        "学習は不要",
        "学習は趣味の範囲で行えばよい"
      ],
      "correctAnswer": "技術の進歩に合わせて継続的に学習する必要がある",
      "explanation": "AI技術は急速に進歩しているため、技術の進歩に合わせて継続的に学習する必要があります。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_085",
      "question": "AIプロジェクトの成功要因として最も適切なものはどれか",
      "options": [
        "最新の技術を使用すること",
        "明確な目的と適切な計画を持つこと",
        "予算を多く投入すること",
        "短期間で完了すること"
      ],
      "correctAnswer": "明確な目的と適切な計画を持つこと",
      "explanation": "AIプロジェクトの成功要因として最も重要なのは、明確な目的と適切な計画を持つことです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_086",
      "question": "AI技術の規制について最も適切な記述はどれか",
      "options": [
        "規制は不要",
        "過度な規制は技術発展を阻害する",
        "厳格な規制が必要",
        "規制は技術発展に影響しない"
      ],
      "correctAnswer": "過度な規制は技術発展を阻害する",
      "explanation": "AI技術の規制は必要ですが、過度な規制は技術発展を阻害する可能性があります。バランスの取れた規制が重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AIガバナンス",
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_087",
      "question": "AI技術の透明性について最も適切な記述はどれか",
      "options": [
        "透明性は不要",
        "意思決定過程の透明性が重要",
        "透明性はコストを増加させるだけ",
        "透明性は技術的に不可能"
      ],
      "correctAnswer": "意思決定過程の透明性が重要",
      "explanation": "AI技術の意思決定過程の透明性は、信頼性と責任性を確保するために重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_088",
      "question": "AI技術の社会的影響について最も適切な記述はどれか",
      "options": [
        "社会的影響はない",
        "正の影響のみがある",
        "負の影響のみがある",
        "正負両方の影響がある"
      ],
      "correctAnswer": "正負両方の影響がある",
      "explanation": "AI技術には正負両方の社会的影響があります。適切な活用により、正の影響を最大化し、負の影響を最小化することが重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_089",
      "question": "AI技術の実践的な活用において最も重要な要素は何か？",
      "options": [
        "最新の技術を使用すること",
        "実際の問題解決に役立つこと",
        "コストを削減すること",
        "処理速度を向上させること"
      ],
      "correctAnswer": "実際の問題解決に役立つこと",
      "explanation": "AI技術の実践的な活用において最も重要なのは、実際の問題解決に役立つことです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_090",
      "question": "AI時代を生き抜くために最も重要な能力は何か？",
      "options": [
        "プログラミングスキル",
        "継続的な学習能力",
        "数学的能力",
        "記憶力"
      ],
      "correctAnswer": "継続的な学習能力",
      "explanation": "AI時代を生き抜くために最も重要なのは、継続的な学習能力です。AI技術は急速に進歩するため、常に新しい知識を習得する必要があります。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_091",
      "question": "ビジネスでのAI導入の成功要因として最も重要なものはどれか",
      "options": [
        "高価なAIソフトウェアを導入する",
        "組織全体でのAI理解と協力",
        "AIエンジニアを大量に採用する",
        "競合他社より早くAIを導入する"
      ],
      "correctAnswer": "組織全体でのAI理解と協力",
      "explanation": "AI導入の成功には、組織全体でのAIに対する理解と協力が最も重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_092",
      "question": "AI技術の個人情報保護における課題として最も重要なものはどれか",
      "options": [
        "データの安全な保存とアクセス制御",
        "AIの処理速度の向上",
        "AIモデルの精度向上",
        "AIシステムのコスト削減"
      ],
      "correctAnswer": "データの安全な保存とアクセス制御",
      "explanation": "AI技術の個人情報保護において最も重要なのは、データの安全な保存と適切なアクセス制御です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "個人情報保護"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_093",
      "question": "AI開発における「責任あるAI」の最も重要な特徴は何か",
      "options": [
        "最高の性能を持つAI",
        "意思決定が説明可能で公平なAI",
        "最新の技術を使用したAI",
        "最も安価なAI"
      ],
      "correctAnswer": "意思決定が説明可能で公平なAI",
      "explanation": "責任あるAIの最も重要な特徴は、意思決定が説明可能であり、公平性を保つことです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_094",
      "question": "AIガバナンスの目的として最も適切なものはどれか",
      "options": [
        "AIの研究開発を加速させる",
        "AI技術の安全で倫理的な利用を促進する",
        "AI技術のコストを削減する",
        "AI技術の独占を防ぐ"
      ],
      "correctAnswer": "AI技術の安全で倫理的な利用を促進する",
      "explanation": "AIガバナンスの主要な目的は、AI技術の安全で倫理的な利用を促進し、リスクを管理することです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "AIガバナンス",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_095",
      "question": "AIシステムのモニタリングにおいて最も重要な評価指標は何か",
      "options": [
        "システムの処理速度",
        "システムのコスト効率",
        "システムの公平性と精度",
        "システムの利用者数"
      ],
      "correctAnswer": "システムの公平性と精度",
      "explanation": "AIシステムのモニタリングにおいては、システムの公平性と精度を継続的に監視することが最も重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_096",
      "question": "AI技術の国際的な標準化の必要性として最も適切なものはどれか",
      "options": [
        "AI技術の競争力向上",
        "AI技術の相互運用性と安全性の確保",
        "AI技術のコスト削減",
        "AI技術の開発速度向上"
      ],
      "correctAnswer": "AI技術の相互運用性と安全性の確保",
      "explanation": "AI技術の国際標準化は、異なるシステム間での相互運用性と、全世界的な安全性の確保のために必要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_097",
      "question": "AI技術の民主化に関する課題として最も適切なものはどれか",
      "options": [
        "AI技術の精度向上",
        "AI技術への平等なアクセスと教育機会の提供",
        "AI技術のコスト削減",
        "AI技術の開発速度向上"
      ],
      "correctAnswer": "AI技術への平等なアクセスと教育機会の提供",
      "explanation": "AI技術の民主化には、すべての人がAI技術に平等にアクセスでき、適切な教育機会を受けられることが重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_098",
      "question": "AI技術の持続可能な発展における環境課題として最も重要なものはどれか",
      "options": [
        "AIの処理速度向上",
        "AIシステムのエネルギー効率改善",
        "AI技術の普及促進",
        "AI開発コスト削減"
      ],
      "correctAnswer": "AIシステムのエネルギー効率改善",
      "explanation": "AI技術の持続可能な発展のためには、AIシステムのエネルギー効率を改善し、環境負荷を減らすことが最も重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_099",
      "question": "AI技術のイノベーションと安全性のバランスについて最も適切な記述はどれか",
      "options": [
        "イノベーションを優先し、安全性は後回しにする",
        "安全性を優先し、イノベーションは制限する",
        "イノベーションと安全性を同時に追求する",
        "イノベーションと安全性は無関係"
      ],
      "correctAnswer": "イノベーションと安全性を同時に追求する",
      "explanation": "AI技術の発展においては、イノベーションと安全性を同時に追求し、バランスを取ることが重要です。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    },
    {
      "questionId": "old_100_100",
      "question": "未来のAI社会における人間の最も重要な役割は何か",
      "options": [
        "AIの新しいアルゴリズムを開発する",
        "AIと協働しながら創造性と倫理を保持する",
        "AIシステムを管理・保守する",
        "AIの使用を避けて伝統的な方法を保持する"
      ],
      "correctAnswer": "AIと協働しながら創造性と倫理を保持する",
      "explanation": "未来のAI社会において人間の最も重要な役割は、AIと協働しながら、人間らしい創造性と倫理を保持し継ぐことです。",
      "metadata": {
        "chapter": 1,
        "category": "第1章 AI（人工知能）",
        "source": "old_100",
        "tags": [
          "AI基礎",
          "リスク管理"
        ],
        "difficulty": "medium",
        "unitId": null
      }
    }
  ]
}