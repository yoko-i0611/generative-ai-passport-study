[
  {
    "chapter": 1,
    "sectionId": "unit01-ai-definition-history",
    "sectionTitle": "AIの定義と歴史",
    "questions": [
      {
        "question": "AI（人工知能）とロボットの定義上の違いとして、最も適切な説明はどれか。",
        "options": [
          "AIは物理的な身体を持つ機械であり、ロボットは知能を持つソフトウェアである。",
          "AIは「脳（ソフトウェア）」であり物理的な身体を必要としないが、ロボットは「体（ハードウェア）」を持つ機械である。",
          "AIとロボットは完全に同じ意味であり、区別する必要はない。",
          "AIは人間型である必要があり、ロボットは産業用である必要がある。"
        ],
        "correctAnswer": "AIは「脳（ソフトウェア）」であり物理的な身体を必要としないが、ロボットは「体（ハードウェア）」を持つ機械である。",
        "explanation": "正解は「AIは「脳（ソフトウェア）」であり物理的な身体を必要としないが、ロボットは「体（ハードウェア）」を持つ機械である。」です。AIは知覚や学習を行うソフトウェア（脳）であり、物理的な身体がなくても機能します。一方、ロボットは物理的な機械（体）を指し、両者は明確に区別されます。選択肢1、3、4はいずれも誤りです。"
      },
      {
        "question": "AIの進化段階を示す「AIの4つのレベル」において、レベル3とレベル4の決定的な違いは何か。",
        "options": [
          "レベル3はルールベースだが、レベル4は機械学習である。",
          "レベル3は家電製品に使われるが、レベル4は将棋プログラムに使われる。",
          "レベル3は人間が特徴量（着眼点）を指定する必要があるが、レベル4はAIが自ら特徴量を学習する（ディープラーニング）。",
          "レベル3は強いAI（AGI）だが、レベル4は弱いAI（ANI）である。"
        ],
        "correctAnswer": "レベル3は人間が特徴量（着眼点）を指定する必要があるが、レベル4はAIが自ら特徴量を学習する（ディープラーニング）。",
        "explanation": "正解は「レベル3は人間が特徴量（着眼点）を指定する必要があるが、レベル4はAIが自ら特徴量を学習する（ディープラーニング）。」です。レベル3（検索エンジン等）は人間が特徴量を設定しますが、レベル4（自動運転等）はディープラーニングにより、特徴量の抽出も含めて自律的に学習します。選択肢1、2、4はいずれも誤りです。"
      },
      {
        "question": "1956年に開催され、「人工知能（Artificial Intelligence）」という言葉が初めて使われた会議はどれか。",
        "options": [
          "ダートマス会議",
          "シリコンバレー会議",
          "ケンブリッジ会議",
          "京都会議"
        ],
        "correctAnswer": "ダートマス会議",
        "explanation": "正解は「ダートマス会議」です。ジョン・マッカーシーらが主催したダートマス会議がAI研究の始まりとされており、ここから第1次AIブームが始まりました。選択肢2、3、4はいずれも誤りです。"
      },
      {
        "question": "「第2次AIブーム（1980年代）」が終焉し、再び「AIの冬」が訪れた主な技術的要因はどれか。",
        "options": [
          "コンピュータの計算速度が速すぎたため。",
          "インターネットが普及し、AIが不要になったため。",
          "専門家の知識を入力・管理するコストが膨大になり、複雑な現実問題に対応できないことが露呈したため。",
          "ディープラーニングの計算コストが高すぎたため。"
        ],
        "correctAnswer": "専門家の知識を入力・管理するコストが膨大になり、複雑な現実問題に対応できないことが露呈したため。",
        "explanation": "正解は「専門家の知識を入力・管理するコストが膨大になり、複雑な現実問題に対応できないことが露呈したため。」です。第2次ブームの主役「エキスパートシステム」は、知識入力の手間と管理の難しさ（ボトルネック）により実用性が限定的となり、ブームは終焉しました。選択肢1、2、4はいずれも誤りです。"
      }
    ]
  },
  {
    "chapter": 1,
    "sectionId": "unit02-machine-learning",
    "sectionTitle": "機械学習の仕組み（4つの学習手法）",
    "questions": [
      {
        "question": "「正解データ」を与えずに、データそのものが持つ構造やパターン（似たもの同士のグループなど）を見つけ出す学習手法はどれか。",
        "options": [
          "教師あり学習",
          "教師なし学習",
          "強化学習",
          "深層学習"
        ],
        "correctAnswer": "教師なし学習",
        "explanation": "正解は「教師なし学習」です。正解（ラベル）を与えない学習は「教師なし学習」です。代表的な手法にクラスタリングや次元削減があります。選択肢1の「教師あり学習」は正解データを必要とします。選択肢3の「強化学習」は報酬に基づいて学習します。選択肢4の「深層学習」は学習手法の分類ではありません。"
      },
      {
        "question": "「強化学習」のプロセスとして最も適切な説明はどれか。",
        "options": [
          "過去のデータを読み込み、未来の数値を予測する。",
          "猫や犬の画像にラベルを付け、それを手本に分類を行う。",
          "コンピュータが行動を選択し、得られる「報酬」を最大化するように試行錯誤して学習する。",
          "少量のエラーデータを人間が修正する。"
        ],
        "correctAnswer": "コンピュータが行動を選択し、得られる「報酬」を最大化するように試行錯誤して学習する。",
        "explanation": "正解は「コンピュータが行動を選択し、得られる「報酬」を最大化するように試行錯誤して学習する。」です。強化学習は、行動の結果として得られる報酬（スコアなど）を最大化するように、試行錯誤を通じて最適な行動を学習します。選択肢1は時系列予測、選択肢2は教師あり学習、選択肢4は半教師あり学習の説明です。"
      },
      {
        "question": "機械学習における「ノーフリーランチ定理」の意味として正しいものはどれか。",
        "options": [
          "無料のランチのように、コストがかからないAIモデルが存在する。",
          "あらゆる問題に対して万能に高性能を発揮できる、唯一のモデルは存在しない。",
          "データを増やせば増やすほど、必ず精度が向上する。",
          "学習には必ず人間による食事（データ入力）が必要である。"
        ],
        "correctAnswer": "あらゆる問題に対して万能に高性能を発揮できる、唯一のモデルは存在しない。",
        "explanation": "正解は「あらゆる問題に対して万能に高性能を発揮できる、唯一のモデルは存在しない。」です。特定の問題に特化したモデルは他の問題では性能が落ちる可能性があり、あらゆる問題に万能なモデルは存在しないという定理です。選択肢1、3、4はいずれも誤りです。"
      },
      {
        "question": "「半教師あり学習」が採用される主なメリットは何か。",
        "options": [
          "ラベル付け（アノテーション）のコストを大幅に削減しつつ、大量のデータを利用できる。",
          "学習時間がゼロになる。",
          "コンピュータの電力を消費しない。",
          "教師あり学習よりも必ず精度が高くなる。"
        ],
        "correctAnswer": "ラベル付け（アノテーション）のコストを大幅に削減しつつ、大量のデータを利用できる。",
        "explanation": "正解は「ラベル付け（アノテーション）のコストを大幅に削減しつつ、大量のデータを利用できる。」です。少量のラベル付きデータと大量のラベルなしデータを組み合わせることで、全てのデータにラベルを付けるコストを削減できるのがメリットです。選択肢2、3、4はいずれも誤りです。"
      }
    ]
  },
  {
    "chapter": 1,
    "sectionId": "unit03-deep-learning",
    "sectionTitle": "ディープラーニングとニューラルネットワーク",
    "questions": [
      {
        "question": "ニューラルネットワークにおいて、人間の脳の「シナプスの結合強度」に相当し、情報の伝達効率を調整するパラメータを何と呼ぶか。",
        "options": [
          "ニューロン",
          "バイアス",
          "重み（ウェイト）",
          "層（レイヤー）"
        ],
        "correctAnswer": "重み（ウェイト）",
        "explanation": "正解は「重み（ウェイト）」です。AIの学習とは、入力と出力の誤差が小さくなるように、この「重み」を最適な値に調整し続けるプロセスを指します。選択肢1の「ニューロン」は神経細胞、選択肢2の「バイアス」は別のパラメータ、選択肢4の「層（レイヤー）」はネットワークの構造を表します。"
      },
      {
        "question": "ディープラーニング（深層学習）の定義として最も適切なものはどれか。",
        "options": [
          "ニューラルネットワークの「隠れ層（中間層）」を多層化したモデル。",
          "1層のみの単純なニューラルネットワーク。",
          "人間が手動でルールを記述するプログラム。",
          "データベースから検索を行うだけのシステム。"
        ],
        "correctAnswer": "ニューラルネットワークの「隠れ層（中間層）」を多層化したモデル。",
        "explanation": "正解は「ニューラルネットワークの「隠れ層（中間層）」を多層化したモデル。」です。隠れ層を何層にも深く（ディープに）重ねることで、複雑な特徴量を自動抽出できるようにしたものがディープラーニングです。選択肢2、3、4はいずれも誤りです。"
      },
      {
        "question": "AIが画像を認識する際、最初のステップとして行われる処理はどれか。",
        "options": [
          "画像全体を「美しい」か「汚い」かで判断する。",
          "画像を画素（ピクセル）に分解し、色情報（RGB）などを数値データとして抽出する。",
          "画像に描かれている物体の名前を辞書で引く。",
          "画像を白黒に変換して保存する。"
        ],
        "correctAnswer": "画像を画素（ピクセル）に分解し、色情報（RGB）などを数値データとして抽出する。",
        "explanation": "正解は「画像を画素（ピクセル）に分解し、色情報（RGB）などを数値データとして抽出する。」です。AIは画像を数値データとして認識します。まず画像を画素に分解し、それぞれのRGB数値（例：R24, G41, B37）を抽出することから始まります。選択肢1、3、4はいずれも誤りです。"
      }
    ]
  },
  {
    "chapter": 1,
    "sectionId": "unit04-overfitting-bias",
    "sectionTitle": "学習の精度と課題（過学習とバイアス）",
    "questions": [
      {
        "question": "機械学習において、AIモデルが訓練データに過度に適応しすぎてしまい、未知のデータに対する予測精度が下がってしまう現象を何と呼ぶか。",
        "options": [
          "汎化（Generalization）",
          "過学習（Overfitting）",
          "転移学習（Transfer Learning）",
          "シンギュラリティ（Singularity）"
        ],
        "correctAnswer": "過学習（Overfitting）",
        "explanation": "正解は「過学習（Overfitting）」です。訓練データのノイズや細かい癖まで暗記してしまい、新しいデータに対応できなくなる状態です。オーバーフィッティングとも呼ばれます。選択肢1の「汎化」は過学習とは逆の理想的な状態、選択肢3の「転移学習」は別のタスクへの知識の再利用、選択肢4の「シンギュラリティ」はAIが人間を超える時点を指します。"
      },
      {
        "question": "「過学習」を防ぐための代表的な手法の組み合わせとして、正しいものはどれか。",
        "options": [
          "データの削除・学習の長時間化・ルールの固定",
          "ドロップアウト・正則化・アーリーストッピング",
          "パラメータの増加・画像の高画質化・転移学習",
          "教師なし学習への切り替え・バイアスの増加"
        ],
        "correctAnswer": "ドロップアウト・正則化・アーリーストッピング",
        "explanation": "正解は「ドロップアウト・正則化・アーリーストッピング」です。過学習の対策としては、ニューロンをランダムに無効化する「ドロップアウト」、モデルを単純化する「正則化」、適切な時点で学習を止める「アーリーストッピング」があります。選択肢1、3、4はいずれも過学習の対策ではありません。"
      },
      {
        "question": "ある領域で学習済みのモデル（例：猫の認識）の知識を、別の領域（例：レントゲン画像の診断）に応用して、学習効率を高める手法を何と呼ぶか。",
        "options": [
          "転移学習",
          "強化学習",
          "アンサンブル学習",
          "敵対的学習"
        ],
        "correctAnswer": "転移学習",
        "explanation": "正解は「転移学習」です。ゼロから学習するのではなく、既存の学習済みモデル（重みなど）を流用・微調整することで、少ないデータと時間で効率的にモデルを構築する手法です。選択肢2の「強化学習」は報酬に基づく学習、選択肢3の「アンサンブル学習」は複数のモデルを組み合わせる手法、選択肢4の「敵対的学習」はGANなどの手法です。"
      },
      {
        "question": "「AI効果」と呼ばれる心理現象の説明として正しいものはどれか。",
        "options": [
          "AIを使うと人間の知能が低下する現象。",
          "AIの原理が分かってしまうと、「それは単なるプログラムに過ぎない」と考え、知能とは認めなくなる（失望する）現象。",
          "AIが人間を超えて自己進化を始める現象。",
          "AIによって経済効果が生まれる現象。"
        ],
        "correctAnswer": "AIの原理が分かってしまうと、「それは単なるプログラムに過ぎない」と考え、知能とは認めなくなる（失望する）現象。",
        "explanation": "正解は「AIの原理が分かってしまうと、「それは単なるプログラムに過ぎない」と考え、知能とは認めなくなる（失望する）現象。」です。AI技術への期待が高すぎるあまり、実際に仕組みが分かったり普及したりすると「たいしたことない」と失望し、知能として認めなくなる心理現象を指します。選択肢1、3、4はいずれも誤りです。"
      }
    ]
  },
  {
    "chapter": 2,
    "sectionId": "unit01-generative-model-evolution",
    "sectionTitle": "生成モデルの誕生と進化",
    "questions": [
      {
        "question": "2012〜2013年のディープラーニングのブレークスルーは、画像認識などの「識別（インプット）」の革命でした。一方、現在の生成AIの台頭は、新たなデータを創り出す「生成（アウトプット）の革命」と言えます。この説明は正しいですか？",
        "options": [
          "正しい",
          "誤り"
        ],
        "correctAnswer": "正しい",
        "explanation": "2012〜2013年のディープラーニングのブレークスルーは画像認識などの「識別（インプット）」の革命でした。一方、現在の生成AIの台頭は、新しいデータを生み出す「生成（アウトプット）の革命」です。この対比はAIの進化を理解する上で重要な概念であり、表現は正確です。"
      },
      {
        "question": "AI研究の歴史において、2012年の画像認識コンペティションで圧倒的な精度を記録し、第3次AIブームの火付け役となった技術はどれか。",
        "options": [
          "RNN（回帰型ニューラルネットワーク）",
          "CNN（畳み込みニューラルネットワーク）",
          "GAN（敵対的生成ネットワーク）",
          "Transformer"
        ],
        "correctAnswer": "CNN（畳み込みニューラルネットワーク）",
        "explanation": "正解はCNNです。2012年のImageNetコンペティションでヒントン教授のチームがCNNを用いて圧勝し、ディープラーニングの有効性が世界に示されました。これが第3次AIブームの火付け役となりました。CNNは画像の局所的な特徴（畳み込み）を捉えるのに適しており、画像認識の革命を起こしました。RNNは時系列データ処理、GANは画像生成、Transformerは2017年登場でCNNより後に開発された技術です。"
      },
      {
        "question": "GAN（敵対的生成ネットワーク）の構成要素である「Generator（生成器）」と「Discriminator（識別器）」の関係として適切なものはどれか。",
        "options": [
          "互いに協力して正解率を高める",
          "識別器が生成器に指示を出して画像を修正させる",
          "互いに競い合い（敵対し）、生成器は識別器を騙そうとし、識別器は真偽を見抜こうとする",
          "生成器が画像を生成した後、識別器が色付けを行う"
        ],
        "correctAnswer": "互いに競い合い（敵対し）、生成器は識別器を騙そうとし、識別器は真偽を見抜こうとする",
        "explanation": "正解は「互いに競い合う」関係です。GANでは、生成器（Generator）は識別器を騙そうと高品質なデータを生成し、識別器（Discriminator）はそのデータが本物か偽物かを見抜こうとします。この敵対的な競争により、生成データの品質が向上します。選択肢1の「協力して」は誤りです。選択肢2の「識別器が指示を出す」や選択肢4の「識別器が色付けを行う」もGANの仕組みとは異なります。"
      },
      {
        "question": "2017年に登場し、現在のLLM（大規模言語モデル）の全ての基礎となっている「Transformer」モデルの最大の特徴はどれか。",
        "options": [
          "畳み込み演算による画像特徴の抽出",
          "逐次処理による時系列データの学習",
          "Self-Attention（自己注意機構）による並列処理と長距離依存の学習",
          "敵対的学習によるデータ生成"
        ],
        "correctAnswer": "Self-Attention（自己注意機構）による並列処理と長距離依存の学習",
        "explanation": "正解は「Self-Attention（自己注意機構）による並列処理と長距離依存の学習」です。Transformerの最大の特徴は、Self-Attentionにより文中の離れた単語同士の関係性を一括（並列）で計算できることです。これにより学習速度と性能が劇的に向上し、現在のLLMの全ての基礎となりました。選択肢1の「畳み込み演算」はCNNの特徴、選択肢2の「逐次処理」はRNN/LSTMの特徴、選択肢4の「敵対的学習」はGANの特徴です。"
      },
      {
        "question": "自然言語処理モデル「BERT」の特徴として適切なものはどれか。",
        "options": [
          "文章の生成に特化したモデルである",
          "文脈を「双方向」から理解し、マスクされた単語を予測する（MLM）",
          "画像とテキストを同時に処理するマルチモーダルモデルである",
          "時系列データを順に処理するRNNの一種である"
        ],
        "correctAnswer": "文脈を「双方向」から理解し、マスクされた単語を予測する（MLM）",
        "explanation": "正解は「文脈を双方向から理解し、マスクされた単語を予測する（MLM）」です。BERTはTransformerのエンコーダ部分を使用し、文章の前後（双方向）から文脈を読んで、マスクされた単語を予測する「Masked Language Model（MLM）」という手法で学習します。これにより深い言語理解を実現しました。選択肢1の「文章の生成に特化」は誤りで、BERTは理解に特化したモデルです。選択肢3の「マルチモーダル」や選択肢4の「RNNの一種」もBERTの特徴ではありません。"
      },
      {
        "question": "VAE（変分自己符号化器）の仕組みとして正しいものはどれか。",
        "options": [
          "データを「潜在変数（ベクトル）」に圧縮し、そこから元のデータを復元・生成する",
          "テキストから画像を生成する専用モデルである",
          "生成器と識別器を競わせて画像を生成する",
          "ノイズから徐々に画像を浮かび上がらせる"
        ],
        "correctAnswer": "データを「潜在変数（ベクトル）」に圧縮し、そこから元のデータを復元・生成する",
        "explanation": "正解は「データを潜在変数（ベクトル）に圧縮し、そこから元のデータを復元・生成する」です。VAEはデータを「潜在変数（ベクトル）」と呼ばれる低次元の表現に圧縮（エンコード）し、そこから元のデータを復元・再構築（デコード）する過程で新しいデータを生成します。選択肢2の「テキストから画像生成専用」は誤りで、VAEは様々なデータタイプに適用可能です。選択肢3の「生成器と識別器を競わせる」はGANの特徴、選択肢4の「ノイズから画像を浮かび上がらせる」は拡散モデルの特徴です。"
      },
      {
        "question": "Transformerの主要な特徴として正しいものはどれですか？",
        "options": [
          "Self-Attentionと並列処理により、文脈を一括計算できる",
          "逐次処理により、長文の文脈を忘れない",
          "CNNベースの画像認識に特化している"
        ],
        "correctAnswer": "Self-Attentionと並列処理により、文脈を一括計算できる",
        "explanation": "正解は「Self-Attentionと並列処理により、文脈を一括計算できる」です。TransformerはSelf-Attentionにより文中の単語同士の関係性を一括で計算し、並列処理により学習速度が飛躍的に向上しました。これにより長文の文脈も一度に計算できるようになり、RNN/LSTMの限界を解決しました。選択肢2の「逐次処理により長文の文脈を忘れない」は誤りで、これはRNN/LSTMの特徴ではなく、むしろ逐次処理が長文の文脈を忘れてしまうという課題がありました。選択肢3の「CNNベースの画像認識」はTransformerの特徴ではありません。"
      }
    ]
  },
  {
    "chapter": 2,
    "sectionId": "unit02-paradigm-shift",
    "sectionTitle": "画像生成技術のパラダイムシフト",
    "questions": [
      {
        "question": "画像生成AIにおいて、2025年以降の最新モデル（GPT-4o統合機能など）で採用が進んでいる「自己回帰型（Autoregressive）」の説明として適切なものはどれか。",
        "options": [
          "ノイズを徐々に除去することで画像を浮かび上がらせる",
          "画像をトークンとして扱い、左上から右下へ一つずつ描画していく",
          "生成器と識別器を競わせて画像を生成する",
          "画像を潜在ベクトルに圧縮してから復元する"
        ],
        "correctAnswer": "画像をトークンとして扱い、左上から右下へ一つずつ描画していく",
        "explanation": "正解は「画像をトークンとして扱い、左上から右下へ一つずつ描画していく」です。自己回帰型は、画像をトークン（断片）として扱い、テキスト生成と同じように左上から右下へ順番に描画していく方式です。これにより、画像内の文字、ロゴ、細かい線、レイアウトの精度が劇的に向上しました。選択肢1の「ノイズ除去」は拡散モデルの特徴、選択肢3の「生成器と識別器を競わせる」はGANの特徴、選択肢4の「潜在ベクトルに圧縮」はVAEの特徴です。"
      },
      {
        "question": "従来の画像生成AI（Stable Diffusionなど）で主流だった「拡散モデル（Diffusion Model）」の仕組みとして正しいものはどれか。",
        "options": [
          "ノイズ（砂嵐）から徐々にノイズを除去して画像を生成する",
          "2つのネットワークを競わせて画像を生成する",
          "過去のデータから未来の値を予測する",
          "画像の左上から順にピクセルを埋めていく"
        ],
        "correctAnswer": "ノイズ（砂嵐）から徐々にノイズを除去して画像を生成する",
        "explanation": "正解は「ノイズ（砂嵐）から徐々にノイズを除去して画像を生成する」です。拡散モデルは、ノイズだらけの画像から少しずつノイズを除去し、元の画像を復元する方式で画像を生成します。Stable Diffusionなど従来の画像生成AIで主流だった技術です。選択肢2の「2つのネットワークを競わせる」はGANの特徴、選択肢3の「過去のデータから未来の値を予測する」は自己回帰モデルの一般的な説明、選択肢4の「左上から順にピクセルを埋める」は自己回帰型画像生成の特徴です。"
      },
      {
        "question": "GPT-4oやo3モデルに統合された最新の画像生成機能が採用している技術方式と、それによる主な改善点として適切な組み合わせはどれか。",
        "options": [
          "拡散モデル（Diffusion） － ノイズ除去プロセスの高速化",
          "自己回帰型（Autoregressive） － 画像内の文字生成能力の向上",
          "GAN（敵対的生成ネットワーク） － 画像の解像度の向上",
          "VAE（変分自己符号化器） － 生成速度の安定化"
        ],
        "correctAnswer": "自己回帰型（Autoregressive） － 画像内の文字生成能力の向上",
        "explanation": "正解は「自己回帰型（Autoregressive） － 画像内の文字生成能力の向上」です。GPT-4oやo3モデルなどの最新モデルでは、従来のDALL-E 3などで採用されていた「拡散モデル」ではなく「自己回帰型」を採用しています。画像をトークンとして扱い、左上から右下へ順次描画することで、看板の文字などを正確に描写できるようになりました。選択肢1の「拡散モデル」は従来技術で、ノイズ除去プロセスの高速化が主な改善点ではありませんでした。選択肢3の「GAN」や選択肢4の「VAE」は最新モデルで採用されている技術ではありません。"
      },
      {
        "question": "自己回帰型画像生成が拡散モデルよりも優れている点として正しいものはどれか。",
        "options": [
          "処理速度が速い",
          "画像内の文字生成や細部の位置制御の精度が高い",
          "ノイズが少ない"
        ],
        "correctAnswer": "画像内の文字生成や細部の位置制御の精度が高い",
        "explanation": "正解は「画像内の文字生成や細部の位置制御の精度が高い」です。自己回帰型は、画像をトークンとして扱い、左上から右下へ順次描画する方式により、画像内の文字、ロゴ、細かい線、レイアウトの精度が劇的に向上しました。これが拡散モデルから自己回帰型への技術転換の主な理由です。選択肢1の「処理速度が速い」は誤りで、自己回帰型は拡散モデルより処理が遅い場合もあります。選択肢3の「ノイズが少ない」は画像生成方式の違いとは直接関係ありません。"
      }
    ]
  },
  {
    "chapter": 2,
    "sectionId": "unit03-openai-omni-series",
    "sectionTitle": "OpenAIモデルの系譜①（Omni系列）",
    "questions": [
      {
        "question": "OpenAIのモデル名称における「o」の意味と、そのモデル特性に関する説明として正しいものはどれか。",
        "options": [
          "「GPT-4o」の「o」は「Optimal（最適）」を意味し、コストパフォーマンスを最優先している。",
          "「GPT-o1」の「o」は「Omni（全て）」を意味し、テキスト・音声・画像をリアルタイムに処理する。",
          "「GPT-4o」の「o」は「Omni（全て）」を意味し、マルチモーダルな処理を単一モデルで高速に行う。",
          "「GPT-o1」と「GPT-4o」は、発売時期が異なるだけで内部構造は同じである。"
        ],
        "correctAnswer": "「GPT-4o」の「o」は「Omni（全て）」を意味し、マルチモーダルな処理を単一モデルで高速に行う。",
        "explanation": "正解は「GPT-4oの『o』は『Omni（全て）』を意味し、マルチモーダルな処理を単一モデルで高速に行う」です。GPT-4oの「o」は「Omni（全て）」を意味し、テキスト・画像・音声を1つのモデルで統合処理する体験重視のマルチモーダルモデルです。選択肢1の「Optimal（最適）」は誤りで、コストパフォーマンスが主目的ではありません。選択肢2の「GPT-o1の『o』はOmni」は誤りで、GPT-o1はReasoning（推論）特化型です。選択肢4の「発売時期が異なるだけで構造は同じ」も誤りで、GPT-4oとGPT-o1は全く異なる系列のモデルです。"
      },
      {
        "question": "「マルチモーダルAI」の定義として最も適切なものはどれか。",
        "options": [
          "複数の言語を話せるAI",
          "テキスト、画像、音声、動画など、複数の種類のデータ形式を統合して処理できるAI",
          "複数のPCで同時に動作するAI",
          "複数のユーザーと同時に会話できるAI"
        ],
        "correctAnswer": "テキスト、画像、音声、動画など、複数の種類のデータ形式を統合して処理できるAI",
        "explanation": "正解は「テキスト、画像、音声、動画など、複数の種類のデータ形式を統合して処理できるAI」です。マルチモーダル（Multimodal）は「複数のモード（様式）」を意味し、テキスト以外の情報（画像・音声・動画など）も扱えるAIを指します。選択肢1の「複数の言語を話せる」は多言語対応であり、マルチモーダルの定義ではありません。選択肢3の「複数のPCで同時に動作」や選択肢4の「複数のユーザーと同時に会話」は、マルチモーダルとは関係ない概念です。"
      },
      {
        "question": "GPT-4o（Omni系列）の音声応答の特徴として正しいものはどれか。",
        "options": [
          "最短232ms、平均320msの低レイテンシ",
          "最短500ms、平均800msの応答速度",
          "最短1秒、平均2秒の応答速度"
        ],
        "correctAnswer": "最短232ms、平均320msの低レイテンシ",
        "explanation": "正解は「最短232ms、平均320msの低レイテンシ」です。GPT-4o（Omni系列）は人間の会話に近い速度を狙って設計されており、音声入力への応答が最短232ms、平均320msと非常に高速です。これによりリアルタイム体験が実現されています。選択肢2の「最短500ms、平均800ms」や選択肢3の「最短1秒、平均2秒」は、GPT-4oの実際の応答速度より遅く、正確ではありません。"
      }
    ]
  },
  {
    "chapter": 2,
    "sectionId": "unit04-openai-reasoning-series",
    "sectionTitle": "OpenAIモデルの系譜②（Reasoning系列）",
    "questions": [
      {
        "question": "「GPT-5 Thinking」モデルの性能報告として、正しい記述を選びなさい。",
        "options": [
          "従来のモデルと比較して、計算速度が10倍になった。",
          "o3モデルと比較して、ハルシネーション（幻覚）が約80%減少した。",
          "画像生成機能が削除され、テキスト処理に特化した。",
          "日本語の学習データが含まれなくなった。"
        ],
        "correctAnswer": "o3モデルと比較して、ハルシネーション（幻覚）が約80%減少した。",
        "explanation": "正解は「o3モデルと比較して、ハルシネーション（幻覚）が約80%減少した」です。GPT-5 Thinkingは深い推論能力を持ち、o3モデルと比較してハルシネーションが約80%減少したと報告されています。この数値は試験の重要ポイントです。選択肢1の「計算速度が10倍になった」は性能報告として記述されていません。選択肢3の「画像生成機能が削除」や選択肢4の「日本語の学習データが含まれなくなった」も、GPT-5 Thinkingの性能報告には含まれていません。"
      },
      {
        "question": "プロンプトエンジニアリングにおける「Chain-of-Thought（思考の連鎖）」プロンプティングの効果は何か。",
        "options": [
          "AIに「ステップバイステップで考えて」と指示することで、論理的推論の精度を向上させる",
          "AIに過去の会話を全て忘れさせる",
          "AIの応答速度を最大化する",
          "画像生成の画質を向上させる"
        ],
        "correctAnswer": "AIに「ステップバイステップで考えて」と指示することで、論理的推論の精度を向上させる",
        "explanation": "正解は「AIに『ステップバイステップで考えて』と指示することで、論理的推論の精度を向上させる」です。Chain-of-Thoughtプロンプティングは、思考過程を出力させることで、複雑な計算や論理問題の正答率を高める手法です。Reasoningモデル（GPT-o1/o3/o4/GPT-5 Thinking）は、このChain-of-Thoughtを内部処理として持つモデル群です。選択肢2の「過去の会話を全て忘れさせる」、選択肢3の「応答速度を最大化」、選択肢4の「画像生成の画質を向上」は、Chain-of-Thoughtプロンプティングの効果ではありません。"
      },
      {
        "question": "GPT-4.1の最大トークン数として正しいものはどれか。",
        "options": [
          "50万トークン",
          "100万トークン",
          "200万トークン"
        ],
        "correctAnswer": "100万トークン",
        "explanation": "正解は「100万トークン」です。GPT-4.1は開発者向けの実務モデルとして、最大100万トークンという長コンテキストに対応しています。この数値は、Reasoning系列の特徴を理解する上で重要な具体例です。選択肢1の「50万トークン」や選択肢3の「200万トークン」は、GPT-4.1の実際のトークン数ではありません。"
      }
    ]
  },
  {
    "chapter": 2,
    "sectionId": "unit05-autonomous-ai-agents",
    "sectionTitle": "自律型AIエージェント",
    "questions": [
      {
        "question": "2025年に公開されたAIエージェント「Operator」の主な機能として、最も適切なものはどれか。",
        "options": [
          "ユーザーの代わりに会議に出席して発言する。",
          "独自の仮想ブラウザを起動し、予約・購入・フォーム入力などのWeb操作を自律的に代行する。",
          "ソフトウェアのバグを自動的に修正し、GitHubへプルリクエストを送る。",
          "テキストから高品質な動画を生成する。"
        ],
        "correctAnswer": "独自の仮想ブラウザを起動し、予約・購入・フォーム入力などのWeb操作を自律的に代行する。",
        "explanation": "正解は「独自の仮想ブラウザを起動し、予約・購入・フォーム入力などのWeb操作を自律的に代行する」です。Operatorは2025年1月に公開された「ブラウザ操作エージェント」で、Web上のタスク（予約や購入など）を画面を画像として認識し、クリックや入力を自律的に行います。選択肢1の「会議に出席して発言」はOperatorの機能ではありません。選択肢3の「ソフトウェアのバグ修正やGitHubプルリクエスト」は「Codex」の役割です。選択肢4の「テキストから動画生成」は画像生成モデルの機能です。"
      },
      {
        "question": "AIエージェントが、従来のチャットボットと決定的に異なる点は何か。",
        "options": [
          "ユーザーと会話ができる点",
          "自律的に計画を立て、ツールを使用してタスクを実行（行動）できる点",
          "インターネットに接続されている点",
          "スマートフォンで使える点"
        ],
        "correctAnswer": "自律的に計画を立て、ツールを使用してタスクを実行（行動）できる点",
        "explanation": "正解は「自律的に計画を立て、ツールを使用してタスクを実行（行動）できる点」です。AIエージェントは、目標を与えると計画→実行→結果確認→修正を自分で回しながらタスクを完遂します。チャットボットは「会話」が主ですが、エージェントは目標達成のために自律的に「行動（ツール実行、ブラウザ操作など）」する点が決定的な違いです。選択肢1の「会話ができる」、選択肢3の「インターネット接続」、選択肢4の「スマートフォンで使える」は、チャットボットとエージェントの両方に当てはまるため、決定的な違いではありません。"
      },
      {
        "question": "Codex（開発エージェント）の特徴として正しいものはどれか。",
        "options": [
          "ブラウザ操作を代行する",
          "クラウド上のサンドボックス環境でコードを実行し、テストが通るまで自律的に修正を繰り返す",
          "画像生成に特化している"
        ],
        "correctAnswer": "クラウド上のサンドボックス環境でコードを実行し、テストが通るまで自律的に修正を繰り返す",
        "explanation": "Codexはソフトウェア開発に特化したエージェントで、GitHubのプルリクエスト作成、バグ修正、新機能追加などの開発工程を、クラウド上のサンドボックス環境で繰り返し実行します。"
      }
    ]
  },
  {
    "chapter": 2,
    "sectionId": "unit06-competitive-models",
    "sectionTitle": "競合モデルの最新動向（Google & Anthropic & Microsoft）",
    "questions": [
      {
        "question": "Anthropic社が開発する「Claude」シリーズの特徴である、安全性と無害性を最優先する設計思想を何と呼ぶか。",
        "options": [
          "Generative Adversarial Networks (GAN)",
          "Reinforcement Learning from Human Feedback (RLHF)",
          "Constitutional AI (憲法AI)",
          "Chain-of-Thought Prompting"
        ],
        "correctAnswer": "Constitutional AI (憲法AI)",
        "explanation": "正解は「Constitutional AI（憲法AI）」です。Anthropic Claudeは「Constitutional AI（憲法AI）」という独自のアプローチを採用しており、「無害・正直・役に立つ」という原則に基づいてモデルが自己修正を行う仕組みを持っています。これがClaudeの最大の特徴である安全性を最優先する設計思想です。選択肢1の「GAN」は敵対的生成ネットワークの略で、画像生成の技術です。選択肢2の「RLHF」は人間のフィードバックからの強化学習で、アライメントの手法の一つですが、Constitutional AIとは異なります。選択肢4の「Chain-of-Thought」は推論手法であり、Claudeの設計思想ではありません。"
      },
      {
        "question": "Google Geminiモデルの最大の特徴は何ですか？",
        "options": [
          "安全性と信頼性",
          "最高速度の応答",
          "ネイティブ・マルチモーダル設計"
        ],
        "correctAnswer": "ネイティブ・マルチモーダル設計",
        "explanation": "正解は「ネイティブ・マルチモーダル設計」です。Google Geminiは最初から画像・音声・テキストを同時に理解する前提で作られたネイティブ・マルチモーダルモデルです。「ネイティブAudioモデル」による低遅延な会話が特徴です。選択肢1の「安全性と信頼性」はAnthropic Claudeの特徴（Constitutional AI）です。選択肢2の「最高速度の応答」はGPT-4o（Omni系列）により明確に特徴として示されているため、Geminiの「最大の特徴」としては適切ではありません。"
      },
      {
        "question": "Microsoft Copilotの最大の特徴は何ですか？",
        "options": [
          "最高速度の応答",
          "業務アプリへの統合と商用データ保護",
          "最低コストでの利用"
        ],
        "correctAnswer": "業務アプリへの統合と商用データ保護",
        "explanation": "正解は「業務アプリへの統合と商用データ保護」です。Microsoft Copilotは、WordやExcel、Teams、OutlookなどのMicrosoft 365アプリ内で、GPT-5ベースのAIを安全な環境（商用データ保護）で利用できるよう設計されています。これは「仕事の中に自然に溶け込むAI」として設計された、企業利用を強く意識した実務志向の特徴です。選択肢1の「最高速度の応答」はGPT-4o（Omni系列）の特徴です。選択肢3の「最低コストでの利用」はGemini 2.5 Flashなどの特徴ですが、Copilotの「最大の特徴」としては適切ではありません。"
      }
    ]
  },
  {
    "chapter": 3,
    "sectionId": "unit01-generative-ai-modality",
    "sectionTitle": "生成AIができることと主なサービス",
    "questions": [
      {
        "question": "GPT-4oや最新の画像生成AIにおいて採用が進んでいる「自己回帰型（Autoregressive）」モデルの特徴として、従来の「拡散モデル（Diffusion）」と比較した際の主な利点はどれか。",
        "options": [
          "ノイズを除去するプロセスにより、芸術的な抽象画が生成しやすくなる。",
          "画像をトークン列として左上から処理することで、画像内の文字（看板やロゴなど）を正確に描写・制御しやすくなる。",
          "計算コストが拡散モデルの10倍になるが、画質は変わらない。",
          "静止画しか生成できず、動画生成には応用できない。"
        ],
        "correctAnswer": "画像をトークン列として左上から処理することで、画像内の文字（看板やロゴなど）を正確に描写・制御しやすくなる。",
        "explanation": "正解は選択肢2です。拡散モデルから自己回帰型への転換により、これまで苦手だった「文字の描写」が正確になった点が強調されています。自己回帰型は画像をトークンとして扱い、左上から右下へ順次描画することで、画像内の文字、ロゴ、細かい線、レイアウトの精度が劇的に向上しました。選択肢1は拡散モデルの特徴、選択肢3と4は誤りです。"
      },
      {
        "question": "2025年にGoogle DeepMindが発表した動画生成AI「Veo3」の画期的な特徴として、最も適切なものはどれか。",
        "options": [
          "テキストのみを出力する。",
          "5秒以内の無音動画しか生成できない。",
          "高精細な映像の生成に加え、環境音やセリフなどの音声も一括で合成できる。",
          "著作権フリーの素材のみを使用して生成する。"
        ],
        "correctAnswer": "高精細な映像の生成に加え、環境音やセリフなどの音声も一括で合成できる。",
        "explanation": "正解は選択肢3です。Veo3は映像だけでなく、音声（環境音やセリフ）も含めた統合的な生成が可能であることが特徴です。動画生成AIの進化により、映像と音声を一括で生成できるようになりました。選択肢1、2、4は誤りです。"
      },
      {
        "question": "テキスト生成AI（LLM）における「自然言語処理（NLP）」の説明として、最も適切なものはどれか。",
        "options": [
          "コンピュータがプログラミング言語を人間の言語に変換する技術。",
          "人間が日常的に使っている言語の曖昧さや複雑さを扱い、理解・生成するための技術の総称。",
          "画像データをテキストデータに変換する技術のみを指す。",
          "音声データを数値データに変換する技術のみを指す。"
        ],
        "correctAnswer": "人間が日常的に使っている言語の曖昧さや複雑さを扱い、理解・生成するための技術の総称。",
        "explanation": "正解は選択肢2です。NLPは人間が使う自然言語をコンピュータが扱うための基盤技術であり、LLMの根幹をなします。コンピュータが日本語や英語などの自然な言葉を理解し、生成するための技術です。選択肢1、3、4は誤りです。"
      },
      {
        "question": "音声生成AIにおいて、特定の人物の画像の口の動きを、生成された音声に同期させる技術を何と呼ぶか。",
        "options": [
          "リップシンク（Lip Sync）",
          "ボイスチェンジャー",
          "マスキング",
          "トークナイゼーション"
        ],
        "correctAnswer": "リップシンク（Lip Sync）",
        "explanation": "正解は選択肢1です。音声生成に加え、口の動きを同期させるリップシンク技術の進化により、バーチャルヒューマンなどの表現力が向上しています。選択肢2の「ボイスチェンジャー」は声質を変える技術、選択肢3の「マスキング」は情報を隠す処理、選択肢4の「トークナイゼーション」はテキストを分割する処理です。"
      },
      {
        "question": "画像生成AIの学習手法として知られる「VAE（変分自己符号化器）」の構成要素である「エンコーダ」の役割はどれか。",
        "options": [
          "ノイズから画像を生成する。",
          "生成された画像が本物かどうかを識別する。",
          "入力データを「潜在ベクトル（データの特徴を要約した情報）」という低次元の表現に変換する。",
          "潜在ベクトルから元の画像を復元する。"
        ],
        "correctAnswer": "入力データを「潜在ベクトル（データの特徴を要約した情報）」という低次元の表現に変換する。",
        "explanation": "正解は選択肢3です。VAEはエンコーダ（特徴を抽出して圧縮）とデコーダ（復元）で構成されます。エンコーダは入力データを潜在ベクトルに変換します。選択肢1は拡散モデルの特徴、選択肢2はGANの識別器の役割、選択肢4はデコーダの役割です。"
      }
    ]
  },
  {
    "chapter": 3,
    "sectionId": "unit02-deepfake",
    "sectionTitle": "ディープフェイク技術とその危険性",
    "questions": [
      {
        "question": "ディープフェイク技術が悪用された事例として、2023年に発生し、米国株式市場（ダウ平均株価）の一時的な下落を引き起こした事件の内容はどれか。",
        "options": [
          "有名俳優が選挙に立候補したという偽動画。",
          "アメリカ国防総省（ペンタゴン）近くで爆発があったとする偽画像。",
          "ある企業のCEOが辞任するという偽音声。",
          "火星に宇宙人がいるという偽ニュース。"
        ],
        "correctAnswer": "アメリカ国防総省（ペンタゴン）近くで爆発があったとする偽画像。",
        "explanation": "正解は選択肢2です。ペンタゴン爆発の偽画像がSNSで拡散され、金融市場に混乱を与えた事例は、AI生成物の社会的リスクとして重要です。この事件は、ディープフェイク技術が金融市場に与える影響を示す具体例として知られています。選択肢1、3、4は誤りです。"
      },
      {
        "question": "イギリスの企業で発生した「ディープフェイクボイス詐欺」の手口として、正しいものはどれか。",
        "options": [
          "取引先の担当者になりすましたメールを送りつけた。",
          "音声生成AIを用いて親会社のCEOの声を模倣し、電話で巨額の送金を指示した。",
          "無言電話を繰り返して業務を妨害した。",
          "社内会議の議事録を改ざんした。"
        ],
        "correctAnswer": "音声生成AIを用いて親会社のCEOの声を模倣し、電話で巨額の送金を指示した。",
        "explanation": "正解は選択肢2です。音声生成AIの悪用により、信頼できる人物の声（CEOや取引先）を模倣して金銭を騙し取る詐欺が発生しています。このようなディープフェイクボイス詐欺は、オレオレ詐欺の高度化版として深刻な問題となっています。選択肢1、3、4は誤りです。"
      },
      {
        "question": "ディープフェイク（Deepfake）の定義として、最も適切な記述はどれか。",
        "options": [
          "AIが作成した芸術的な絵画のこと。",
          "ディープラーニング等を利用して、実在しない人物や実際には行っていない言動を含む、真偽の識別が困難な合成コンテンツを作成する技術。",
          "検索エンジンの検索結果を偽装する技術。",
          "コンピュータウイルスの別名。"
        ],
        "correctAnswer": "ディープラーニング等を利用して、実在しない人物や実際には行っていない言動を含む、真偽の識別が困難な合成コンテンツを作成する技術。",
        "explanation": "正解は選択肢2です。ディープフェイクは、ディープラーニングを用いて人の顔や声、映像を本物のように合成する技術です。人を欺く目的で使用されることが多く、真偽不明な合成メディアを作成する技術を指します。画像、音声、動画すべてが対象となり、現実と見分けがつかないレベルまで精度が向上しています。選択肢1、3、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 3,
    "sectionId": "unit03-rag",
    "sectionTitle": "RAG（検索拡張生成）",
    "questions": [
      {
        "question": "生成AIにおける「ナレッジカットオフ」の問題を解決するために用いられる、RAG（検索拡張生成）の基本的な動作原理はどれか。",
        "options": [
          "モデルのパラメータ数を無限に増やす。",
          "質問に対して、まず外部データベースから関連情報を「検索（Retrieve）」し、その情報を基に回答を「生成（Generate）」する。",
          "毎日すべてのデータを再学習（ファインチューニング）し続ける。",
          "インターネット接続を遮断して、内部知識のみで回答させる。"
        ],
        "correctAnswer": "質問に対して、まず外部データベースから関連情報を「検索（Retrieve）」し、その情報を基に回答を「生成（Generate）」する。",
        "explanation": "正解は選択肢2です。RAGは「検索（Retrieval）」と「生成（Generation）」を組み合わせることで、学習データに含まれない最新情報や社内情報に対応します。通常の生成AIは学習時点までの知識しか持たず、最新情報や社内文書などの外部データに直接アクセスできませんが、RAGはこの課題を解決します。選択肢1、3、4は誤りです。"
      },
      {
        "question": "RAGシステムを構築する際、検索精度を高めるために長い文書を意味のまとまりごとに分割する処理を何と呼ぶか。",
        "options": [
          "チャンク分割（Chunking）",
          "スクレイピング",
          "プロンプトエンジニアリング",
          "バイアス除去"
        ],
        "correctAnswer": "チャンク分割（Chunking）",
        "explanation": "正解は選択肢1です。文書を適切なサイズ（チャンク）に分割し、ベクトル化して保存することがRAGの精度向上に不可欠です。長い文書をそのまま扱うと検索精度が下がるため、意味のまとまりごとに分割することで、関連する情報を正確に検索できるようになります。選択肢2の「スクレイピング」はWebページからデータを抽出する技術、選択肢3の「プロンプトエンジニアリング」はプロンプトを最適化する技術、選択肢4の「バイアス除去」はデータの偏りを減らす処理です。"
      },
      {
        "question": "文書や質問の意味的な類似性を計算するために、RAGシステムにおいてテキストデータを数値の列に変換する処理を何と呼ぶか。",
        "options": [
          "暗号化",
          "圧縮",
          "ベクトル化（エンベッディング）",
          "翻訳"
        ],
        "correctAnswer": "ベクトル化（エンベッディング）",
        "explanation": "正解は選択肢3です。コンピュータが意味の近さを計算できるように、テキストを多次元の数値ベクトルに変換することをエンベッディングと呼びます。これにより、意味的に似た文書や質問を検索できるようになります。選択肢1の「暗号化」は情報を秘匿する処理、選択肢2の「圧縮」はデータサイズを減らす処理、選択肢4の「翻訳」は言語を変換する処理です。"
      },
      {
        "question": "従来のファインチューニング（追加学習）と比較した際の、RAGのメリットとして誤っているものはどれか。",
        "options": [
          "データの更新が容易である（データベースに追加するだけでよい）。",
          "回答の根拠（出典）を明示しやすい。",
          "ハルシネーション（もっともらしい嘘）を完全にゼロにできる。",
          "再学習にかかる膨大なコストや時間を削減できる。"
        ],
        "correctAnswer": "ハルシネーション（もっともらしい嘘）を完全にゼロにできる。",
        "explanation": "正解は選択肢3です。RAGはハルシネーションを「低減」しますが、「完全にゼロ」にすることはできません。他の選択肢はRAGの明確なメリットです。選択肢1は、RAGではデータベースに情報を追加するだけで知識を更新できるため、再学習が不要です。選択肢2は、RAGでは検索した情報を根拠として提示できるため、回答の信頼性が高まります。選択肢4は、再学習にかかるコストや時間を削減できる点がRAGの大きなメリットです。"
      },
      {
        "question": "企業内でRAGを活用するユースケースとして、最も適切なものはどれか。",
        "options": [
          "社内マニュアルや過去のトラブル事例を検索対象とし、新人オペレーターの質問に即座に回答させる。",
          "一般的な雑談相手として利用する。",
          "競合他社の機密情報を違法に収集させる。",
          "社内のPCのパスワードを強制的に解除させる。"
        ],
        "correctAnswer": "社内マニュアルや過去のトラブル事例を検索対象とし、新人オペレーターの質問に即座に回答させる。",
        "explanation": "正解は選択肢1です。企業固有の知識（社内規定、マニュアル、過去事例）に基づいた回答生成は、RAGの最も代表的な活用例です。社内ナレッジ検索、FAQ自動応答、法務・医療文書検索、カスタマーサポート支援など、業務システムとの親和性が非常に高い技術です。選択肢2は一般的な用途でRAGの特徴を活かせません。選択肢3、4は違法または不適切な用途です。"
      },
      {
        "question": "2020年にRAGの概念を提唱した論文を発表した組織はどこか。",
        "options": [
          "OpenAI",
          "Google DeepMind",
          "Facebook AI Research (現Meta AI)",
          "Apple"
        ],
        "correctAnswer": "Facebook AI Research (現Meta AI)",
        "explanation": "正解は選択肢3です。2020年にFacebook AI ResearchのPatrick LewisらのチームがRAGの概念を正式に提案しました。RAGは第4版テキストの最重要項目の一つであり、生成AIの弱点である情報の古さや誤情報（ハルシネーション）を補うために開発された技術です。選択肢1、2、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 3,
    "sectionId": "unit04-ai-agent",
    "sectionTitle": "AIエージェント",
    "questions": [
      {
        "question": "第4版テキストにおける「AIエージェント」の定義として、従来のチャットボットと決定的に異なる特徴はどれか。",
        "options": [
          "音声で会話ができる点。",
          "感情を持っている点。",
          "目標を与えられると、自律的に「計画→行動→評価」のループを回し、ツールを使用してタスクを完遂しようとする点。",
          "常にインターネットから切断されている点。"
        ],
        "correctAnswer": "目標を与えられると、自律的に「計画→行動→評価」のループを回し、ツールを使用してタスクを完遂しようとする点。",
        "explanation": "正解は選択肢3です。単なる応答（Chat）ではなく、自律的に計画し行動（Action）する点がエージェントの本質です。AIエージェントは、与えられた目標を達成するために、自分で考え、行動し、結果を見て評価しながら作業を進めるAIシステムです。チャットボットが「会話」が主なのに対し、エージェントは目標達成のために自律的に「行動（ツール実行、ブラウザ操作など）」する点が特徴です。選択肢1、2、4は誤りです。"
      },
      {
        "question": "Anthropic社が提唱している、AIモデルと外部ツール（データベースやAPI）を接続するためのオープンな標準規格であり、「AI版のUSB」とも例えられる技術は何か。",
        "options": [
          "API Gateway",
          "MCP (Model Context Protocol)",
          "SQL",
          "RESTful API"
        ],
        "correctAnswer": "MCP (Model Context Protocol)",
        "explanation": "正解は選択肢2です。MCPは、LLMと外部ツールを安全かつ標準的に接続するためのプロトコルで、個別のコネクタ開発を不要にする「AI版USB」です。これにより、AIエージェントが様々な外部ツールと連携しやすくなります。選択肢1の「API Gateway」はAPIの管理システム、選択肢3の「SQL」はデータベース言語、選択肢4の「RESTful API」はWeb APIの設計方式です。"
      },
      {
        "question": "AIエージェントの実装アプローチのうち、「ワークフロー型」の説明として適切なものはどれか。",
        "options": [
          "最終目標だけを与えれば、AIが勝手に手順を考えて実行する。",
          "あらかじめ定義された業務フロー（手順や分岐）に従って、LLMがタスクを実行する。RPAに近い考え方。",
          "完全にランダムに行動する。",
          "常に人間が操作する必要がある。"
        ],
        "correctAnswer": "あらかじめ定義された業務フロー（手順や分岐）に従って、LLMがタスクを実行する。RPAに近い考え方。",
        "explanation": "正解は選択肢2です。エージェントには「ワークフロー型（手順固定）」と「自律型（目標のみ指定）」があり、前者は定型業務の自動化に向いています。ワークフロー型は、決まった手順に従ってタスクを実行するため、RPA（Robotic Process Automation）に近い考え方です。選択肢1は自律型の説明、選択肢3、4は誤りです。"
      },
      {
        "question": "シンガポール発のAIエージェント「Manus」の特徴として紹介されている機能はどれか。",
        "options": [
          "多数の履歴書を分析し、評価結果をExcelにまとめるなどの複雑な事務処理を、人手を介さず全自動で遂行する。",
          "ゲームをプレイする。",
          "天気予報のみを行う。",
          "画像生成のみを行う。"
        ],
        "correctAnswer": "多数の履歴書を分析し、評価結果をExcelにまとめるなどの複雑な事務処理を、人手を介さず全自動で遂行する。",
        "explanation": "正解は選択肢1です。Manusは汎用エージェントとして、複雑なオンライン業務や事務処理の全自動化が可能とされています。AIエージェントは、単発の質問に答える生成AIとは異なり、複数の工程を連続的に処理できる点が特徴です。選択肢2、3、4は誤りです。"
      },
      {
        "question": "AIエージェントが外部ツールを実行したり情報を取得したりするために必要な、拡張LLMの3つの機能要素は「検索(Retrieval)」「メモリ(Memory)」ともう一つは何か。",
        "options": [
          "ツール呼び出し（Tool Use）",
          "画像認識",
          "音声合成",
          "感情分析"
        ],
        "correctAnswer": "ツール呼び出し（Tool Use）",
        "explanation": "正解は選択肢1です。エージェントが行動するためには、外部の機能を実行するための「ツール呼び出し（Tool Use）」機能が不可欠です。AIエージェントは、検索エンジン、データベース、ブラウザ操作、業務システムなどと連携し、情報取得から処理、実行までを一貫して自動化できます。選択肢2、3、4は誤りです。"
      },
      {
        "question": "生成AIが扱う「モダリティ」とは何を指すか。",
        "options": [
          "AIモデルのパラメータ数のこと。",
          "データの種類や形式（テキスト、画像、音声、動画など）のこと。",
          "AIの学習速度のこと。",
          "AIの応答時間のこと。"
        ],
        "correctAnswer": "データの種類や形式（テキスト、画像、音声、動画など）のこと。",
        "explanation": "正解は選択肢2です。モダリティとは、生成AIが扱うデータの種類や形式を指します。テキスト、画像、音声、動画など、異なる形式のデータを生成AIは処理・生成できます。選択肢1、3、4は誤りです。",
        "questionId": "unit_058"
      },
      {
        "question": "画像生成AIにおいて、「拡散モデル（Diffusion Model）」の基本的な動作原理として最も適切なものはどれか。",
        "options": [
          "ノイズから画像を段階的に生成する。",
          "既存の画像をコピーするだけである。",
          "テキストのみを生成する。",
          "音声を生成する。"
        ],
        "correctAnswer": "ノイズから画像を段階的に生成する。",
        "explanation": "正解は選択肢1です。拡散モデルは、ランダムなノイズから始めて、段階的にノイズを除去しながら画像を生成する手法です。これにより、高品質な画像を生成できます。選択肢2、3、4は誤りです。",
        "questionId": "unit_059"
      },
      {
        "question": "音声生成AIの主な用途として、最も適切でないものはどれか。",
        "options": [
          "バーチャルアシスタントの音声合成",
          "多言語の音声翻訳",
          "画像の生成",
          "オーディオブックの自動生成"
        ],
        "correctAnswer": "画像の生成",
        "explanation": "正解は選択肢3です。音声生成AIは音声を生成する技術であり、画像の生成は画像生成AIの役割です。選択肢1、2、4は音声生成AIの適切な用途です。",
        "questionId": "unit_060"
      },
      {
        "question": "動画生成AIの技術的な課題として、最も適切なものはどれか。",
        "options": [
          "動画の時間的な一貫性を保つことが難しい。",
          "静止画しか生成できない。",
          "音声のみを生成できる。",
          "テキストのみを生成できる。"
        ],
        "correctAnswer": "動画の時間的な一貫性を保つことが難しい。",
        "explanation": "正解は選択肢1です。動画生成では、フレーム間の時間的な一貫性を保つことが技術的な課題となっています。動画は複数のフレームが連続して構成されるため、各フレーム間の自然なつながりを実現することが重要です。選択肢2、3、4は誤りです。",
        "questionId": "unit_061"
      },
      {
        "question": "ディープフェイク技術が社会的に問題視される主な理由として、最も適切なものはどれか。",
        "options": [
          "計算コストが高いため。",
          "実在する人物の顔や声を模倣し、真偽の識別が困難な合成コンテンツを作成できるため。",
          "画像の解像度が低いため。",
          "音声の品質が悪いため。"
        ],
        "correctAnswer": "実在する人物の顔や声を模倣し、真偽の識別が困難な合成コンテンツを作成できるため。",
        "explanation": "正解は選択肢2です。ディープフェイク技術は、実在する人物の顔や声を本物のように合成できるため、詐欺や情報操作に悪用されるリスクがあります。真偽の識別が困難であることが最大の問題です。選択肢1、3、4は誤りです。",
        "questionId": "unit_062"
      },
      {
        "question": "ディープフェイクを検出するための対策として、最も適切なものはどれか。",
        "options": [
          "AIによる自動検出システムの開発",
          "ディープフェイクの使用を完全に禁止する",
          "インターネットの使用を禁止する",
          "画像や動画の共有を禁止する"
        ],
        "correctAnswer": "AIによる自動検出システムの開発",
        "explanation": "正解は選択肢1です。ディープフェイクに対抗するため、AI技術を用いた自動検出システムの開発が進められています。技術的な対策と、情報リテラシーの向上の両面から対応が求められています。選択肢2、3、4は現実的ではありません。",
        "questionId": "unit_063"
      },
      {
        "question": "RAGシステムにおいて、「検索（Retrieval）」の段階で行われる処理として、最も適切なものはどれか。",
        "options": [
          "質問に対して、外部データベースから関連する情報を探し出す。",
          "回答を生成する。",
          "モデルを再学習する。",
          "画像を生成する。"
        ],
        "correctAnswer": "質問に対して、外部データベースから関連する情報を探し出す。",
        "explanation": "正解は選択肢1です。RAGの「Retrieval（検索）」段階では、ユーザーの質問に対して、外部データベースや文書から関連する情報を検索します。その後、検索した情報を基に回答を生成します。選択肢2は「Generation（生成）」段階、選択肢3、4は誤りです。",
        "questionId": "unit_064"
      },
      {
        "question": "RAGシステムの「生成（Generation）」段階において、検索した情報をどのように活用するか。",
        "options": [
          "検索した情報を無視して回答を生成する。",
          "検索した情報をコンテキストとして与え、その情報を基に回答を生成する。",
          "検索した情報を削除する。",
          "検索した情報を画像に変換する。"
        ],
        "correctAnswer": "検索した情報をコンテキストとして与え、その情報を基に回答を生成する。",
        "explanation": "正解は選択肢2です。RAGの「Generation（生成）」段階では、検索で取得した情報をコンテキストとしてLLMに与え、その情報を基に回答を生成します。これにより、学習データに含まれない最新情報や社内情報に基づいた回答が可能になります。選択肢1、3、4は誤りです。",
        "questionId": "unit_065"
      },
      {
        "question": "RAGシステムを構築する際、ベクトルデータベース（Vector Database）を使用する主な理由として、最も適切なものはどれか。",
        "options": [
          "意味的に類似した文書を高速に検索するため。",
          "画像を保存するため。",
          "音声を保存するため。",
          "動画を保存するため。"
        ],
        "correctAnswer": "意味的に類似した文書を高速に検索するため。",
        "explanation": "正解は選択肢1です。ベクトルデータベースは、文書をベクトル化して保存し、意味的に類似した文書を高速に検索するために使用されます。これにより、RAGシステムの検索精度と速度が向上します。選択肢2、3、4は誤りです。",
        "questionId": "unit_066"
      },
      {
        "question": "RAGシステムにおいて、「グラウンディング（Grounding）」とは何を指すか。",
        "options": [
          "回答の根拠となる情報源（ソース）を明示すること。",
          "AIモデルを地面に設置すること。",
          "画像を生成すること。",
          "音声を生成すること。"
        ],
        "correctAnswer": "回答の根拠となる情報源（ソース）を明示すること。",
        "explanation": "正解は選択肢1です。グラウンディングとは、生成AIの回答がどの情報源に基づいているかを明示することで、回答の信頼性を高める手法です。RAGシステムでは、検索した文書の出典を提示することで、ユーザーが回答の根拠を確認できます。選択肢2、3、4は誤りです。",
        "questionId": "unit_067"
      },
      {
        "question": "AIエージェントの「自律型」アプローチの特徴として、最も適切なものはどれか。",
        "options": [
          "最終目標だけを与えれば、AIが自ら手順を考えて実行する。",
          "あらかじめ定義された手順に従ってのみ実行する。",
          "常に人間が操作する必要がある。",
          "ランダムに行動する。"
        ],
        "correctAnswer": "最終目標だけを与えれば、AIが自ら手順を考えて実行する。",
        "explanation": "正解は選択肢1です。自律型エージェントは、最終目標だけを与えられると、自ら計画を立て、実行し、評価しながらタスクを完遂します。これに対し、ワークフロー型はあらかじめ定義された手順に従います。選択肢2はワークフロー型の説明、選択肢3、4は誤りです。",
        "questionId": "unit_068"
      },
      {
        "question": "AIエージェントが「計画→行動→評価」のループを回す際、「評価」段階で行われる処理として、最も適切なものはどれか。",
        "options": [
          "実行結果を確認し、目標達成度を判断し、必要に応じて計画を修正する。",
          "画像を生成する。",
          "音声を生成する。",
          "動画を生成する。"
        ],
        "correctAnswer": "実行結果を確認し、目標達成度を判断し、必要に応じて計画を修正する。",
        "explanation": "正解は選択肢1です。AIエージェントの「評価」段階では、実行した結果を確認し、目標にどれだけ近づいたかを判断します。目標が達成されていない場合は、計画を見直して再度実行します。このループを繰り返すことで、タスクを完遂します。選択肢2、3、4は誤りです。",
        "questionId": "unit_069"
      },
      {
        "question": "AIエージェントが外部ツールを使用する際の「ツール呼び出し（Tool Use）」の説明として、最も適切なものはどれか。",
        "options": [
          "検索エンジン、データベース、ブラウザ操作などの外部機能を実行する機能。",
          "画像を生成する機能。",
          "音声を生成する機能。",
          "動画を生成する機能。"
        ],
        "correctAnswer": "検索エンジン、データベース、ブラウザ操作などの外部機能を実行する機能。",
        "explanation": "正解は選択肢1です。ツール呼び出し（Tool Use）は、AIエージェントが外部の機能やサービスを実行するための機能です。検索エンジンで情報を取得したり、データベースにアクセスしたり、ブラウザを操作したりすることで、タスクを完遂します。選択肢2、3、4は誤りです。",
        "questionId": "unit_070"
      },
      {
        "question": "AIエージェントの「メモリ（Memory）」機能の役割として、最も適切なものはどれか。",
        "options": [
          "過去の会話履歴や実行結果を記憶し、文脈を保持する機能。",
          "画像を保存する機能。",
          "音声を保存する機能。",
          "動画を保存する機能。"
        ],
        "correctAnswer": "過去の会話履歴や実行結果を記憶し、文脈を保持する機能。",
        "explanation": "正解は選択肢1です。AIエージェントのメモリ機能は、過去の会話履歴や実行結果を記憶し、文脈を保持することで、一貫性のある行動を可能にします。これにより、長期的なタスクや複数のステップを要するタスクを実行できます。選択肢2、3、4は誤りです。",
        "questionId": "unit_071"
      },
      {
        "question": "マルチモーダル生成AIの特徴として、最も適切なものはどれか。",
        "options": [
          "テキスト、画像、音声など、複数の形式のデータを同時に理解・生成できる。",
          "テキストのみを生成できる。",
          "画像のみを生成できる。",
          "音声のみを生成できる。"
        ],
        "correctAnswer": "テキスト、画像、音声など、複数の形式のデータを同時に理解・生成できる。",
        "explanation": "正解は選択肢1です。マルチモーダル生成AIは、テキスト、画像、音声、動画など、複数の形式のデータを同時に理解し、生成できるAIです。これにより、より自然で統合的な対話やタスク実行が可能になります。選択肢2、3、4は単一モダリティの説明です。",
        "questionId": "unit_072"
      },
      {
        "question": "生成AIにおける「ナレッジカットオフ」の問題とは何か。",
        "options": [
          "AIの学習時点以降の最新情報や、学習データに含まれていない情報に対応できない問題。",
          "AIが情報を削除する問題。",
          "AIが画像を生成できない問題。",
          "AIが音声を生成できない問題。"
        ],
        "correctAnswer": "AIの学習時点以降の最新情報や、学習データに含まれていない情報に対応できない問題。",
        "explanation": "正解は選択肢1です。ナレッジカットオフとは、生成AIが学習時点までの情報しか持たず、その後の最新情報や学習データに含まれていない情報（例：社内文書）に対応できない問題です。RAGはこの問題を解決する技術です。選択肢2、3、4は誤りです。",
        "questionId": "unit_073"
      },
      {
        "question": "RAGシステムにおいて、チャンク分割（Chunking）を行う際の適切なサイズの目安として考慮すべき要素として、最も適切でないものはどれか。",
        "options": [
          "文書の意味的なまとまりを保つこと。",
          "検索精度と処理速度のバランスを取ること。",
          "チャンクサイズを無限に大きくすること。",
          "文脈が失われないようにすること。"
        ],
        "correctAnswer": "チャンクサイズを無限に大きくすること。",
        "explanation": "正解は選択肢3です。チャンク分割では、文書を適切なサイズに分割することが重要です。大きすぎると検索精度が下がり、小さすぎると文脈が失われます。意味的なまとまりを保ちながら、検索精度と処理速度のバランスを取ることが重要です。選択肢1、2、4は適切な考慮事項です。",
        "questionId": "unit_074"
      },
      {
        "question": "AIエージェントと従来の自動化システム（RPAなど）の主な違いとして、最も適切なものはどれか。",
        "options": [
          "AIエージェントは状況に応じて柔軟に対応できるが、RPAは決められた手順に従う。",
          "RPAは柔軟に対応できるが、AIエージェントは決められた手順に従う。",
          "両者に違いはない。",
          "AIエージェントは画像のみを生成する。"
        ],
        "correctAnswer": "AIエージェントは状況に応じて柔軟に対応できるが、RPAは決められた手順に従う。",
        "explanation": "正解は選択肢1です。AIエージェントは、状況に応じて柔軟に判断し、計画を修正しながらタスクを実行できます。一方、RPA（Robotic Process Automation）は、あらかじめ定義された手順に従って実行する自動化システムです。選択肢2、3、4は誤りです。",
        "questionId": "unit_075"
      },
      {
        "question": "生成AIの活用において、「ハルシネーション（Hallucination）」とは何を指すか。",
        "options": [
          "AIが事実に基づかない、もっともらしい誤った情報を生成すること。",
          "AIが画像を生成すること。",
          "AIが音声を生成すること。",
          "AIが動画を生成すること。"
        ],
        "correctAnswer": "AIが事実に基づかない、もっともらしい誤った情報を生成すること。",
        "explanation": "正解は選択肢1です。ハルシネーションとは、生成AIが事実に基づかない、しかし一見正しそうに見える誤った情報を生成する現象です。RAGやグラウンディングなどの技術により、ハルシネーションを低減することができます。選択肢2、3、4は誤りです。",
        "questionId": "unit_076"
      },
      {
        "question": "生成AIの実務活用において、RAGシステムが特に有効な場面として、最も適切なものはどれか。",
        "options": [
          "社内のマニュアルや過去の事例に基づいた質問応答システム。",
          "一般的な雑談のみを行うシステム。",
          "画像のみを生成するシステム。",
          "音声のみを生成するシステム。"
        ],
        "correctAnswer": "社内のマニュアルや過去の事例に基づいた質問応答システム。",
        "explanation": "正解は選択肢1です。RAGシステムは、社内のマニュアル、過去の事例、専門文書など、特定の知識ベースに基づいた質問応答システムに特に有効です。これにより、学習データに含まれていない社内情報に基づいた回答が可能になります。選択肢2、3、4は誤りです。",
        "questionId": "unit_077"
      }
    ]
  },
  {
    "chapter": 4,
    "sectionId": "unit01-internet-literacy",
    "sectionTitle": "インターネットリテラシーの基礎",
    "questions": [
      {
        "question": "攻撃者が緊急性や権威を装い、人間の心理的な隙や行動のミスにつけ込んで機密情報を盗み出す攻撃手法を何と呼ぶか。",
        "options": [
          "SQLインジェクション",
          "ソーシャルエンジニアリング",
          "DDoS攻撃",
          "ゼロデイ攻撃"
        ],
        "correctAnswer": "ソーシャルエンジニアリング",
        "explanation": "正解は「ソーシャルエンジニアリング」です。技術的な脆弱性ではなく、人間の心理（焦りや恐怖など）を利用して情報を盗む手法です。AIによるなりすましもこの一種として警戒が必要です。選択肢1の「SQLインジェクション」はデータベースへの不正なSQL文の挿入、選択肢3の「DDoS攻撃」は大量のトラフィックを送りつける攻撃、選択肢4の「ゼロデイ攻撃」は未知の脆弱性を突く攻撃です。"
      },
      {
        "question": "生成AI技術の悪用により、実在する人物の声色や話し方をAIで模倣し、電話で金銭を騙し取る詐欺手法として、テキストで紹介されている事例はどれか。",
        "options": [
          "ワンクリック詐欺",
          "ディープフェイクボイス詐欺（オレオレ詐欺の高度化）",
          "ランサムウェア攻撃",
          "クロスサイトスクリプティング"
        ],
        "correctAnswer": "ディープフェイクボイス詐欺（オレオレ詐欺の高度化）",
        "explanation": "正解は「ディープフェイクボイス詐欺（オレオレ詐欺の高度化）」です。AIによる音声合成（音声クローン）技術が悪用され、親族や取引先になりすます詐欺が発生しています。生成AI技術の悪用により、実在する人物の声色や話し方をAIで模倣し、電話で金銭を騙し取る手法です。選択肢1の「ワンクリック詐欺」はクリックだけで料金が発生する詐欺、選択肢3の「ランサムウェア攻撃」はデータを暗号化して身代金を要求する攻撃、選択肢4の「クロスサイトスクリプティング」はWebサイトへのスクリプト注入攻撃です。"
      },
      {
        "question": "フィッシング詐欺への対策として、組織内で実施すべき「技術的対策」と「人的対策」の組み合わせとして最も適切なものはどれか。",
        "options": [
          "パスワードを紙に書いて貼る・全員で共有する",
          "多要素認証（MFA）の導入・不審なメールを見抜くための疑似訓練",
          "ウイルス対策ソフトをアンインストールする・全てのリンクをクリックする",
          "社外との通信を全て遮断する・パソコンを使わない"
        ],
        "correctAnswer": "多要素認証（MFA）の導入・不審なメールを見抜くための疑似訓練",
        "explanation": "正解は「多要素認証（MFA）の導入・不審なメールを見抜くための疑似訓練」です。システム側での多要素認証（MFA）と、人間側でのリテラシー向上（訓練）の両輪が不可欠です。技術的対策と人的対策を組み合わせることで、フィッシング詐欺への防御が強化されます。選択肢1、3、4は不適切な対策です。"
      },
      {
        "question": "公衆Wi-Fi（フリーWi-Fi）を利用する際のリスクと対策として、適切な記述はどれか。",
        "options": [
          "パスワードがかかっていれば絶対に安全である。",
          "攻撃者が設置した偽のアクセスポイント（なりすましWi-Fi）に接続すると、通信内容を盗聴される恐れがあるため、VPNの利用や機密情報の入力を避ける対策が必要である。",
          "スマートフォンの「Wi-Fi自動接続」は常にオンにしておくべきである。",
          "Wi-Fi経由ではウイルスには感染しない。"
        ],
        "correctAnswer": "攻撃者が設置した偽のアクセスポイント（なりすましWi-Fi）に接続すると、通信内容を盗聴される恐れがあるため、VPNの利用や機密情報の入力を避ける対策が必要である。",
        "explanation": "正解は選択肢2です。正規のWi-Fiに見せかけた罠（Evil Twin）が存在するため、自動接続をオフにし、VPNを利用する等の対策が推奨されます。公衆Wi-Fiを利用する際は、偽のアクセスポイントに接続されないよう注意し、VPNの利用や機密情報の入力を避けることが重要です。選択肢1、3、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 4,
    "sectionId": "unit02-personal-info-ai",
    "sectionTitle": "個人情報保護と生成AI",
    "questions": [
      {
        "question": "個人情報保護法において、本人の人種、信条、社会的身分、病歴、犯罪歴など、不当な差別や偏見が生じる可能性があるため、取得にあたって原則として本人の同意が必要な情報を何と呼ぶか。",
        "options": [
          "機微情報（センシティブ情報）",
          "特定個人情報",
          "要配慮個人情報",
          "基本個人情報"
        ],
        "correctAnswer": "要配慮個人情報",
        "explanation": "正解は「要配慮個人情報」です。法令上の用語は「要配慮個人情報」です。「機微情報」は金融ガイドライン等で使われるより広い概念ですが、法の定義としては要配慮個人情報が正解です。人種、信条、社会的身分、病歴、犯罪歴など、差別や不利益につながる可能性が高い情報です。"
      },
      {
        "question": "AIサービスを利用する際、入力したデータがAIモデルの学習に再利用されないようにするために行うべき設定や手続きを何と呼ぶか。",
        "options": [
          "オプトイン",
          "オプトアウト",
          "サインアップ",
          "バックアップ"
        ],
        "correctAnswer": "オプトアウト",
        "explanation": "正解は「オプトアウト」です。「学習利用を拒否する（利用させない）」意思表示や設定をオプトアウトと呼びます。企業利用では必須の確認事項です。選択肢1の「オプトイン」は同意を得て利用する方式、選択肢3の「サインアップ」はサービスへの登録、選択肢4の「バックアップ」はデータの複製保存です。"
      },
      {
        "question": "「匿名加工情報」の定義として、正しい記述はどれか。",
        "options": [
          "特定の個人を識別できないように加工し、かつ、元の個人情報を復元できないようにした情報。",
          "名前だけを黒塗りにした情報（他の記述から特定できてもよい）。",
          "暗号化して保存した個人情報。",
          "特定の個人を識別できるが、外部には漏らさない情報。"
        ],
        "correctAnswer": "特定の個人を識別できないように加工し、かつ、元の個人情報を復元できないようにした情報。",
        "explanation": "正解は選択肢1です。単なるマスキングではなく、特定の個人を識別できず、かつ「復元も不可能」な状態に加工した情報を指します。匿名加工情報は、特定の個人を識別できないように加工し、かつ、元の個人情報を復元できないようにした情報です。選択肢2は単なるマスキング、選択肢3は暗号化（復号可能）、選択肢4は識別可能な情報なので誤りです。"
      },
      {
        "question": "改正個人情報保護法において、個人情報を取り扱う事業者の対象範囲はどう変化したか。",
        "options": [
          "大企業のみが対象となった。",
          "5,000人以上の個人情報を保有する事業者のみが対象となった。",
          "取り扱う個人情報の数に関わらず、全ての個人情報取扱事業者が法の適用対象となった。",
          "AIを利用する企業のみが対象となった。"
        ],
        "correctAnswer": "取り扱う個人情報の数に関わらず、全ての個人情報取扱事業者が法の適用対象となった。",
        "explanation": "正解は選択肢3です。かつての「5,000人要件」は撤廃され、小規模事業者や個人事業主を含むすべての事業者が法の適用対象となっています。改正個人情報保護法において、個人情報を取り扱う事業者の対象範囲は、取り扱う個人情報の数に関わらず、全ての個人情報取扱事業者が法の適用対象となりました。選択肢1、2、4は誤りです。"
      },
      {
        "question": "金融分野のガイドラインにおける「機微（センシティブ）情報」の取り扱いとして、適切なものはどれか。",
        "options": [
          "自由に売買できる。",
          "要配慮個人情報に加え、労働組合への加盟や性生活なども含み、原則として取得・利用・第三者提供が禁止されている。",
          "本人の同意がなくても自由にWebで公開できる。",
          "社内であれば自由に共有できる。"
        ],
        "correctAnswer": "要配慮個人情報に加え、労働組合への加盟や性生活なども含み、原則として取得・利用・第三者提供が禁止されている。",
        "explanation": "正解は選択肢2です。金融分野では「機微情報」として、要配慮個人情報よりも広い範囲（労組加盟など）を含み、原則取得禁止という厳しい制限があります。金融分野のガイドラインにおける「機微（センシティブ）情報」は、要配慮個人情報に加え、労働組合への加盟や性生活なども含み、原則として取得・利用・第三者提供が禁止されています。選択肢1、3、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 4,
    "sectionId": "unit03-copyright",
    "sectionTitle": "制作物に関わる権利（知的財産権）",
    "questions": [
      {
        "question": "他人の著作物の権利を侵害している（著作権侵害）と判断されるために必要な2つの要件は、「類似性」ともう一つは何か。",
        "options": [
          "独創性",
          "依拠性（いきょせい）",
          "商業性",
          "芸術性"
        ],
        "correctAnswer": "依拠性（いきょせい）",
        "explanation": "正解は「依拠性（いきょせい）」です。侵害成立には「似ていること（類似性）」に加え、「既存の著作物を知っていて、それに基づいたこと（依拠性）」の両方が必要です。著作権侵害と判断されるためには、「類似性」と「依拠性（既存の著作物を知っていて、それに基づいたこと）」の両方が必要です。選択肢1の「独創性」、選択肢3の「商業性」、選択肢4の「芸術性」は著作権侵害の要件ではありません。"
      },
      {
        "question": "文化庁の見解（令和6年）において、AI生成物が「著作物」として認められるために必要な要素は、「創作意図」ともう一つは何か。",
        "options": [
          "AIの性能の高さ",
          "プロンプトの長さ",
          "人間による「創作的寄与」（試行錯誤や加筆修正など）",
          "有料ツールの使用"
        ],
        "correctAnswer": "人間による「創作的寄与」（試行錯誤や加筆修正など）",
        "explanation": "正解は選択肢3です。AIが自律的に生成しただけでは著作物にならず、人間が道具としてAIを使いこなし、創作的に寄与したと認められる必要があります。文化庁の見解（令和6年）において、AI生成物が「著作物」として認められるためには、「創作意図」と「人間による創作的寄与（試行錯誤や加筆修正など）」が必要です。選択肢1、2、4は著作物として認められる条件ではありません。"
      },
      {
        "question": "日本の著作権法において、個人の著作物の保護期間は原則としていつまでか。",
        "options": [
          "創作から50年",
          "著作者の死後70年",
          "公表から20年",
          "永久に保護される"
        ],
        "correctAnswer": "著作者の死後70年",
        "explanation": "正解は「著作者の死後70年」です。原則として著作者の死後70年まで保護されます。保護期間が終了したものはパブリックドメインとなります。日本の著作権法では、原則として著作者の死後70年まで著作権が保護されます。選択肢1、3、4は誤りです。"
      },
      {
        "question": "著名人の肖像（顔や姿）や氏名が持つ「顧客吸引力（経済的価値）」を排他的に利用する権利を何と呼ぶか。AI生成物で無断利用した場合に侵害となる恐れがある。",
        "options": [
          "肖像権",
          "パブリシティ権",
          "商標権",
          "意匠権"
        ],
        "correctAnswer": "パブリシティ権",
        "explanation": "正解は「パブリシティ権」です。プライバシーの保護（肖像権）とは別に、有名人の名前や姿を勝手に商品に使って利益を得ることを防ぐ権利が「パブリシティ権」です。著名人の肖像（顔や姿）や氏名が持つ「顧客吸引力（経済的価値）」を排他的に利用する権利です。選択肢1の「肖像権」はプライバシー保護の権利、選択肢3の「商標権」は商標の権利、選択肢4の「意匠権」はデザインの権利です。"
      },
      {
        "question": "「不正競争防止法」によって保護される「営業秘密」の3要件に含まれないものはどれか。",
        "options": [
          "秘密管理性（秘密として管理されていること）",
          "有用性（事業活動に有用であること）",
          "非公知性（公然と知られていないこと）",
          "審美性（見た目が美しいこと）"
        ],
        "correctAnswer": "審美性（見た目が美しいこと）",
        "explanation": "正解は選択肢4です。営業秘密の3要件は「秘密管理性」「有用性」「非公知性」です。審美性は意匠権などの要件です。不正競争防止法によって保護される「営業秘密」の3要件は、「秘密管理性（秘密として管理されていること）」「有用性（事業活動に有用であること）」「非公知性（公然と知られていないこと）」です。選択肢4の「審美性」は含まれません。"
      },
      {
        "question": "AIを利用して他人の登録商標と類似したロゴを作成し、商用利用した場合の法的判断として正しいものはどれか。",
        "options": [
          "AIが作ったものなので、責任はAI開発者にある。",
          "模倣する意図がなくても、結果的に類似しており、商用利用すれば商標権侵害となる可能性がある。",
          "プロンプトに商標名を入れなければ侵害にはならない。",
          "商標権はAI生成物には適用されない。"
        ],
        "correctAnswer": "模倣する意図がなくても、結果的に類似しており、商用利用すれば商標権侵害となる可能性がある。",
        "explanation": "正解は選択肢2です。商標権や意匠権は、著作権とは異なり「依拠性（マネする意図）」がなくても、登録された権利と類似していれば侵害となります。AIを利用して他人の登録商標と類似したロゴを作成し、商用利用した場合、模倣する意図がなくても、結果的に類似しており、商用利用すれば商標権侵害となる可能性があります。選択肢1、3、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 4,
    "sectionId": "unit04-ai-guidelines",
    "sectionTitle": "AI社会の基本理念とAI社会原則",
    "questions": [
      {
        "question": "「AI事業者ガイドライン（第1.1版）」において、AIビジネスに関わる主体は3つに分類されている。「AI開発者」「AI提供者」に加え、もう1つは何か。",
        "options": [
          "AI利用者（AI Business User）",
          "AI監視者",
          "AI規制者",
          "AI消費者"
        ],
        "correctAnswer": "AI利用者（AI Business User）",
        "explanation": "正解は「AI利用者（AI Business User）」です。ガイドラインでは、AIモデルを作る「開発者」、サービスとして提供する「提供者」、それを事業で活用する「利用者（主に企業）」の3主体それぞれの責務を規定しています。「AI事業者ガイドライン（第1.1版）」において、AIビジネスに関わる主体は「AI開発者（AIモデルを作る）」「AI提供者（サービスとして提供する）」「AI利用者（AI Business User、事業で活用する主に企業）」の3つに分類されています。選択肢2、3、4は誤りです。"
      },
      {
        "question": "AI事業者ガイドラインにおいて、「AI利用者（事業者）」に求められる重要な責務の一つはどれか。",
        "options": [
          "AIモデルのアルゴリズムをゼロから開発すること",
          "AIの判断結果に過度に依存せず、最終的な判断は人間が行う（人間中心の判断）こと",
          "すべてのデータを公開すること",
          "AIの利用を禁止すること"
        ],
        "correctAnswer": "AIの判断結果に過度に依存せず、最終的な判断は人間が行う（人間中心の判断）こと",
        "explanation": "正解は選択肢2です。利用者はAIを鵜呑みにせず、適正利用やリスク管理を行い、最終的な意思決定に責任を持つことが求められます。AI事業者ガイドラインにおいて、AI利用者（事業者）に求められる重要な責務の一つは、AIの判断結果に過度に依存せず、最終的な判断は人間が行う（人間中心の判断）ことです。選択肢1は開発者の責務、選択肢3、4は不適切です。"
      },
      {
        "question": "2025年に交付された「AI新法（人工知能関連技術の研究開発及び活用の推進に関する法律）」の特徴的な規制アプローチはどれか。",
        "options": [
          "すべてのAI開発を一律に禁止する",
          "リスクベース・アプローチ（AIのリスクの大きさに応じて、異なるレベルの義務や規制を課す）",
          "AI利用者のみを処罰する",
          "開発者の国籍で規制を変える"
        ],
        "correctAnswer": "リスクベース・アプローチ（AIのリスクの大きさに応じて、異なるレベルの義務や規制を課す）",
        "explanation": "正解は選択肢2です。AI新法や欧州AI法（EU AI Act）などは、高リスクなAIには厳しい規制を、低リスクなAIには緩やかな規制を適用する「リスクベース・アプローチ」を採用しています。2025年に交付された「AI新法（人工知能関連技術の研究開発及び活用の推進に関する法律）」の特徴的な規制アプローチは、リスクベース・アプローチです。AIのリスクの大きさに応じて、異なるレベルの義務や規制を課す方式で、高リスクなAIには厳しい規制を、低リスクなAIには緩やかな規制を適用します。選択肢1、3、4は誤りです。"
      },
      {
        "question": "AI倫理において、ブラックボックス化を防ぎ、判断根拠を説明できるようにすることを何と呼ぶか？",
        "options": [
          "公平性",
          "透明性・説明可能性",
          "人間中心",
          "安全性"
        ],
        "correctAnswer": "透明性・説明可能性",
        "explanation": "正解は「透明性・説明可能性」です。AI倫理において、ブラックボックス化を防ぎ、判断根拠を説明できるようにすることを透明性・説明可能性と呼びます。これはAI社会原則の柱の一つです。選択肢1の「公平性」、選択肢3の「人間中心」、選択肢4の「安全性」もAI倫理の重要な概念ですが、判断根拠の説明可能性を指すのは「透明性・説明可能性」です。"
      },
      {
        "question": "AI社会原則の一つである「人間中心（Human-centric）」の考え方として適切なものはどれか。",
        "options": [
          "AIが人間の代わりに全ての政治的決定を行うべきである。",
          "AIは人間の尊厳や基本的人権を尊重し、人間の幸福や能力拡張のために利用されるべきである。",
          "人間はAIの進化のために奉仕すべきである。",
          "AIの効率性を最優先し、人間の雇用は考慮しなくてよい。"
        ],
        "correctAnswer": "AIは人間の尊厳や基本的人権を尊重し、人間の幸福や能力拡張のために利用されるべきである。",
        "explanation": "正解は選択肢2です。AIはあくまで人間のための道具であり、人間の尊厳や権利が脅かされないよう、人間がコントロール権を持つべきという原則です。AI社会原則の「人間中心（Human-centric）」の考え方とは、AIは人間の尊厳や基本的人権を尊重し、人間の幸福や能力拡張のために利用されるべきであるという考え方です。AIは人間の能力を拡張し、社会全体の幸福と発展に貢献する存在であるべきとされています。選択肢1、3、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 5,
    "sectionId": "unit01-llm-params",
    "sectionTitle": "LLMの仕組みとパラメータ",
    "questions": [
      {
        "question": "「LM（言語モデル）」と「LLM（大規模言語モデル）」の主な違いに関する記述として、最も適切なものはどれか。",
        "options": [
          "LMは画像データを学習するが、LLMはテキストデータを学習する。",
          "LMはn-gramなどの統計手法を用いることが多いが、LLMは計算量とデータ量が桁違いに巨大なニューラルネットワークを用いて構築される。",
          "LMは翻訳専用だが、LLMは要約専用である。",
          "両者に違いはなく、呼び方が変わっただけである。"
        ],
        "correctAnswer": "LMはn-gramなどの統計手法を用いることが多いが、LLMは計算量とデータ量が桁違いに巨大なニューラルネットワークを用いて構築される。",
        "explanation": "正解は選択肢2です。LLMは数十億以上のパラメータと大規模なデータセットを用いてトレーニングされたモデルであり、従来のLMとは規模と汎用性が決定的に異なります。選択肢1、3、4は誤りです。"
      },
      {
        "question": "LLMの学習プロセスにおける「プレトレーニング（事前学習）」と「ファインチューニング（微調整）」の関係として正しいものはどれか。",
        "options": [
          "ファインチューニングを行ってから、プレトレーニングを行う。",
          "プレトレーニングで一般的な言語知識を大量に学習し、その後ファインチューニングで特定のタスクや目的に合わせて調整する。",
          "プレトレーニングのみでモデルは完成し、ファインチューニングは不要である。",
          "ファインチューニングはモデルのサイズを小さくする工程である。"
        ],
        "correctAnswer": "プレトレーニングで一般的な言語知識を大量に学習し、その後ファインチューニングで特定のタスクや目的に合わせて調整する。",
        "explanation": "正解は選択肢2です。汎用的な知識を学ぶ「プレトレーニング」と、特定用途に特化させる「ファインチューニング」の2段階構成がLLMの基本です。選択肢1、3、4は誤りです。"
      },
      {
        "question": "生成AIの出力の「ランダム性（創造性）」を調整するハイパーパラメータである「Temperature（温度）」の設定について、正しい説明はどれか。",
        "options": [
          "値を「0」に近づけると、毎回同じような確実性の高い回答が出やすくなる（論理的タスク向き）。",
          "値を「1」に近づけると、回答が固定的になり、面白みがなくなる。",
          "値を高くすると、計算速度が速くなる。",
          "値を低くすると、AIが感情を持つようになる。"
        ],
        "correctAnswer": "値を「0」に近づけると、毎回同じような確実性の高い回答が出やすくなる（論理的タスク向き）。",
        "explanation": "正解は選択肢1です。Temperatureが低い（0に近い）と予測確率が高い単語が選ばれやすく「決まった回答」になり、高い（1に近い）とランダム性が増し「創造的な回答」になります。選択肢2、3、4は誤りです。"
      },
      {
        "question": "「Top-p」パラメータの役割として適切なものはどれか。",
        "options": [
          "AIの回答速度を制限する。",
          "出力する単語の候補を、累積確率が指定した値（p）になる上位グループに絞り込み、その中から選択させることでランダム性を制御する。",
          "過去の会話履歴をどれだけ記憶するかを設定する。",
          "不適切な発言をフィルタリングする。"
        ],
        "correctAnswer": "出力する単語の候補を、累積確率が指定した値（p）になる上位グループに絞り込み、その中から選択させることでランダム性を制御する。",
        "explanation": "正解は選択肢2です。Temperatureと同様に出力の多様性を制御するパラメータです。Top-pサンプリングとも呼ばれます。選択肢1、3、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 5,
    "sectionId": "unit02-prompt-basics",
    "sectionTitle": "プロンプトエンジニアリング基礎",
    "questions": [
      {
        "question": "プロンプトを構成する「4つの要素」に含まれないものはどれか。",
        "options": [
          "Instruction（命令）：AIに何をしてほしいか",
          "Context（文脈）：背景情報や役割",
          "Emotion（感情）：ユーザーの怒りや喜びの度合い",
          "Output Indicator（出力指示）：形式や長さの指定"
        ],
        "correctAnswer": "Emotion（感情）：ユーザーの怒りや喜びの度合い",
        "explanation": "正解は選択肢3です。プロンプトの4要素は「Instruction（命令）」「Context（文脈）」「Input Data（入力データ）」「Output Indicator（出力指示）」です。感情は要素に含まれません。選択肢1、2、4はプロンプトの4要素に含まれます。"
      },
      {
        "question": "「Zero-Shotプロンプティング」の説明として正しいものはどれか。",
        "options": [
          "例文（正解例）を一つも提示せず、いきなり質問や指示を投げる手法。",
          "0回しか質問できないという制限付きの手法。",
          "誤った回答を0にするための特殊な手法。",
          "プロンプトを入力せずに念じるだけで回答を得る手法。"
        ],
        "correctAnswer": "例文（正解例）を一つも提示せず、いきなり質問や指示を投げる手法。",
        "explanation": "正解は選択肢1です。「〜について教えて」のように、例示なしで指示する手法です。モデルの基礎能力に依存します。選択肢2、3、4は誤りです。"
      },
      {
        "question": "「Few-Shotプロンプティング」が有効な理由は何か。",
        "options": [
          "プロンプトが短くなるため、料金が安くなるから。",
          "AIに「回答のパターン（入力と出力のセット）」をいくつか例示することで、期待する回答形式やニュアンスを学習（In-context Learning）させることができるから。",
          "AIの学習データを削除できるから。",
          "どんな質問にも必ず正解できるようになるから。"
        ],
        "correctAnswer": "AIに「回答のパターン（入力と出力のセット）」をいくつか例示することで、期待する回答形式やニュアンスを学習（In-context Learning）させることができるから。",
        "explanation": "正解は選択肢2です。2〜3個の例（Shot）を見せることで、AIは「あ、こういう風に答えればいいんだな」と文脈から推論し、精度が向上します。選択肢1、3、4は誤りです。"
      },
      {
        "question": "複雑な推論を要する問題に対し、「ステップバイステップで考えてください（Let's think step by step）」と指示することで正答率が向上する手法を何と呼ぶか。",
        "options": [
          "Chain-of-Thought（思考の連鎖）プロンプティング",
          "Zero-Shotプロンプティング",
          "マルチモーダルプロンプティング",
          "敵対的プロンプティング"
        ],
        "correctAnswer": "Chain-of-Thought（思考の連鎖）プロンプティング",
        "explanation": "正解は選択肢1です。いきなり答えを出させるのではなく、思考過程（中間ステップ）を出力させることで論理的な誤りを減らす手法です。選択肢2の「Zero-Shot」は例を示さずに質問、選択肢3の「マルチモーダル」は複数のモダリティを扱う手法、選択肢4の「敵対的プロンプティング」は攻撃手法です。"
      }
    ]
  },
  {
    "chapter": 5,
    "sectionId": "unit03-advanced-prompting",
    "sectionTitle": "応用プロンプティング（高度な思考制御技法）",
    "questions": [
      {
        "question": "「あなたはプロのマーケターです」のように、AIに特定の役割や肩書きを与えるプロンプト技法（ペルソナ設定）の主な効果は何か。",
        "options": [
          "AIが人間になったと勘違いして、暴走する。",
          "一般的な回答ではなく、その専門分野の視点や用語を用いた、より質の高い具体的な回答を引き出せる。",
          "AIの処理速度が2倍になる。",
          "嘘をつく確率が上がる。"
        ],
        "correctAnswer": "一般的な回答ではなく、その専門分野の視点や用語を用いた、より質の高い具体的な回答を引き出せる。",
        "explanation": "正解は選択肢2です。役割（ロール）を与えることで、回答の視座やトーン＆マナーを制御し、専門的なアウトプットを得やすくなります。選択肢1、3、4は誤りです。"
      },
      {
        "question": "長文を要約させる際、AIが重要な情報を見落とさないようにするための工夫として、最も効果的な指示はどれか。",
        "options": [
          "「短くして」とだけ伝える。",
          "「以下の文章の『結論』と『3つの根拠』を箇条書きで抽出して要約してください」のように、抽出項目と形式を具体的に指定する。",
          "何度も同じ文章を入力する。",
          "英語に翻訳してから要約させる。"
        ],
        "correctAnswer": "「以下の文章の『結論』と『3つの根拠』を箇条書きで抽出して要約してください」のように、抽出項目と形式を具体的に指定する。",
        "explanation": "正解は選択肢2です。単に「要約して」ではなく、「何を（要素）」「どうやって（形式）」残すかを指定することで、精度の高い要約が得られます。選択肢1、3、4は効果的ではありません。"
      },
      {
        "question": "箇条書きのメモから、自然なビジネスメールの文章を作成させるタスクは、プロンプトエンジニアリングのどの活用例にあたるか。",
        "options": [
          "文章の校正",
          "文章の生成・変換（フォーマット変換）",
          "情報の検索",
          "画像の生成"
        ],
        "correctAnswer": "文章の生成・変換（フォーマット変換）",
        "explanation": "正解は選択肢2です。「箇条書き→文章」「文章→表」などのフォーマット変換は、LLMが非常に得意とするタスクの一つです。選択肢1の「校正」は誤字脱字の修正、選択肢3の「検索」は情報の探索、選択肢4の「画像生成」は別のモダリティです。"
      },
      {
        "question": "ブレインストーミング（アイデア出し）において、AIを活用する最大のメリットは何か。",
        "options": [
          "人間が思いつかないような突飛なアイデアも含め、短時間で大量のバリエーションを出せるため、発想の幅が広がる。",
          "最終的な決定をAIに任せられる。",
          "会議室を予約する必要がなくなる。",
          "参加者全員の意見を無視できる。"
        ],
        "correctAnswer": "人間が思いつかないような突飛なアイデアも含め、短時間で大量のバリエーションを出せるため、発想の幅が広がる。",
        "explanation": "正解は選択肢1です。AIは疲れることなく、多角的な視点から大量の案を出せるため、アイデアの「壁打ち相手」として最適です。選択肢2、3、4は誤りです。"
      },
      {
        "question": "海外企業へのメール作成などで、AI翻訳を活用する際の注意点として適切なものはどれか。",
        "options": [
          "AIの翻訳は完璧なので、確認せずに送信してよい。",
          "専門用語やニュアンスが誤訳される可能性があるため、逆翻訳（日本語→英語→日本語）をして意味が通じるか確認するか、人間の手で最終チェックを行う。",
          "翻訳機能は使わず、単語リストだけ出させるべき。",
          "敬語は翻訳できないので諦める。"
        ],
        "correctAnswer": "専門用語やニュアンスが誤訳される可能性があるため、逆翻訳（日本語→英語→日本語）をして意味が通じるか確認するか、人間の手で最終チェックを行う。",
        "explanation": "正解は選択肢2です。高性能化していますが、文脈の取り違えは起こり得ます。逆翻訳や目視チェックは必須のリスク管理です。選択肢1、3、4は誤りです。"
      }
    ]
  },
  {
    "chapter": 5,
    "sectionId": "unit04-business-risk",
    "sectionTitle": "ビジネス活用とリスク管理",
    "questions": [
      {
        "question": "大規模言語モデル（LLM）が、「3桁以上の掛け算」や「複雑な数学パズル」を間違えることがある主な理由は何か。",
        "options": [
          "コンピュータの故障。",
          "LLMは計算機ではなく「次に来る単語を確率で予測するモデル」であり、論理的な計算プロセスを厳密に実行しているわけではないから。",
          "意地悪をしているから。",
          "学習データに数字が含まれていないから。"
        ],
        "correctAnswer": "LLMは計算機ではなく「次に来る単語を確率で予測するモデル」であり、論理的な計算プロセスを厳密に実行しているわけではないから。",
        "explanation": "正解は選択肢2です。LLMは「計算」しているのではなく、テキストとして「確率的に続きを予測」しているだけなので、数字の厳密な操作は苦手分野です。選択肢1、3、4は誤りです。"
      },
      {
        "question": "「〇〇文字以内で書いて」という文字数指定を、AIが正確に守れないことが多い技術的な理由はどれか。",
        "options": [
          "AIが反抗期だから。",
          "AIは文字数ではなく「トークン（単語の断片）」単位でデータを処理しており、トークン数と実際の文字数が一致しないため。",
          "日本語の文字を認識できないから。",
          "文字数を数える機能が実装されていないから。"
        ],
        "correctAnswer": "AIは文字数ではなく「トークン（単語の断片）」単位でデータを処理しており、トークン数と実際の文字数が一致しないため。",
        "explanation": "正解は選択肢2です。AI内部では「トークン」で処理されており、特に日本語はトークン化の区切りが複雑なため、文字数指定の誤差が出やすくなります。選択肢1、3、4は誤りです。"
      },
      {
        "question": "従来のLLMが抱える「ナレッジカットオフ（学習データの期間終了後の情報を知らない）」の問題を解決し、最新情報に基づいた回答を得るためのアプローチとして、適切なツールや手法はどれか。",
        "options": [
          "20年前のデータを学習させる。",
          "Perplexity AIなどの「Web検索機能」を統合したAIツールや、RAG（検索拡張生成）を利用する。",
          "同じ質問を100回繰り返す。",
          "コンピュータを再起動する。"
        ],
        "correctAnswer": "Perplexity AIなどの「Web検索機能」を統合したAIツールや、RAG（検索拡張生成）を利用する。",
        "explanation": "正解は選択肢2です。テキスト第4版では、最新情報の弱点を補う手段として、リアルタイム検索を行うPerplexity AIやRAGの活用が挙げられています。選択肢1、3、4は誤りです。"
      },
      {
        "question": "「ハルシネーション（幻覚）」と呼ばれる現象の説明として正しいものはどれか。",
        "options": [
          "AIが幽霊を見ること。",
          "AIが事実とは異なる内容や、架空の情報を、あたかも事実であるかのように自信満々に回答してしまう現象。",
          "AIがユーザーの心を読み取ること。",
          "AIが回答を拒否すること。"
        ],
        "correctAnswer": "AIが事実とは異なる内容や、架空の情報を、あたかも事実であるかのように自信満々に回答してしまう現象。",
        "explanation": "正解は選択肢2です。もっともらしい嘘（幻覚）をつく現象です。これを防ぐためには「情報源を明示させる」などのプロンプト工夫が必要です。選択肢1、3、4は誤りです。"
      },
      {
        "question": "企業の機密データを扱って資料を作成する際、AIサービスに入力するデータについて注意すべき点は何か。",
        "options": [
          "AIは友達なので、秘密を打ち明けても大丈夫。",
          "入力したデータが「AIの学習に利用される（オプトイン）」設定になっている場合、機密情報が他社への回答として流出する恐れがあるため、オプトアウト設定を確認するか、個人情報をマスキングする。",
          "機密情報は暗号化すれば入力してもよい。",
          "深夜に入力すれば学習されない。"
        ],
        "correctAnswer": "入力したデータが「AIの学習に利用される（オプトイン）」設定になっている場合、機密情報が他社への回答として流出する恐れがあるため、オプトアウト設定を確認するか、個人情報をマスキングする。",
        "explanation": "正解は選択肢2です。学習利用される設定（デフォルトの場合が多い）では情報漏洩のリスクがあります。オプトアウト（学習拒否）の確認は必須です。選択肢1、3、4は誤りです。"
      },
      {
        "question": "AIが生成した文章に、特定の人種や性別に対する偏見（バイアス）が含まれてしまう主な原因は何か。",
        "options": [
          "AIの性格が悪いから。",
          "AIが学習したインターネット上の大量のテキストデータ自体に、人間社会の偏見やステレオタイプが含まれていたから。",
          "開発者が意図的に差別プログラムを組み込んだから。",
          "ユーザーのプロンプトが短すぎたから。"
        ],
        "correctAnswer": "AIが学習したインターネット上の大量のテキストデータ自体に、人間社会の偏見やステレオタイプが含まれていたから。",
        "explanation": "正解は選択肢2です。AIは学習データを鏡のように反映します。学習元のデータにある社会的バイアスが、そのまま出力に現れるリスクを理解しておく必要があります。選択肢1、3、4は誤りです。"
      },
      {
        "question": "生成AIを利用する際、最終的な成果物の責任は誰にあると考えられるか。",
        "options": [
          "AIを開発したベンダー企業だけにある。",
          "AI自身にある。",
          "AIを利用し、その出力を採用・公開した利用者（人間）にある。",
          "誰にも責任はない。"
        ],
        "correctAnswer": "AIを利用し、その出力を採用・公開した利用者（人間）にある。",
        "explanation": "正解は選択肢3です。AIはあくまで「道具」です。その出力内容の真偽確認（ファクトチェック）や権利侵害の確認を含め、最終的な責任は利用者にあります。選択肢1、2、4は誤りです。"
      }
    ]
  }
]